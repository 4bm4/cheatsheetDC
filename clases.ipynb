{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import inspect\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from pygam import LinearGAM, s, f, l\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as stats2\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from statsmodels.formula.api import ols,glm\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error,r2_score, confusion_matrix, precision_recall_fscore_support,roc_curve, accuracy_score, roc_auc_score\n",
    "from dmba import stepwise_selection,AIC_score,classificationSummary\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prueba = pd.DataFrame({\n",
    "\"ES_NO_ES\":[np.random.choice(['s','n']) for _ in range(1000)],\n",
    "\"sexo\":[np.random.choice(['h','m']) for _ in range(1000)],\n",
    "\"Datos_C\":[np.random.choice([0,1]) for _ in range(1000)],\n",
    "\"Datos_D\": list(np.random.standard_normal(1000)),\n",
    "\"Datos_E\": list(np.random.standard_normal(1000)),\n",
    "\"Datos_Poisson_1\": list( stats.poisson.rvs(mu=4, size=1000)),\n",
    "\"Datos_Poisson_3\": list( np.random.poisson(lam=10, size=1000)),\n",
    "\"Datos_Geom\": list( stats.geom.rvs(0.75, size=1000)),\n",
    "\"Datos_F\": [np.random.randint(0,1000) for _ in range(1000)],\n",
    "\"Datos_G\": [np.random.randint(0,1000) for _ in range(1000)],\n",
    "\"Datos_cate_A\": ['Grupo '+str(np.random.randint(0,6)) for _ in range(1000)],\n",
    "\"Datos_cate_B\": ['Grupo '+str(np.random.randint(0,4)) for _ in range(1000)],\n",
    "\"Datos_cate_C\": [np.random.randint(0,60) for _ in range(1000)],\n",
    "\n",
    "})\n",
    "\n",
    "# for i in range(1,6):\n",
    "#     df_prueba['Datos_E'][random.randint(0,23)]=None\n",
    "\n",
    "\n",
    "# for i in range(1,10):\n",
    "#     df_prueba['Datos_F'][random.randint(0,23)]=None\n",
    "\n",
    "# for i in range(0,11):\n",
    "#     df_prueba['Datos_G'][i]=None\n",
    "\n",
    "    \n",
    "lista_de_items= ['Item '+str(np.random.randint(0,6)) for _ in range(30000)]\n",
    "num_fact= 30000\n",
    "\n",
    "def crear_lista (lista):\n",
    "    listafin=[]\n",
    "    for i in range (0,num_fact):\n",
    "        lista_aux=[]\n",
    "        for j in range(1, random.randint(1, 10)):\n",
    "            lista_aux.append(random.choice(lista))\n",
    "        \n",
    "        listafin.append(lista_aux)\n",
    "    \n",
    "    return listafin\n",
    "\n",
    "# facturas=crear_lista(lista_de_items)\n",
    "\n",
    "\n",
    "# df_prueb2 = pd.DataFrame({\n",
    "# \"Items\": lista_de_items,\n",
    "# \"facturas\": facturas,\n",
    "# })\n",
    "\n",
    "# pd.merge(df_prueba, df_prueb2,left_index=True, right_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DF_exploracion(pd.DataFrame):\n",
    "\n",
    "    def __init__(self, *args, **kw):\n",
    "        super(DF_exploracion, self).__init__(*args, **kw)\n",
    "        self.cuanti=pd.DataFrame\n",
    "        self.cuanti_antes_de_outliers_y_inputs=pd.DataFrame\n",
    "        self.cuali=pd.DataFrame\n",
    "        self.dico=pd.DataFrame\n",
    "        self.cate=pd.DataFrame\n",
    "        self.eliminado=pd.DataFrame\n",
    "        self.dummy=pd.DataFrame\n",
    "        self.df=pd.DataFrame\n",
    "        self.df_inputado=pd.DataFrame\n",
    "        self.df_limpio=pd.DataFrame\n",
    "        self.predicotres=pd.DataFrame\n",
    "        self.outcome=pd.DataFrame\n",
    "        # self.outcome_col=self.outcome.columns\n",
    "        self.normal_cuatis=[]\n",
    "        self.normal_grupos_dico=[]\n",
    "        self.normal_grupos_cate=[]\n",
    "        self.discreta=[]\n",
    "        self.stingg=[]\n",
    "        self.outliers_hecho=True\n",
    "        self.porcentaje_nulos_permitido=0.3\n",
    "\n",
    "    def variables(self):\n",
    "\n",
    "        dico=[]\n",
    "        cuantis=[]\n",
    "        categori=[]\n",
    "        eliminar=[]\n",
    "        \n",
    "\n",
    "        for i in self.columns: \n",
    "\n",
    "            try:\n",
    "                datos=self[i].dropna().to_numpy()\n",
    "                discreta=True\n",
    "                for j in datos:\n",
    "                    if (j%1 !=0):\n",
    "                        discreta=False\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                if (discreta):\n",
    "                    self.discreta.append(i)\n",
    "            except:\n",
    "                self.stingg.append(i)\n",
    "\n",
    "            nulos= (self[i].isnull().sum())/len(self[i])\n",
    "            \n",
    "            if ((len(self[i].dropna().unique())==2) and (nulos<=self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: DICOTOMICA\"\n",
    "                dico.append(i)\n",
    "\n",
    "            elif ((len(self[i].dropna().unique())>10) and  (nulos<=self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: CUANTITATIVA\"\n",
    "                cuantis.append(i)\n",
    "\n",
    "            elif ( (len(self[i].dropna().unique())<2) or (nulos>self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"SOLO {len(self[i].dropna().unique())} TIPOS, NO VALE LA COLUMNA\"\n",
    "                eliminar.append(i)\n",
    "            else:\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: CATEGORICA/CUANTI\"\n",
    "                categori.append(i)\n",
    "\n",
    "            print (f\"|  {i} \\n|   - Tipo de dato: {self[i].dtype} \\n|   - Valores repetidos: {tipo_de_var} \\n|   - Nulos: {nulos} \\n| \")\n",
    "\n",
    "        print (f\"|----------------------------------------------------------------------------------------------------\\n|  TODAS: {self.columns} \\n|  DICOTOMICAS: {dico} \\n|  CATEGORICAS: {categori} \\n|  CUANTITATIVAS: {cuantis} \\n|  ELIMINAR: {eliminar}\")\n",
    "        print(\"|----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        self.DF_cuantis(cuantis)\n",
    "        self.DF_cualis(categori+dico)\n",
    "        self.DF_dicotomica(dico)\n",
    "        self.DF_categorica(categori)\n",
    "        self.DF_elimiminado(eliminar)\n",
    "        self.df=self\n",
    "        \n",
    "    def todas_col(self):\n",
    "        return self.df\n",
    "    \n",
    "    def DF_cuantis(self,lista):\n",
    "        self.cuanti=self[lista]\n",
    "\n",
    "    def DF_elimiminado(self,lista):\n",
    "        self.eliminado=self[lista]\n",
    "        \n",
    "    def DF_cualis(self,lista):\n",
    "        self.cuali=self[lista]\n",
    "        \n",
    "    def DF_dicotomica(self, lista):\n",
    "        self.dico=self[lista]\n",
    "        \n",
    "    def DF_categorica(self, lista):\n",
    "        self.cate=self[lista]   \n",
    "\n",
    "\n",
    "\n",
    "    def limpiar_aux(self):\n",
    "        \n",
    "        try:\n",
    "            df_nuevo=pd.DataFrame\n",
    "            aux1=list(self.dico.columns)\n",
    "            aux=[]\n",
    "            df_nuevo=pd.get_dummies(self.df, columns=aux1)\n",
    "            \n",
    "            for columna in df_nuevo.columns:\n",
    "                for variables in list(self.dico.columns):\n",
    "                    if variables in columna:\n",
    "                        aux.append(columna)\n",
    "                    \n",
    "            self.dummy=df_nuevo[aux]\n",
    "            self[aux]=df_nuevo[aux]\n",
    "\n",
    "            # self.df=self.drop(columns=var, axis='columns')\n",
    "            # self.df= self[self.columns.difference(self.dico.columns)]\n",
    "            \n",
    "            print(\"********************** self.dummy ************\\n\")\n",
    "            print(self.dummy)\n",
    "            print(\"\\n********************** self.df o todas_las_col() ************\\n\")\n",
    "            print(self.df)\n",
    "\n",
    "        except:\n",
    "            print(\"---------------------- ERROR -----------------\")\n",
    "\n",
    "\n",
    "\n",
    "    def limpiar_dummys(self):\n",
    "\n",
    "        b=False\n",
    "        lista=list(self.dico.columns)\n",
    "        for ind, i in enumerate(lista):\n",
    "                if (ind+1<len(lista)):\n",
    "                    if( (i in lista [ind+1]) ):\n",
    "                        b=True\n",
    "                        break\n",
    "        if b:\n",
    "            nombres_nuevos=[]\n",
    "            if len(lista)>2:\n",
    "                for ind, i in enumerate(lista):\n",
    "                    if (ind+1<len(lista)):\n",
    "                        if( (i in lista [ind+1]) ):\n",
    "                            nombres_nuevos.append(i.upper())\n",
    "                        else:\n",
    "                            nombres_nuevos.append(i)\n",
    "                    else:\n",
    "                        nombres_nuevos.append(i)\n",
    "                        \n",
    "            aux_df=self.df\n",
    "\n",
    "            for i,j in zip(lista,nombres_nuevos):\n",
    "                aux_df.rename(columns={i:j},inplace=True)\n",
    "                \n",
    "            self.df=aux_df\n",
    "            self.dico.columns=nombres_nuevos\n",
    "            \n",
    "            self.limpiar_aux()\n",
    "        else: \n",
    "            self.limpiar_aux()\n",
    "\n",
    "\n",
    "\n",
    "    def estadistica_descriptiva_cuantis(self):\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\nDESCRIPCIÓN\")\n",
    "        print (self.cuanti.describe())\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\nCUARTILES\")\n",
    "        print (self.cuanti.quantile([0.05,0.25,0.5,0.75,0.95]))\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        # df_auxiliar = self.groupby('sexo').apply(lambda x: pd.Series(shapiro(x), index=['W','P'])).reset_index()\n",
    "        # print(df_auxiliar)\n",
    "                \n",
    "        for a in list(aux1.values):\n",
    "            \n",
    "            for b in list(aux.values):\n",
    "                \n",
    "                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                agrupado=self.groupby(a)[b]\n",
    "                titulo=f\"Agrupado por {a} y por {b}\"\n",
    "                print(titulo)\n",
    "                print(agrupado.describe().reset_index())\n",
    "                # df.groupby(['cat1', 'cat2'])['purchases','sales'].apply(stats.shapiro)\n",
    "                print(\"////////////////////////// TEST DE SHAPIRO ////////////////////////////\")\n",
    "                aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                print(aux_shapiro)\n",
    "        \n",
    "                \n",
    "                print(\"\\n\")\n",
    "                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "    def estadistica_descriptiva_cualis(self):\n",
    "\n",
    "        print(\"\\n--------------------- Variables dico ---------------------\")\n",
    "        print(\"\\n\")\n",
    "        for i in self.dico.columns:\n",
    "            print(f\"...........Frecuencia variable {i} ....................\")\n",
    "            print(self[i].value_counts()/(self[i].count()))\n",
    "            print(\"\\n\")\n",
    "\n",
    "        print(\"\\n-------------------- Variables categoricas --------------------\")\n",
    "        print(\"\\n\")\n",
    "        for i in self.cate.columns:\n",
    "            print(f\"...........Frecuencia variable {i} ....................\")\n",
    "            print(self[i].value_counts()/(self[i].count()))\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # crosstab variables cualis con cate\n",
    "        aux=list(self.cate.columns)\n",
    "\n",
    "        a=0\n",
    "        for i in aux:\n",
    "            a=a+1\n",
    "            if a<len(aux)/2:\n",
    "                b=0\n",
    "                for j in aux[:-1]:\n",
    "                    b=b+1\n",
    "                    if b > a:\n",
    "                        print(f\"*************** TABAL DE VARIABLES CATEGORICAS {i} y {j} *********************\\n \")\n",
    "                        tab = pd.crosstab (index=self[i], columns=self[j])\n",
    "                        x=(tab/tab.sum())\n",
    "                        print(tab)\n",
    "                        print(\"\\n\")\n",
    "                        print(f\"/////////////////// EN PROPORCION //////////////////\\n\")\n",
    "                        print(x)\n",
    "                        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    def anova(self):\n",
    "\n",
    "        aux_cate=list(self.cate.columns)\n",
    "        aux_cuati=list(self.cuanti.columns)\n",
    "\n",
    "        for i in aux_cate:\n",
    "            for j in aux_cuati:\n",
    "                try:\n",
    "                    print(f\"\\n----------- ANOVA Categoria {i} y variable continua {j} ----------\\n\")\n",
    "                    model = ols(f\"{j} ~ {i}\", data=self).fit()\n",
    "                    a=sm.stats.anova_lm(model, typ=2)\n",
    "                    print(a)\n",
    "                except:\n",
    "                    print(f\"\\n - - - - - Fallo en variable {i} y {j} - - - - - - \\n\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Chi(self):\n",
    "\n",
    "        aux_dico=list(self.dico.columns)\n",
    "\n",
    "        if len(aux_dico)>1:\n",
    "            for ind, i in enumerate(aux_dico):\n",
    "                for j in range(ind+1,len(aux_dico)):\n",
    "                    chi, p, dof, expected = stats.chi2_contingency(pd.crosstab(self[i],self[aux_dico[j]]), correction=False)\n",
    "                    print(f\"\\n-------------- Chi2 entre {i} y {aux_dico[j]} ----------------\")\n",
    "                    print(f\"p: {p} \\n\") \n",
    "        else:\n",
    "            print(\"******************** No suficientes argumentos ********************\")\n",
    "\n",
    "\n",
    "    def t_test_aux(self, columns):\n",
    "        results = []\n",
    "        for i, col1 in enumerate(columns[:-1]):\n",
    "            for col2 in columns[i+1:]:\n",
    "                t, p = stats.ttest_ind(self[col1].dropna(), self[col2].dropna(), equal_var=False)\n",
    "                # results.append((col1, col2, t, p))\n",
    "                if p < 0.05:\n",
    "                    print( f\"+++++ Variable{col1}, variable 2 {col2} con p de: \\033[1m{p}\\033[0m  Se RECHAZA H0 ++++\") \n",
    "                else:\n",
    "                    print( f\"+++++ Variable{col1}, variable 2 {col2}  con p de: {p} SE ACEPTA H0 ++++\") \n",
    "    \n",
    "    def wilcoxon_test_aux(self,col1, col2):\n",
    "        if (col1== col2).all():\n",
    "            print (\"\\nLas coluimnas son iguales\\n\")\n",
    "        res = stats.wilcoxon(col1, col2)\n",
    "        if res.pvalue < 0.05:\n",
    "            print(f\"Reject null hypothesis. Significant difference  (p-value={res.pvalue:.4f})\")\n",
    "        else:\n",
    "            print (f\"Fail to reject null hypothesis. No significant difference (p-value={res.pvalue:.4f})\")\n",
    "\n",
    "    def wilconxon(self, lista):\n",
    "        # lista=[grupo, var]\n",
    "        a,b=self.agrupar(lista)\n",
    "        print(f\"\\n- Variable: {lista[1]}, Grupo: {lista[0]}\")\n",
    "        self.wilcoxon_test_aux(a, b)\n",
    "\n",
    "    def agrupar (self, lista):\n",
    "        groupby_col=lista[0]\n",
    "        col=lista[1]\n",
    "        valor=self[groupby_col].unique()\n",
    "        group= self.where(self[groupby_col]== valor[0])[col]\n",
    "        group2= self.where(self[groupby_col]== valor[1])[col] \n",
    "        return group,group2\n",
    "\n",
    "    # def t_test_groupby_one_col(self, col, groupby_col):\n",
    "        \n",
    "    #     group= self.where(self[groupby_col]== self[groupby_col][0]).dropna()[col]\n",
    "    #     group2= self.where(self[groupby_col]== self[groupby_col][1]).dropna()[col]\n",
    "    #     t, p = stats.ttest_ind(group, group2, equal_var=False)\n",
    "    #     print( col, groupby_col,p) \n",
    "\n",
    "    def t_test_all(self):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        aux2=list(self.dico.columns)\n",
    "        self.t_test_aux(self.normal_cuatis) #aqui ya hace todas las cuantis entre ellas faltan los grupos\n",
    "        for i in self.normal_grupos_dico:\n",
    "            a,b=self.agrupar(i)\n",
    "            t, p = stats.ttest_ind(a.dropna(), b.dropna(), equal_var=False)\n",
    "            if p < 0.05:\n",
    "                print( f\"+++++ Variable{i[1]}, Agrupado por {i[0]} con p de: \\033[1m{p}\\033[0m  Se RECHAZA H0 ++++\") \n",
    "            else:\n",
    "                print( f\"+++++ Variable{i[1]}, Agrupado por {i[0]} con p de: {p} SE ACEPTA H0 ++++\") \n",
    "    # df_prueba.groupby('sexo').apply(lambda df: stats.ttest_ind(df['Datos_D'].dropna(), df['Datos_E'].dropna())[1])\n",
    "\n",
    "\n",
    "    def plot_confidence_interval(self, col, confidence_level= 0.95):\n",
    "        data = self[col].to_numpy()\n",
    "        n = len(data)\n",
    "        mean =self[col].mean(axis=0)\n",
    "        # std_error = stats.sem( self[col].dropna())\n",
    "        std_error = self[col].dropna().std()\n",
    "        lower_bound = stats.t.ppf(0.025, n - 1, loc = mean, scale = std_error)  # =>  99.23452406698323\n",
    "        upper_bound = stats.t.ppf(0.975, n - 1, loc = mean, scale = std_error)\n",
    "        # h = std_error * stats.t.ppf((1 + confidence_level) / 2, n - 1)\n",
    "        \n",
    "        # lower_bound = mean - h\n",
    "        # upper_bound = mean + h\n",
    "        # plt.hist(data, bins=30, edgecolor='black', alpha=0.5)\n",
    "        # plt.axvspan(lower_bound, upper_bound, color='gray', alpha=0.2, label=f'{confidence_level * 100}% Confidence Interval')\n",
    "        # plt.axvline(x=mean, color='red', label='Sample Mean')\n",
    "        # plt.legend()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(data, bins=30, edgecolor='black', alpha=0.5)\n",
    "        ax.axvline(x=mean, color='red', label='Sample Mean')\n",
    "        ax.axvspan(lower_bound, upper_bound, color='grey', alpha=0.5, label=f'{confidence_level * 100}% Confidence Interval')\n",
    "        ax.annotate(\n",
    "            f'lower_bound:\\n {lower_bound:.2f}',\n",
    "            xy=(lower_bound, 0), xytext=(lower_bound-0.5, 50)\n",
    "        )\n",
    "        ax.annotate(\n",
    "            f'upper_bound:\\n  {upper_bound:.2f}',\n",
    "            xy=(upper_bound, 0), xytext=(upper_bound-0.5, 50)\n",
    "        )\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_normailidad(self):\n",
    "        aux=self.cuanti.columns\n",
    "        for i in aux:\n",
    "            stats.probplot(self[i], dist=\"norm\", plot=plt)\n",
    "            plt.title(\"Probability Plot - \" )\n",
    "            plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    def plot_bigotes(self):\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "        print(\"-------------- Graficas de bigotes cualitativas-------------------\")\n",
    "        # fig = plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        (self.cuanti).plot(kind='box', title='Variables cuantitativas',figsize=(12, 8))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        print(\"-------------- Graficas de bigotes por dicotomicas-------------------\")   \n",
    "        \n",
    "        for a in aux1:\n",
    "\n",
    "            # fig = plt.figure(figsize=(12, 8))\n",
    "            self.boxplot(column=list(aux.values), by=a,figsize=(12, 8))\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        print(\"-------------- Graficas de bigotes por categoricas-------------------\") \n",
    "\n",
    "        for a in aux2:\n",
    "            # fig = plt.figure(figsize=(12, 8))\n",
    "            ax= self.boxplot(column=list(aux.values), by=a, figsize=(12, 8))\n",
    "            # ax = sns.swarmplot(column=list(aux.values), by=a,data=self, color='#7d0013')\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        \n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    def plot_corr(self):\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        print(\"-------------- MATRIZ DE CORRELACIONES ENTRE CUANTITATIVAS -------------------\\n\") \n",
    "\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        matrix = self.cuanti.corr().round(2)\n",
    "        mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "        sns.heatmap(matrix, annot=True, vmax=1, vmin=-1, center=0, cmap='vlag', mask=mask)  \n",
    "        plt.show()\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "    def plot_barras(self):\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"-------------- GRAFICA DE BARRAS DE TODAS LAS CUANTITATIVAS -------------------\\n\") \n",
    "        # fig = plt.figure(figsize=(15, 20))\n",
    "        self.cuanti.plot.bar(figsize=(18, 8))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"-------------- GRAFICA DE BARRAS CON DISTRIBUCIÓN DE DENSIDAD DE CADA CUANTITATIVA  -------------------\\n\") \n",
    "        for i in list(aux.values):\n",
    "            fig = plt.figure(figsize=(12, 8))\n",
    "            print(f\"\\n.............. GRAFICA DE BARRAS  DE {i} ............\\n\") \n",
    "            ax=self[i].plot.hist(density=True)\n",
    "            self[i].plot.density(ax=ax)\n",
    "            plt.show()\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")    \n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "    def todos_plots(self):\n",
    "\n",
    "        self.plot_bigotes()\n",
    "        self.plot_corr()\n",
    "        self.plot_barras()\n",
    "        self.violines()\n",
    "        \n",
    "        \n",
    "\n",
    "    def violines(self):\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        print(\"--------------  GRAFICA DE VIOLINES  -------------------\\n\") \n",
    "        sns.set(style=\"whitegrid\")\n",
    "        for i in aux2:\n",
    "            for j in aux:\n",
    "                ax= sns.violinplot(x=self[i], y=self[j], palette=\"Set2\", split=True, inner=\"quartile\",scale=\"count\")\n",
    "                plt.show()\n",
    "\n",
    "        print(\"\\n\\n/////////-------------- GRAFICA DE VIOLINES POR DICOTOMICAS -------------------/////////////\\n\") \n",
    "        \n",
    "        for i in aux2:\n",
    "            for j in aux:\n",
    "                for k in aux1:\n",
    "                    ax= sns.violinplot(x=self[i], y=self[j], hue=self[k],palette=\"Set2\", split=True, inner=\"quartile\",scale=\"count\")\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "    def cross_var_cualis_con_ciantis(self):\n",
    "\n",
    "        aux=list(self.cate.columns)\n",
    "        aux_cuati=list(self.cuanti.columns)\n",
    "\n",
    "        for k in aux_cuati:\n",
    "            a=0\n",
    "            for i in aux:\n",
    "                a=a+1\n",
    "                if a<len(aux)/2:\n",
    "                    b=0\n",
    "                    for j in aux[:-1]:\n",
    "                        b=b+1\n",
    "                        if b > a:\n",
    "                            print(f\"\\n\\n*************** TABAL DE VARIABLES CATEGORICAS {i} y {j} con valores de {k} MEDIA *********************\\n \")\n",
    "                            tab = pd.crosstab (index=self[i], columns=self[j],values=self[k],aggfunc=np.mean)\n",
    "                            print(tab)\n",
    "                            print(\"\\n\\n\")\n",
    "\n",
    "    def nulos(self):\n",
    "        aux_df=list(self.cuanti.columns)\n",
    "        self.inputado=self.df\n",
    "        for i in aux_df:\n",
    "            nulos=self[i].isna().sum()\n",
    "            total=len(self[i])\n",
    "            porcentaje=nulos/total\n",
    "            if ((nulos>0)):\n",
    "                percen=self[i].quantile([0.2,0.8]).to_list()\n",
    "                self[i]=self[i].apply(lambda x: ( random.randint ( round(percen[0]) , round(percen[1]) )) if pd.isna(x) else x )\n",
    "                print(f\"\\n- Se han inputado {nulos} nulos a la variable {i} (tenía porcentaje de nulos de: {porcentaje}) \\n\")\n",
    "            elif (porcentaje>self.porcentaje_nulos_permitido):\n",
    "                print(f\"\\n - No se ha podido inputar a la variable {i} porque el porcentaje de nulos era de {porcentaje}\\n\")\n",
    "                \n",
    "\n",
    "    def normalidad(self):\n",
    "        \n",
    "        DataF=self.df\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "                \n",
    "        for b in list(aux.values):\n",
    "            aux_shapiro=(stats.shapiro(DataF[b]))\n",
    "            if(aux_shapiro.pvalue<0.05):\n",
    "                print(\"////////////////////////// TEST DE SHAPIRO CUANTITATIVAS ////////////////////////////\")\n",
    "                print(\"++++++++++++++++++++++++++++  \"+ b +\"  ++++++++++++++++++++++++++\\n\")\n",
    "                titulo=f\"Variable cuantitativa {b} y test Shapiro < 0.05\"\n",
    "                print(titulo)\n",
    "                print(aux_shapiro)\n",
    "                print(\"\\n\")\n",
    "                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                self.normal_cuatis.append(b)\n",
    "\n",
    "        for a in list(aux1.values):\n",
    "            for b in list(aux.values):\n",
    "                    agrupado=DataF.groupby(a)[b]\n",
    "                    try:\n",
    "                        aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                        for h in aux_shapiro:\n",
    "                            if(h.pvalue<0.05):\n",
    "                                print(\"////////////////////////// TEST DE SHAPIRO DICOTOMICAS ////////////////////////////\")\n",
    "                                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                                titulo=f\"Agrupado por {a} y por {b} y test Shapiro < 0.05\"\n",
    "                                print(titulo)\n",
    "                                print(aux_shapiro)\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                                self.normal_grupos_dico.append([a,b])\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "        for a in list(aux2.values):\n",
    "            for b in list(aux.values):\n",
    "                    agrupado=DataF.groupby([a])[b]\n",
    "                    try:\n",
    "                        aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                        for h in aux_shapiro:\n",
    "                            if(h.pvalue<0.05):\n",
    "                                print(\"////////////////////////// TEST DE SHAPIRO CATEGORICAS ////////////////////////////\")\n",
    "                                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                                titulo=f\"Agrupado por {a} y por {b} y test Shapiro < 0.05\"\n",
    "                                print(titulo)\n",
    "                                print(h)\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                                self.normal_grupos_cate.append([a,b])\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "        self.normal_grupos_dico=[i for n, i in enumerate(self.normal_grupos_dico) if i not in self.normal_grupos_dico[:n]]\n",
    "        self.normal_grupos_cate=[i for n, i in enumerate(self.normal_grupos_cate) if i not in self.normal_grupos_cate[:n]]\n",
    "        \n",
    "    def detec_outlaiers(self):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        aux_DF=self.cuanti\n",
    "        for i in aux:\n",
    "            z = np.abs(stats.zscore(aux_DF[i]))\n",
    "            print(z)\n",
    "    \n",
    "    def seleccionar_distribuciones(self,familia='realall', verbose=False):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        familia : {'realall', 'realline', 'realplus', 'real0to1', 'discreta'}\n",
    "            realall: distribuciones de la familia `realline` + `realplus`\n",
    "            realline: distribuciones continuas en el dominio (-inf, +inf)\n",
    "            realplus: distribuciones continuas en el dominio [0, +inf)\n",
    "            real0to1: distribuciones continuas en el dominio [0,1]\n",
    "            discreta: distribuciones discretas\n",
    "            \n",
    "        verbose : bool\n",
    "            Si se muestra información de las distribuciones seleccionadas\n",
    "            (the default `False`)\n",
    "        '''\n",
    "    \n",
    "        distribuciones = [getattr(stats,d) for d in dir(stats) \\\n",
    "                        if isinstance(getattr(stats,d), (stats.rv_continuous, stats.rv_discrete))]\n",
    "        \n",
    "        exclusiones = ['levy_stable', 'vonmises']\n",
    "        distribuciones = [dist for dist in distribuciones if dist.name not in exclusiones]\n",
    "                \n",
    "        dominios = {\n",
    "            'realall' : [-np.inf, np.inf],\n",
    "            'realline': [np.inf,np.inf],\n",
    "            'realplus': [0, np.inf],\n",
    "            'real0to1': [0, 1], \n",
    "            'discreta': [None, None],\n",
    "        }\n",
    "\n",
    "        distribucion = []\n",
    "        tipo = []\n",
    "        dominio_inf = []\n",
    "        dominio_sup = []\n",
    "\n",
    "        for dist in distribuciones:\n",
    "            distribucion.append(dist.name)\n",
    "            tipo.append(np.where(isinstance(dist, stats.rv_continuous), 'continua', 'discreta'))\n",
    "            dominio_inf.append(dist.a)\n",
    "            dominio_sup.append(dist.b)\n",
    "        \n",
    "        info_distribuciones = pd.DataFrame({\n",
    "                                'distribucion': distribucion,\n",
    "                                'tipo': tipo,\n",
    "                                'dominio_inf': dominio_inf,\n",
    "                                'dominio_sup': dominio_sup\n",
    "                            })\n",
    "\n",
    "        info_distribuciones = info_distribuciones \\\n",
    "                            .sort_values(by=['dominio_inf', 'dominio_sup'])\\\n",
    "                            .reset_index(drop=True)\n",
    "        \n",
    "        if familia in ['realall', 'realline', 'realplus', 'real0to1']:\n",
    "            info_distribuciones = info_distribuciones[info_distribuciones['tipo']=='continua']\n",
    "            condicion = (info_distribuciones['dominio_inf'] == dominios[familia][0]) & \\\n",
    "                        (info_distribuciones['dominio_sup'] == dominios[familia][1]) \n",
    "            info_distribuciones = info_distribuciones[condicion].reset_index(drop=True)\n",
    "            \n",
    "        if familia in ['discreta']:\n",
    "            info_distribuciones = info_distribuciones[info_distribuciones['tipo']=='discreta']\n",
    "            \n",
    "        seleccion = [dist for dist in distribuciones \\\n",
    "                    if dist.name in info_distribuciones['distribucion'].values]\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            print(\"---------------------------------------------------\")\n",
    "            print(\"       Distribuciones seleccionadas                \")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "                print(info_distribuciones)\n",
    "        \n",
    "        return seleccion\n",
    "\n",
    "\n",
    "    def plot_multiple_distribuciones(self, nombre_distribuciones):\n",
    "\n",
    "        aux=list(self.cuanti.columns)\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "        for i in aux:\n",
    "            x=self[i]\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots(figsize=(7,4))\n",
    "                \n",
    "            ax.hist(x=x, density=True, bins=30, color=\"#3182bd\", alpha=0.5)\n",
    "            ax.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "            ax.set_title('Ajuste distribuciones')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('Densidad de probabilidad')\n",
    "            \n",
    "            for nombre in nombre_distribuciones:\n",
    "                \n",
    "                distribucion = getattr(stats, nombre)\n",
    "\n",
    "                parametros = distribucion.fit(data=x)\n",
    "\n",
    "                nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                    if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "\n",
    "                log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "\n",
    "                aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "\n",
    "                x_hat = np.linspace(min(x), max(x), num=100)\n",
    "                y_hat = distribucion.pdf(x_hat, *parametros)\n",
    "                ax.plot(x_hat, y_hat, linewidth=2, label=distribucion.name)\n",
    "            \n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "    def fit_discrete(self,datos):\n",
    "\n",
    "        # self.discreta\n",
    "\n",
    "        mean = datos.mean()\n",
    "        var = datos.var()\n",
    "        likelihoods = {}  \n",
    "        log_likelihoods = {}\n",
    "\n",
    "        p = 1 - mean / var  \n",
    "        r = (1-p) * mean / p\n",
    "\n",
    "\n",
    "\n",
    "        log_likelihoods['nbinom'] = datos.map(lambda val: stats.nbinom.logpmf(val, r, p)).sum()\n",
    "\n",
    "        lambda_ = mean\n",
    "\n",
    "        log_likelihoods['poisson'] = datos.map(lambda val: stats.poisson.logpmf(val, lambda_)).sum()\n",
    "\n",
    "\n",
    "        best_fit = max(log_likelihoods, key=lambda x: log_likelihoods[x])\n",
    "        print(\"**** Best fit between poisson and nbinorm :\", best_fit)\n",
    "        \n",
    "\n",
    "    \n",
    "        plt.hist(datos, bins=int(np.max(datos)), density=True, alpha=0.5)\n",
    "\n",
    "        mean = datos.mean()\n",
    "        var = datos.var()\n",
    "\n",
    "\n",
    "        def loss_function_poisson(params, datos_in):\n",
    "\n",
    "            mu = params[0]\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            for i in range(len(datos_in)):\n",
    "\n",
    "                loglikelihood = stats.poisson.logpmf(datos_in[i], mu)\n",
    "\n",
    "                loss_to_add = -loglikelihood\n",
    "\n",
    "                loss += loss_to_add\n",
    "\n",
    "            return(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        params0 = np.array([20])\n",
    "        minimum = stats2.optimize.fmin(loss_function_poisson, params0, args=(datos,))\n",
    "\n",
    "        mu_fit = minimum[0]\n",
    "\n",
    "        print(\"***********  The best mu_fit is:  \",  mu_fit)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        x = list(range(int(np.min(datos)), int(np.max(datos))+1))\n",
    "        plt.scatter(x, stats.poisson.pmf(x, mu_fit),color=\"red\")\n",
    "        plt.show()   \n",
    "\n",
    "        print(\"\\n\\n Otras variables discretas:  \",  self.discreta)\n",
    "\n",
    "\n",
    "    def comparar_distribuciones_caunti_cont(self, ordenar='aic', verbose=False):\n",
    "\n",
    "            '''\n",
    "            resultados: data.frame\n",
    "                distribucion: nombre de la distribución.\n",
    "                log_likelihood: logaritmo del likelihood del ajuste.\n",
    "                aic: métrica AIC.\n",
    "                bic: métrica BIC.\n",
    "                n_parametros: número de parámetros de la distribución de la distribución.\n",
    "                parametros: parámetros del tras el ajuste\n",
    "                \n",
    "            Raises\n",
    "            ------\n",
    "            Exception\n",
    "                Si `familia` es distinto de 'realall', 'realline', 'realplus', 'real0to1',\n",
    "                o 'discreta'.\n",
    "                \n",
    "            Notes\n",
    "            -----\n",
    "            '''\n",
    "            aux=list(self.cuanti.columns)\n",
    "            \n",
    "            for i in aux:\n",
    "                print(f\"\\n ******************** Variable: {i} ******************** \\n\")\n",
    "                x=self[i]\n",
    "                distribuciones = self.seleccionar_distribuciones(familia='realall',verbose=verbose)\n",
    "                distribucion_ = []\n",
    "                log_likelihood_= []\n",
    "                aic_ = []\n",
    "                bic_ = []\n",
    "                n_parametros_ = []\n",
    "                parametros_ = []\n",
    "                \n",
    "                for j, distribucion in enumerate(distribuciones):\n",
    "                    \n",
    "                    # print(f\"{j+1}/{len(distribuciones)} Ajustando distribución: {distribucion.name}\")\n",
    "                    \n",
    "                    try:\n",
    "                        parametros = distribucion.fit(data=x)\n",
    "                        nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                            if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                        parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "                        log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "                        aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                        bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "                        \n",
    "                        distribucion_.append(distribucion.name)\n",
    "                        log_likelihood_.append(log_likelihood)\n",
    "                        aic_.append(aic)\n",
    "                        bic_.append(bic)\n",
    "                        n_parametros_.append(len(parametros))\n",
    "                        parametros_.append(parametros_dict)\n",
    "                        \n",
    "                        resultados = pd.DataFrame({\n",
    "                                        'distribucion': distribucion_,\n",
    "                                        'log_likelihood': log_likelihood_,\n",
    "                                        'aic': aic_,\n",
    "                                        'bic': bic_,\n",
    "                                        'n_parametros': n_parametros_,\n",
    "                                        'parametros': parametros_,\n",
    "                            \n",
    "                                    })\n",
    "                        \n",
    "                        resultados = resultados.sort_values(by=ordenar).reset_index(drop=True)\n",
    "\n",
    "                        \n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al tratar de ajustar la distribución {distribucion.name}\")\n",
    "                        print(e)\n",
    "                        print(\"\")\n",
    "\n",
    "                nombre_distribuciones=resultados['distribucion'][:5]\n",
    "                fig, ax = plt.subplots(figsize=(7,4))\n",
    "                \n",
    "                \n",
    "                ax.hist(x=x, density=True, bins=30, color=\"#3182bd\", alpha=0.5)\n",
    "                ax.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "                ax.set_title('Ajuste distribuciones')\n",
    "                ax.set_xlabel('x')\n",
    "                ax.set_ylabel('Densidad de probabilidad')\n",
    "                \n",
    "                for nombre in nombre_distribuciones:\n",
    "                    \n",
    "                    distribucion = getattr(stats, nombre)\n",
    "\n",
    "                    parametros = distribucion.fit(data=x)\n",
    "\n",
    "                    nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                        if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                    parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "\n",
    "                    log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "\n",
    "                    aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                    bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "\n",
    "                    x_hat = np.linspace(min(x), max(x), num=100)\n",
    "                    y_hat = distribucion.pdf(x_hat, *parametros)\n",
    "                    ax.plot(x_hat, y_hat, linewidth=2, label=distribucion.name)\n",
    "            \n",
    "                ax.legend()\n",
    "                plt.show()\n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(resultados.head(5))    \n",
    "                print(\"\\n------------------------------------------------------------------\\n\")\n",
    "\n",
    "    def remove_outliers(self, k=1.5):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        for column in aux:\n",
    "            print(f\"\\n\\n                    <<<<<<<<<<<<<<<<<<<<<<<< {column} >>>>>>>>>>>>>>>>>>>>>>>>\\n\\n\")\n",
    "            self.plot_outliers2(column, k=1.5)\n",
    "            q1, q3 = self[column].quantile([0.25, 0.75])\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - (k * iqr)\n",
    "            upper_bound = q3 + (k * iqr)\n",
    "            self.loc[(self[column] < lower_bound) | (self[column] > upper_bound), column] = None    \n",
    "        self.nulos()\n",
    "        self.outliers_hecho=False\n",
    "\n",
    "\n",
    "    def plot_outliers(self, column, k=1.5):\n",
    "        \n",
    "        q1, q3 = self[column].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (k * iqr)\n",
    "        upper_bound = q3 + (k * iqr)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(self.index, self[column], color='blue', label='inlier')\n",
    "        ax.scatter(self[(self[column] < lower_bound) | (self[column] > upper_bound)].index,\n",
    "                self[(self[column] < lower_bound) | (self[column] > upper_bound)][column],\n",
    "                color='red', label='outlier')\n",
    "        ax.axhline(lower_bound, color='gray', linestyle='--')\n",
    "        ax.axhline(upper_bound, color='gray', linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.show() \n",
    "\n",
    "    \n",
    "    def plot_outliers2(df, column, k=1.5):\n",
    "        q1, q3 = df[column].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (k * iqr)\n",
    "        upper_bound = q3 + (k * iqr)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(df.index, df[column], color='blue')\n",
    "        ax.scatter(df[df[column].isnull()].index,\n",
    "                df[df[column].isnull()][column],\n",
    "                color='red', marker='x')\n",
    "        ax.axhline(lower_bound, color='red', linestyle='--')\n",
    "        ax.axhline(upper_bound, color='red', linestyle='--')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_xy_data(df, x_column, y_column):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(df[x_column], df[y_column])\n",
    "        plt.xlabel(x_column)\n",
    "        plt.ylabel(y_column)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def reg_lineal(self, predictores, OUTCOME):\n",
    "        aux1=set(predictores)\n",
    "        aux2=set(list(self.cuali.columns))\n",
    "        \n",
    "\n",
    "        if (aux1.intersection(aux2)): \n",
    "            print(\"Tienes alguna variable cualitativa en los predictores\")\n",
    "        elif(OUTCOME in list(self.cuali.columns)):\n",
    "            print(\"OUTCOME es cualitativa\") \n",
    "        #No funciona con NA ni con distinta longitud dentro de los DF\n",
    "        if (self.outliers_hecho):\n",
    "            try:\n",
    "                self.remove_outliers()\n",
    "                self.predicotres=self[predictores]\n",
    "                self.outcome=self[OUTCOME]\n",
    "                ej_lm=LinearRegression()\n",
    "                ej_lm.fit(self.predicotres,self.outcome)\n",
    "\n",
    "                for name, coef in zip(predictores,ej_lm.coef_):\n",
    "                    print(f\"{name}: {coef}\")\n",
    "\n",
    "                fitted= ej_lm.predict(self.predicotres)\n",
    "                RMSE= np.sqrt(mean_squared_error(self.outcome,fitted))\n",
    "                r2= r2_score(self.outcome,fitted) \n",
    "\n",
    "                # RMSE es como el accuracy del modelo (es practicamente igual al RSE)\n",
    "                print(f\"- RMSE: {RMSE:.0f}\")\n",
    "\n",
    "                # coeficiente de determinación:  0-1 proporción de varianza en los datos\n",
    "                # que estan contabilizados en el modelo\n",
    "                print(f\"- R2: {r2:.4f}\")\n",
    "                model=sm.OLS(self.outcome,self.predicotres.assign(const=1) )\n",
    "                resul=model.fit()\n",
    "                print(\"\\n - RESUMEN \\n\")\n",
    "                print( resul.summary())\n",
    "                return ej_lm\n",
    "            except:\n",
    "                print(\"Puede que haya columans con distinta longitud\")\n",
    "\n",
    "        elif (self[predictores].isna().any().any()):\n",
    "            print(\"HAY VALORES NULOS EN LAS COLUMNAS Y YA HAS HECHO LA FUNCIÓN DE OUTLIERS\")\n",
    "\n",
    "        else :\n",
    "            try:\n",
    "                self.predicotres=self[predictores]\n",
    "                self.outcome=self[OUTCOME]\n",
    "                ej_lm=LinearRegression()\n",
    "                ej_lm.fit(self.predicotres,self.outcome)\n",
    "\n",
    "                for name, coef in zip(predictores,ej_lm.coef_):\n",
    "                    print(f\"{name}: {coef}\")\n",
    "\n",
    "                fitted= ej_lm.predict(self.predicotres)\n",
    "                RMSE= np.sqrt(mean_squared_error(self.outcome,fitted))\n",
    "                r2= r2_score(self.outcome,fitted) \n",
    "\n",
    "                # RMSE es como el accuracy del modelo (es practicamente igual al RSE)\n",
    "                print(f\"- RMSE: {RMSE:.0f}\")\n",
    "\n",
    "                # coeficiente de determinación:  0-1 proporción de varianza en los datos\n",
    "                # que estan contabilizados en el modelo\n",
    "                print(f\"- R2: {r2:.4f}\")\n",
    "                model=sm.OLS(self.outcome,self.predicotres.assign(const=1) )\n",
    "                resul=model.fit()\n",
    "                print(\"\\n ------------------------- RESUMEN --------------------------- \\n\")\n",
    "                print( resul.summary())\n",
    "                return ej_lm\n",
    "            except:\n",
    "                print(\"Puede que haya columans con distinta longitud\")\n",
    "\n",
    "\n",
    "    def forward_selected(self):\n",
    "        \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "        response: string, name of response column in data\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        model: an \"optimal\" fitted statsmodels linear model\n",
    "            with an intercept\n",
    "            selected by forward selection\n",
    "            evaluated by adjusted R-squared\n",
    "        \"\"\"\n",
    "        data=pd.merge(self.predicotres, self.outcome,left_index=True, right_index=True)\n",
    "        response=self.outcome.columns[0]\n",
    "\n",
    "        remaining = set(data.columns)\n",
    "        remaining.remove(response)\n",
    "        selected = []\n",
    "        current_score, best_new_score = 0.0, 0.0\n",
    "        while remaining and current_score == best_new_score:\n",
    "            scores_with_candidates = []\n",
    "            for candidate in remaining:\n",
    "                formula = \"{} ~ {} + 1\".format(response,\n",
    "                                            ' + '.join(selected + [candidate]))\n",
    "                score = ols(formula, data).fit().rsquared_adj\n",
    "                scores_with_candidates.append((score, candidate))\n",
    "            scores_with_candidates.sort()\n",
    "            best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "            if current_score < best_new_score:\n",
    "                remaining.remove(best_candidate)\n",
    "                selected.append(best_candidate)\n",
    "                current_score = best_new_score\n",
    "        formula = \"{} ~ {} + 1\".format(response,\n",
    "                                    ' + '.join(selected))\n",
    "        model = ols(formula, data).fit()\n",
    "\n",
    "        print (f\"Formula: {model.model.formula}\")\n",
    "        print (f\"Ajuste por R2: {model.rsquared_adj}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def weighted_regression(self, weights):\n",
    "        X = self.predicotres.values\n",
    "        y = self.outcome.values\n",
    "        w = weights.values\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y, sample_weight=w)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def codificar_catego(self,modelo,cate_var:str):\n",
    "        self['residuos']=(self.outcome-modelo.predict(self.predicotres))\n",
    "        self['residuos']\n",
    "        self[cate_var]= self[cate_var]\n",
    "        grupos1_aux= pd.merge(self[cate_var], self['residuos'],left_index=True, right_index=True)\n",
    "        grupos1_agrupado=grupos1_aux.groupby([cate_var])\n",
    "\n",
    "        summary_function = lambda x: {\n",
    "            cate_var: x.iloc[0,0],\n",
    "            'count': len(x),\n",
    "            'residuo_medio': x.residuos.median()\n",
    "        }\n",
    "        \n",
    "        group_summaries = grupos1_agrupado.apply(summary_function)\n",
    "        final_df = pd.DataFrame([    *group_summaries])\n",
    "        grupos1 = final_df.sort_values('residuo_medio')\n",
    "        grupos1['cum_count']=np.cumsum(grupos1['count'])\n",
    "        grupos1['Col_a_codificar_grupos']=pd.qcut(grupos1['cum_count'],5,labels=False,retbins=False)\n",
    "        to_join= grupos1[[cate_var,'Col_a_codificar_grupos']].set_index(cate_var)\n",
    "\n",
    "        self=self.join(to_join, on=cate_var)\n",
    "        return (self[[cate_var,'Col_a_codificar_grupos']])\n",
    "    \n",
    "    def regre_con_interaccion_de_var(self,outcome,predictores,lista_predictores_condicionados):\n",
    "        frase=outcome+\" ~\"\n",
    "        frase_aux1=\"\"\n",
    "        frase_aux2=\"\"\n",
    "        aux=0\n",
    "        for i, j in lista_predictores_condicionados:\n",
    "            if aux==0:\n",
    "                frase_aux1=i+\"*\"+j\n",
    "            else:\n",
    "                frase_aux1=frase_aux1+\"+\"+i+\"*\"+j\n",
    "            aux=aux+1\n",
    "        for i in predictores:\n",
    "            frase_aux2=frase_aux2+\"+\"+i\n",
    "        frase=frase+frase_aux1+frase_aux2\n",
    "        print(f\" Formula final: {frase} \\n\\n\")\n",
    "        model=smf.ols(formula= frase,data=self )\n",
    "        results=model.fit()\n",
    "        return results.summary()\n",
    "    \n",
    "\n",
    "    def regre_outliers(self, cate=None, grupo=None):\n",
    "\n",
    "        if cate==None:\n",
    "            ej_outliers=sm.OLS(self.outcome, self.predicotres.assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "\n",
    "            influence=OLSInfluence(resul_1)\n",
    "            sresiduals= influence.resid_studentized_internal\n",
    "\n",
    "            outliers=self.loc[sresiduals.idxmin(), :]\n",
    "            print(\"resultado\", outliers[list(self.outcome.columns)])\n",
    "            print(outliers[list(self.predicotres.columns)])\n",
    "\n",
    "\n",
    "            print(\"puntos con alta influencia y distancia de Cooks mayor de 0.08\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            ax.axhline(-2.5, linestyle='--', color='C1')\n",
    "            ax.axhline(2.5, linestyle='--', color='C1')\n",
    "            ax.scatter(influence.hat_matrix_diag, \n",
    "                    influence.resid_studentized_internal,\n",
    "                    s=1000*np.sqrt(influence.cooks_distance[0]), \n",
    "                    alpha=0.5)\n",
    "            ax.set_xlabel('hat values')\n",
    "            ax.set_ylabel('studentized residuals')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            print(\"predictores vs residuos para ver heteroskedascity\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            df = pd.DataFrame({'fitted': resul_1.fittedvalues, \n",
    "                            'residuals': np.abs(resul_1.resid)})\n",
    "            sns.regplot(x='fitted', y='residuals', data=df, scatter_kws={'alpha':0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax)\n",
    "            ax.set_xlabel('predictos')\n",
    "            ax.set_ylabel('abs(residuos)')\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "            ej_outliers=sm.OLS(datos_agru[list(self.outcome.columns)], datos_agru[list(self.predicotres.columns)].assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "\n",
    "            influence=OLSInfluence(resul_1)\n",
    "            sresiduals= influence.resid_studentized_internal\n",
    "\n",
    "            outliers=datos_agru.loc[sresiduals.idxmin(), :]\n",
    "            print(\"resultado\", outliers[list(self.outcome.columns)])\n",
    "            print(outliers[list(self.predicotres.columns)])\n",
    "\n",
    "            print(\"puntos con alta influencia y distancia de Cooks mayor de 0.08\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            ax.axhline(-2.5, linestyle='--', color='C1')\n",
    "            ax.axhline(2.5, linestyle='--', color='C1')\n",
    "            ax.scatter(influence.hat_matrix_diag, \n",
    "                    influence.resid_studentized_internal,\n",
    "                    s=1000*np.sqrt(influence.cooks_distance[0]), \n",
    "                    alpha=0.5)\n",
    "            ax.set_xlabel('hat values')\n",
    "            ax.set_ylabel('studentized residuals')\n",
    "            plt.show()\n",
    "\n",
    "            print(\"predictores vs residuos para ver heteroskedascity\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            df = pd.DataFrame({'fitted': resul_1.fittedvalues, \n",
    "                            'residuals': np.abs(resul_1.resid)})\n",
    "            sns.regplot(x='fitted', y='residuals', data=df, scatter_kws={'alpha':0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax)\n",
    "            ax.set_xlabel('predictos')\n",
    "            ax.set_ylabel('abs(residuos)')\n",
    "            plt.show()\n",
    "\n",
    "    def infl_residual_modelo(self, var_influ, cate=None, grupo=None):\n",
    "        if cate==None:\n",
    "            ej_outliers=sm.OLS(self.outcome, self.predicotres.assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "            sm.graphics.plot_ccpr(resul_1,var_influ)\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fig = sm.graphics.plot_ccpr_grid(resul_1, fig=fig)\n",
    "        \n",
    "        else:\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "            ej_outliers=sm.OLS(datos_agru[list(self.outcome.columns)], datos_agru[list(self.predicotres.columns)].assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "            sm.graphics.plot_ccpr(resul_1,var_influ)\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fig = sm.graphics.plot_ccpr_grid(resul_1, fig=fig)\n",
    "\n",
    "    def regre_poly(self,variables_exp,expo,cate=None, grupo=None,verbose=False):\n",
    "\n",
    "        if cate==None:\n",
    "\n",
    "            out=list(self.outcome.columns)\n",
    "            predic=list(self.predicotres.columns)\n",
    "\n",
    "            frase=out[0]+\" ~ \"\n",
    "            variables_no_exp = [element for element in predic if element not in variables_exp]\n",
    "            frase_expo=\"\"\n",
    "            frase_no_expo=\"\"\n",
    "\n",
    "            for i,j in zip(variables_exp,expo):\n",
    "                frase_expo=frase_expo + f\"np.power({i}, {j}) + \" \n",
    "\n",
    "            for indice,i in enumerate(variables_no_exp):\n",
    "                if indice == len(variables_no_exp)-1:\n",
    "                    frase_no_expo=frase_no_expo+i    \n",
    "                else: \n",
    "                    frase_no_expo=frase_no_expo+i+ \"+\"   \n",
    "\n",
    "            frase=frase+frase_expo+frase_no_expo\n",
    "            print(frase)\n",
    "            \n",
    "            model_poly = smf.ols(formula=frase, data=self)\n",
    "            result_poly = model_poly.fit()\n",
    "            if (verbose):\n",
    "             print(result_poly.summary())\n",
    "\n",
    "        else:\n",
    "\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "\n",
    "            out=list(self.outcome.columns)\n",
    "            predic=list(self.predicotres.columns)\n",
    "\n",
    "            frase=out[0]+\" ~ \"\n",
    "            variables_no_exp = [element for element in predic if element not in variables_exp]\n",
    "            frase_expo=\"\"\n",
    "            frase_no_expo=\"\"\n",
    "\n",
    "            for i,j in zip(variables_exp,expo):\n",
    "                frase_expo=frase_expo + f\"np.power({i}, {j}) + \" \n",
    "\n",
    "            for indice,i in enumerate(variables_no_exp):\n",
    "                if indice == len(variables_no_exp)-1:\n",
    "                    frase_no_expo=frase_no_expo+i    \n",
    "                else: \n",
    "                    frase_no_expo=frase_no_expo+i+ \"+\"   \n",
    "\n",
    "            frase=frase+frase_expo+frase_no_expo\n",
    "            print(frase)\n",
    "            \n",
    "            model_poly = smf.ols(formula=frase, data=datos_agru)\n",
    "            result_poly = model_poly.fit()\n",
    "            if (verbose):\n",
    "                print(result_poly.summary())\n",
    "\n",
    "        return result_poly\n",
    "        \n",
    "\n",
    "    def partialResidualPlot(self, model, feature):\n",
    "        df= pd.merge(self.predicotres, self.outcome, left_index=True, right_index=True)\n",
    "        outcome= list(self.outcome.columns)\n",
    "\n",
    "        y_pred = model.predict(df)\n",
    "        copy_df = df.copy()\n",
    "        for c in copy_df.columns:\n",
    "            if c == feature:\n",
    "                continue\n",
    "            copy_df[c] = 0.0\n",
    "        feature_prediction = model.predict(copy_df)\n",
    "        \n",
    "        \n",
    "        residual=df[outcome].values - y_pred.values\n",
    "        results = pd.DataFrame({\n",
    "            'feature': df[feature].values,\n",
    "            'residual': residual[0],\n",
    "            'ypartial': feature_prediction.values - model.params[0],\n",
    "        })\n",
    "\n",
    "        results = results.sort_values(by=['feature'])\n",
    "        smoothed = sm.nonparametric.lowess(results.ypartial, results.feature, frac=1/3)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "        ax.scatter(results.feature, results.ypartial + results.residual)\n",
    "        ax.plot(smoothed[:, 0], smoothed[:, 1], color='gray')\n",
    "        ax.plot(results.feature, results.ypartial, color='black')\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(f'Residual + {feature} contribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def plot_partial_residuals_poly(self,variables_exp,expo,variable ,cate=None, grupo=None):\n",
    "        model=self.regre_poly(variables_exp,expo,cate, grupo)\n",
    "        self.partialResidualPlot(model,variable)\n",
    "\n",
    "    \n",
    "    def clasificador_bayes(self,predictores,outcome,new):\n",
    "        X =self[predictores]\n",
    "        y = self[outcome]\n",
    "\n",
    "        naive_model = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "        naive_model = MultinomialNB(alpha=1e-10, fit_prior=False)\n",
    "        naive_model.fit(X, y)\n",
    "\n",
    "        print(\"Input en el modelo bayesiano: \")\n",
    "        print(new)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print('Clase más probable: ', naive_model.predict(new)[0])\n",
    "\n",
    "        probabilities = pd.DataFrame(naive_model.predict_proba(new),columns=naive_model.classes_)\n",
    "        print('Probabilidades de cada clase:',)\n",
    "        print(probabilities)\n",
    "\n",
    "    def accuracy_bayes(self,predictores,outcome):\n",
    "        X =self[predictores]\n",
    "        y = self[outcome]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        modelo_gausian = GaussianNB()\n",
    "        \n",
    "        modelo_gausian .fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo_gausian .predict(X_test)\n",
    "\n",
    "        precision_gausian  = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"La precisión del modelo gaussiano de bayes es: {precision_gausian }\")\n",
    "\n",
    "        modelo_multino=MultinomialNB()\n",
    "\n",
    "        modelo_multino.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo_multino.predict(X_test)\n",
    "\n",
    "        precision_multino = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"La precisión del modelo multinomial de bayes es: {precision_multino}\")\n",
    "\n",
    "    def predict_lda(self,predictors,outcome):\n",
    "        X=self[predictors]\n",
    "        y=self[outcome]\n",
    "\n",
    "        modelo_lda = LinearDiscriminantAnalysis()\n",
    "        modelo_lda.fit(X, y)\n",
    "        y_pred = modelo_lda.predict(X)\n",
    "\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        print(\"Accuracy modelo LDA:\", accuracy)\n",
    "\n",
    "    def GLM_datos(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "\n",
    "            logit_reg_sm = sm.GLM(y, X.assign(const=1), \n",
    "                                family=sm.families.Binomial())\n",
    "            logit_result = logit_reg_sm.fit()\n",
    "            print(logit_result.summary())\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "\n",
    "    def GLM_datos_formula(self,predictors,outcome,formula):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            data=pd.merge(y, X,left_index=True, right_index=True)\n",
    "            model = glm(formula=formula, data=data, family=sm.families.Binomial())\n",
    "            results = model.fit()\n",
    "            print(results.summary())\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "\n",
    "    def mat_conf(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            logit_reg = LogisticRegression(penalty='l2', C=1e42, solver='liblinear')\n",
    "            logit_reg.fit(X, y)\n",
    "\n",
    "            print(' - Intercept ', logit_reg.intercept_[0])\n",
    "            print(' - Classes', logit_reg.classes_)\n",
    "            pd.DataFrame({'coeff': logit_reg.coef_[0]}, \n",
    "                        index=X.columns)\n",
    "\n",
    "            # Confusion matrix\n",
    "            pred = logit_reg.predict(X)\n",
    "            pred_y = logit_reg.predict(X) == \"0\"\n",
    "            true_y = y == \"0\"\n",
    "            true_pos = true_y & pred_y\n",
    "            true_neg = ~true_y & ~pred_y\n",
    "            false_pos = ~true_y & pred_y\n",
    "            false_neg = true_y & ~pred_y\n",
    "\n",
    "            conf_mat = pd.DataFrame([[np.sum(true_pos), np.sum(false_neg)], [np.sum(false_pos), np.sum(true_neg)]],\n",
    "                                index=['Y = 0', 'Y = 1'],\n",
    "                                columns=['Yhat = 1', 'Yhat = 0'])\n",
    "            # print(conf_mat)\n",
    "\n",
    "            # print(confusion_matrix(y, logit_reg.predict(X)))\n",
    "            print(\"\\n*******************************\")\n",
    "            classificationSummary(y, logit_reg.predict(X), \n",
    "                                class_names=logit_reg.classes_)\n",
    "            print(\"\\n*******************************\")\n",
    "            \n",
    "            self.prec_sens_espe(predictors,outcome,logit_reg)\n",
    "            self.ROC_curva(predictors,outcome,logit_reg)\n",
    "                        \n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "    \n",
    "    def prec_sens_espe(self,predictors,outcome,logit_reg):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            conf_mat = confusion_matrix(y, logit_reg.predict(X))\n",
    "            print(' - Precision', conf_mat[0, 0] / sum(conf_mat[:, 0]))\n",
    "            print(' - Sensibilidad', conf_mat[0, 0] / sum(conf_mat[0, :]))\n",
    "            print(' - Especificidad', conf_mat[1, 1] / sum(conf_mat[1, :]))\n",
    "\n",
    "            precision_recall_fscore_support(y, logit_reg.predict(X), \n",
    "                                            labels=['0', '1'])\n",
    "            \n",
    "\n",
    "    def ROC_curva(self,predictors,outcome,logit_reg):\n",
    "\n",
    "        y= self[outcome]\n",
    "        X= self[predictors]\n",
    "        fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:, 0], pos_label=0)\n",
    "        roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "        ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(1, 0)\n",
    "        ax.plot((1, 0), (0, 1))\n",
    "        ax.set_xlabel('Especificidad')\n",
    "        ax.set_ylabel('Sensibilidad')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:,0], \n",
    "                                        pos_label=0)\n",
    "        roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "\n",
    "        ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(1, 0)\n",
    "        # ax.plot((1, 0), (0, 1))\n",
    "        ax.set_xlabel('Especificidad')\n",
    "        ax.set_ylabel('Sensibilidad')\n",
    "        ax.fill_between(roc_df.specificity, 0, roc_df.recall, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def oversampling(self,predictors,outcome):\n",
    "        X= self[predictors]\n",
    "        y=self[outcome]\n",
    "        positive_wt = 1 / np.mean(y==1)\n",
    "        # default_wt = 1 / (np.sum(dummys.ES_NO_ES_s)/len(dummys.ES_NO_ES_s))\n",
    "        # default_wt = 1 / np.mean(dummys.ES_NO_ES_s)\n",
    "        wt = [positive_wt if outcome == 1 else 1 for outcome in y]\n",
    "\n",
    "        full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "        full_model.fit(X, y,wt)\n",
    "        print('Porcentaje de valores predichos (weighting): ') \n",
    "        print( 100 * np.mean(full_model.predict(X) == 1) )  \n",
    "\n",
    "    def data_gen(self,predictors,outcome):\n",
    "        X= self[predictors]\n",
    "        y=self[outcome]\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "        print('Porcentaje de elemetos positivos predichos (SMOTE resampled): ', \n",
    "            100 * np.mean(y_resampled == 1))\n",
    "        \n",
    "        full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "        full_model.fit(X_resampled, y_resampled)\n",
    "        print('Porcentaje de elemetos positivos predichos  (SMOTE): ', \n",
    "            100 * np.mean(full_model.predict(X) ==1 ))\n",
    "\n",
    "    def explo_predict(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y=self[outcome]\n",
    "            X=self[predictors]\n",
    "            loan_tree = DecisionTreeClassifier(random_state=1, criterion='entropy', \n",
    "                                            min_impurity_decrease=0.003)\n",
    "            loan_tree.fit(X, y)\n",
    "\n",
    "            loan_lda = LinearDiscriminantAnalysis()\n",
    "            loan_lda.fit(X, y)\n",
    "\n",
    "            logit_reg = LogisticRegression(penalty=\"l2\", solver='liblinear')\n",
    "            logit_reg.fit(X, y)\n",
    "\n",
    "\n",
    "            ## model\n",
    "            gam = LinearGAM(s(0) + s(1))\n",
    "            print(gam.gridsearch(X.values, y.values))\n",
    "\n",
    "            models = {\n",
    "                'Decision Tree': loan_tree,\n",
    "                'Linear Discriminant Analysis': loan_lda,\n",
    "                'Logistic Regression': logit_reg,\n",
    "                'Generalized Additive Model': gam,\n",
    "            }\n",
    "\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(5, 5))\n",
    "\n",
    "            xvalues = np.arange(0.25, 0.73, 0.005)\n",
    "            yvalues = np.arange(-0.1, 20.1, 0.1)\n",
    "            xx, yy = np.meshgrid(xvalues, yvalues)\n",
    "            X = pd.DataFrame({\n",
    "                'Datos_F': xx.ravel(),\n",
    "                'Datos_E': yy.ravel(),\n",
    "            })\n",
    "\n",
    "            boundary = {}\n",
    "\n",
    "            for n, (title, model) in enumerate(models.items()):\n",
    "                ax = axes[n // 2, n % 2]\n",
    "                predict = model.predict(X)\n",
    "                if 'Generalized' in title:\n",
    "                    Z = np.array([1 if z > 0.5 else 0 for z in predict])\n",
    "                else:\n",
    "                    \n",
    "                    Z = np.array([1 if z == 1 else 0 for z in predict])\n",
    "                Z = Z.reshape(xx.shape)\n",
    "                boundary[title] = yvalues[np.argmax(Z > 0, axis=0)]\n",
    "                boundary[title][Z[-1,:] == 0] = yvalues[-1]\n",
    "\n",
    "                c = ax.pcolormesh(xx, yy, Z, cmap='Blues', vmin=0.1, vmax=1.3, shading='auto')\n",
    "                ax.set_title(title)\n",
    "                ax.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            boundary['Datos_F'] = xvalues\n",
    "            boundaries = pd.DataFrame(boundary)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(5, 4))\n",
    "            boundaries.plot(x='Datos_F', ax=ax)\n",
    "            ax.set_ylabel('Datos_E')\n",
    "            ax.set_ylim(0, 20)\n",
    "\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACIÓN DE LA CLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo=DF_exploracion(df_prueba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas._libs.properties.AxisProperty at 0x279450a68f0>"
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.cuanti.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINICIÓN DE LAS VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  ES_NO_ES \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  sexo \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_C \n",
      "|   - Tipo de dato: int32 \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_D \n",
      "|   - Tipo de dato: float64 \n",
      "|   - Valores repetidos: 1000 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_E \n",
      "|   - Tipo de dato: float64 \n",
      "|   - Valores repetidos: 1000 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Poisson_1 \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 12 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Poisson_3 \n",
      "|   - Tipo de dato: int32 \n",
      "|   - Valores repetidos: 21 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Geom \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 5 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_F \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 625 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_G \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 634 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_A \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 6 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_B \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 4 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_C \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 60 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|----------------------------------------------------------------------------------------------------\n",
      "|  TODAS: Index(['ES_NO_ES', 'sexo', 'Datos_C', 'Datos_D', 'Datos_E', 'Datos_Poisson_1',\n",
      "       'Datos_Poisson_3', 'Datos_Geom', 'Datos_F', 'Datos_G', 'Datos_cate_A',\n",
      "       'Datos_cate_B', 'Datos_cate_C'],\n",
      "      dtype='object') \n",
      "|  DICOTOMICAS: ['ES_NO_ES', 'sexo', 'Datos_C'] \n",
      "|  CATEGORICAS: ['Datos_Geom', 'Datos_cate_A', 'Datos_cate_B'] \n",
      "|  CUANTITATIVAS: ['Datos_D', 'Datos_E', 'Datos_Poisson_1', 'Datos_Poisson_3', 'Datos_F', 'Datos_G', 'Datos_cate_C'] \n",
      "|  ELIMINAR: []\n",
      "|----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ejemplo.variables()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de variables dummys a traves de dicotómicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** self.dummy ************\n",
      "\n",
      "     ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  Datos_C_1\n",
      "0             1           0       1       0          1          0\n",
      "1             0           1       1       0          1          0\n",
      "2             0           1       1       0          1          0\n",
      "3             1           0       1       0          0          1\n",
      "4             1           0       1       0          0          1\n",
      "..          ...         ...     ...     ...        ...        ...\n",
      "995           1           0       1       0          1          0\n",
      "996           0           1       1       0          1          0\n",
      "997           1           0       1       0          0          1\n",
      "998           0           1       1       0          0          1\n",
      "999           1           0       0       1          0          1\n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "\n",
      "********************** self.df o todas_las_col() ************\n",
      "\n",
      "    ES_NO_ES sexo  Datos_C   Datos_D   Datos_E  Datos_Poisson_1  \\\n",
      "0          n    h        0 -1.140929 -1.966275                2   \n",
      "1          s    h        0  0.370079 -1.936759                2   \n",
      "2          s    h        0 -0.700380 -1.449648                6   \n",
      "3          n    h        1 -2.145670  0.824539                6   \n",
      "4          n    h        1 -1.185198 -1.119841                2   \n",
      "..       ...  ...      ...       ...       ...              ...   \n",
      "995        n    h        0  0.339738 -0.030168                4   \n",
      "996        s    h        0 -0.782203 -1.824712                8   \n",
      "997        n    h        1 -0.468133  2.370625                5   \n",
      "998        s    h        1 -2.192413 -0.320991                2   \n",
      "999        n    m        1  0.613364  1.330426                5   \n",
      "\n",
      "     Datos_Poisson_3  Datos_Geom  Datos_F  Datos_G Datos_cate_A Datos_cate_B  \\\n",
      "0                  8           2      720      790      Grupo 0      Grupo 2   \n",
      "1                 14           1      852      730      Grupo 0      Grupo 3   \n",
      "2                 11           2      657      370      Grupo 5      Grupo 2   \n",
      "3                  9           1      386      956      Grupo 1      Grupo 2   \n",
      "4                 11           2      373      928      Grupo 3      Grupo 2   \n",
      "..               ...         ...      ...      ...          ...          ...   \n",
      "995               12           3      784      246      Grupo 3      Grupo 3   \n",
      "996                9           2       68      834      Grupo 1      Grupo 1   \n",
      "997               14           1      627      618      Grupo 5      Grupo 3   \n",
      "998               12           1      501      554      Grupo 1      Grupo 0   \n",
      "999                7           1       66      270      Grupo 3      Grupo 0   \n",
      "\n",
      "     Datos_cate_C  ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  \\\n",
      "0              16           1           0       1       0          1   \n",
      "1              14           0           1       1       0          1   \n",
      "2              29           0           1       1       0          1   \n",
      "3              42           1           0       1       0          0   \n",
      "4              26           1           0       1       0          0   \n",
      "..            ...         ...         ...     ...     ...        ...   \n",
      "995            31           1           0       1       0          1   \n",
      "996            12           0           1       1       0          1   \n",
      "997             0           1           0       1       0          0   \n",
      "998             6           0           1       1       0          0   \n",
      "999            11           1           0       0       1          0   \n",
      "\n",
      "     Datos_C_1  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            1  \n",
      "4            1  \n",
      "..         ...  \n",
      "995          0  \n",
      "996          0  \n",
      "997          1  \n",
      "998          1  \n",
      "999          1  \n",
      "\n",
      "[1000 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "ejemplo.limpiar_dummys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES_NO_ES</th>\n",
       "      <th>sexo</th>\n",
       "      <th>Datos_C</th>\n",
       "      <th>Datos_D</th>\n",
       "      <th>Datos_E</th>\n",
       "      <th>Datos_Poisson_1</th>\n",
       "      <th>Datos_Poisson_3</th>\n",
       "      <th>Datos_Geom</th>\n",
       "      <th>Datos_F</th>\n",
       "      <th>Datos_G</th>\n",
       "      <th>Datos_cate_A</th>\n",
       "      <th>Datos_cate_B</th>\n",
       "      <th>Datos_cate_C</th>\n",
       "      <th>ES_NO_ES_n</th>\n",
       "      <th>ES_NO_ES_s</th>\n",
       "      <th>sexo_h</th>\n",
       "      <th>sexo_m</th>\n",
       "      <th>Datos_C_0</th>\n",
       "      <th>Datos_C_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.140929</td>\n",
       "      <td>-1.966275</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>720</td>\n",
       "      <td>790</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>-1.936759</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>852</td>\n",
       "      <td>730</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.700380</td>\n",
       "      <td>-1.449648</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>657</td>\n",
       "      <td>370</td>\n",
       "      <td>Grupo 5</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.145670</td>\n",
       "      <td>0.824539</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>386</td>\n",
       "      <td>956</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.185198</td>\n",
       "      <td>-1.119841</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>373</td>\n",
       "      <td>928</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339738</td>\n",
       "      <td>-0.030168</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>784</td>\n",
       "      <td>246</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.782203</td>\n",
       "      <td>-1.824712</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>834</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.468133</td>\n",
       "      <td>2.370625</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>627</td>\n",
       "      <td>618</td>\n",
       "      <td>Grupo 5</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.192413</td>\n",
       "      <td>-0.320991</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>501</td>\n",
       "      <td>554</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613364</td>\n",
       "      <td>1.330426</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>270</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ES_NO_ES sexo  Datos_C   Datos_D   Datos_E  Datos_Poisson_1  \\\n",
       "0          n    h        0 -1.140929 -1.966275                2   \n",
       "1          s    h        0  0.370079 -1.936759                2   \n",
       "2          s    h        0 -0.700380 -1.449648                6   \n",
       "3          n    h        1 -2.145670  0.824539                6   \n",
       "4          n    h        1 -1.185198 -1.119841                2   \n",
       "..       ...  ...      ...       ...       ...              ...   \n",
       "995        n    h        0  0.339738 -0.030168                4   \n",
       "996        s    h        0 -0.782203 -1.824712                8   \n",
       "997        n    h        1 -0.468133  2.370625                5   \n",
       "998        s    h        1 -2.192413 -0.320991                2   \n",
       "999        n    m        1  0.613364  1.330426                5   \n",
       "\n",
       "     Datos_Poisson_3  Datos_Geom  Datos_F  Datos_G Datos_cate_A Datos_cate_B  \\\n",
       "0                  8           2      720      790      Grupo 0      Grupo 2   \n",
       "1                 14           1      852      730      Grupo 0      Grupo 3   \n",
       "2                 11           2      657      370      Grupo 5      Grupo 2   \n",
       "3                  9           1      386      956      Grupo 1      Grupo 2   \n",
       "4                 11           2      373      928      Grupo 3      Grupo 2   \n",
       "..               ...         ...      ...      ...          ...          ...   \n",
       "995               12           3      784      246      Grupo 3      Grupo 3   \n",
       "996                9           2       68      834      Grupo 1      Grupo 1   \n",
       "997               14           1      627      618      Grupo 5      Grupo 3   \n",
       "998               12           1      501      554      Grupo 1      Grupo 0   \n",
       "999                7           1       66      270      Grupo 3      Grupo 0   \n",
       "\n",
       "     Datos_cate_C  ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  \\\n",
       "0              16           1           0       1       0          1   \n",
       "1              14           0           1       1       0          1   \n",
       "2              29           0           1       1       0          1   \n",
       "3              42           1           0       1       0          0   \n",
       "4              26           1           0       1       0          0   \n",
       "..            ...         ...         ...     ...     ...        ...   \n",
       "995            31           1           0       1       0          1   \n",
       "996            12           0           1       1       0          1   \n",
       "997             0           1           0       1       0          0   \n",
       "998             6           0           1       1       0          0   \n",
       "999            11           1           0       0       1          0   \n",
       "\n",
       "     Datos_C_1  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  \n",
       "..         ...  \n",
       "995          0  \n",
       "996          0  \n",
       "997          1  \n",
       "998          1  \n",
       "999          1  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo.df\n",
    "# ejemplo.cuanti\n",
    "# ejemplo.dummy\n",
    "# ejemplo.dico\n",
    "ejemplo.df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de variables agrupadas automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datos con distribución discreta: ['Datos_C', 'Datos_Poisson_1', 'Datos_Poisson_3', 'Datos_Geom', 'Datos_F', 'Datos_G', 'Datos_cate_C']\n",
      "Datos de tipos string seguramente: ['ES_NO_ES', 'sexo', 'Datos_cate_A', 'Datos_cate_B']\n"
     ]
    }
   ],
   "source": [
    "print(f\" Datos con distribución discreta: {ejemplo.discreta}\")\n",
    "print(f\"Datos de tipos string seguramente: {ejemplo.stingg}\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTADISTICA DESCRIPTIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.estadistica_descriptiva_cuantis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.estadistica_descriptiva_cualis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.cross_var_cualis_con_ciantis()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables normales y no normales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.normalidad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación normal por categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.normal_grupos_cate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación normalidad por dicotomicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.normal_grupos_dico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitar outlayers e inputar datos en columnas variables cuantitativas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.remove_outliers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar a distribuciones variables cuantitativas (No puede haber nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.comparar_distribuciones_caunti_cont()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar a distribuciones variables discretas (No puede haber nulos) (Solo poisson y binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.fit_discrete(df_prueba[\"Datos_Poisson_1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejemplo.todos_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_bigotes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_barras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.violines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_normailidad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ESTADISTICOS NO MULTIVARIANTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables cualitativas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.Chi()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables cuantitativas no pareadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.t_test_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilconxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.wilconxon( [\"sexo\",\"Datos_D\" ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.anova()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_confidence_interval(\"Datos_D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictores=['Datos_D','Datos_E','Datos_F']\n",
    "# OUTCOME=['Datos_G']\n",
    "\n",
    "# modelo=ejemplo.reg_lineal(predictores,OUTCOME)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables predictoras en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.forward_selected()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal por pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights=ejemplo[\"Datos_Poisson_1\"]\n",
    "# ejemplo.weighted_regression( weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificar variables categoricas si son muy largas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # si tienes variables con muchas categorias pues \n",
    "    # tendrías un monton de dummys y no es la cosa tampoco \n",
    "    # que va a parecer esto un sudoku (es que además pueden incluso ser practicamente iguales)\n",
    "    # Entonces los puedes codificar usando los residuos de la regresión\n",
    "    # DESPUES NO SE GUARDA COL_A_CODIFICAR_GRUPOS!!!\n",
    "\n",
    "# ejemplo.codificar_catego(modelo,'Datos_cate_C')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadir en el modelo variables correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # interacciones entre variables que entre ellas hacen efecto en el outcome\n",
    "\n",
    "# predictores=[\"Datos_E\",\"Datos_F\"]\n",
    "# lista_predictores_condicionados=[[\"Datos_D\",\"Datos_E\"],[\"Datos_Poisson_1\",\"Datos_Poisson_3\"]]\n",
    "# outcome=\"Datos_G\"\n",
    "# ejemplo.regre_con_interaccion_de_var(outcome,predictores,lista_predictores_condicionados)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Outliers no es lo mismo que en la distribución porque aqui se usa el \n",
    "\n",
    "# ejemplo.regre_outliers(cate=\"Datos_cate_C\",grupo=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuos parciales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # residuos parciales \n",
    "\n",
    "    # La función sm.graphics.plot_ccpr de la biblioteca statsmodels es una función para \n",
    "    # crear un gráfico de la influencia residual del modelo lineal. \n",
    "    # La función toma como argumentos un objeto de resultado de modelo lineal (resul_1) \n",
    "    # y un nombre de variable independiente ('Datos_F').\n",
    "\n",
    "    # El gráfico de influencia residual se utiliza para evaluar la influencia de cada \n",
    "    # punto en el ajuste del modelo lineal. En la gráfica, los ejes representan las \n",
    "    # predicciones del modelo y los residuales absolutos respectivamente. \n",
    "    # Los puntos son una representación de cada observación en el conjunto de datos, \n",
    "    # con la posición de cada punto indicando la influencia de esa observación en el modelo.\n",
    "\n",
    "    # El gráfico de influencia residual se utiliza para detectar outliers y puntos \n",
    "    # con influencia anormal en el modelo lineal. Si un punto tiene una influencia \n",
    "    # anormal en el modelo, puede ser necesario revisar ese punto en el conjunto de datos \n",
    "    # y considerar si debería ser incluido o excluido del modelo.\n",
    "\n",
    "    # En general, un gráfico de influencia residual es una herramienta útil para \n",
    "    # comprender la calidad del ajuste del modelo lineal y para detectar posibles \n",
    "    # problemas en los datos o en el modelo.\n",
    "\n",
    "# ejemplo.infl_residual_modelo(var_influ='Datos_F', cate=\"Datos_cate_C\",grupo=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_exp=[\"Datos_E\",\"Datos_F\"]\n",
    "# expo=[2,3]\n",
    "\n",
    "# ejemplo.regre_poly(variables_exp,expo, cate=\"Datos_cate_C\",grupo=1,verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot de residuos parciales con regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_exp=[\"Datos_E\",\"Datos_F\"]\n",
    "# expo=[2,3]\n",
    "# grupo=1\n",
    "# variable=\"Datos_F\"\n",
    "# cate=\"Datos_cate_C\"\n",
    "\n",
    "# ejemplo.plot_partial_residuals_poly(variables_exp,expo,variable ,cate, grupo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input en el modelo bayesiano: \n",
      "   Datos_Poisson_3  Datos_Poisson_1  Datos_Geom\n",
      "3                9                6           1\n",
      "\n",
      "\n",
      "Clase más probable:  Grupo 5\n",
      "Probabilidades de cada clase:\n",
      "    Grupo 0   Grupo 1   Grupo 2   Grupo 3   Grupo 4   Grupo 5\n",
      "0  0.158733  0.171391  0.161393  0.145646  0.178419  0.184417\n"
     ]
    }
   ],
   "source": [
    "predictors=['Datos_Poisson_3','Datos_Poisson_1','Datos_Geom']\n",
    "outcome=['Datos_cate_A']\n",
    "\n",
    "#LOS PREDICTORES TODOS EN NÚMEROS, SI SON DICO SE PASAN A DUMMYS\n",
    "# Naive porque predictores independientes \n",
    "\n",
    "ejemplo.clasificador_bayes(predictors,outcome,df_prueba[predictors].loc[3:3, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo gaussiano de bayes es: 0.14\n",
      "La precisión del modelo multinomial de bayes es: 0.164\n"
     ]
    }
   ],
   "source": [
    "ejemplo.accuracy_bayes(predictors,outcome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy modelo LDA: 0.525\n"
     ]
    }
   ],
   "source": [
    "# limitado al número de filas, da igual cuantos predictores mientras \n",
    "# distribución normal pero vamos que puede valer para todo\n",
    "# Outcome categorico \n",
    "\n",
    "predictors=['Datos_Poisson_3','Datos_Geom']\n",
    "outcome=['sexo']\n",
    "\n",
    "ejemplo.predict_lda(predictors,outcome)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_NO_ES_n\n",
      "ES_NO_ES_s\n",
      "sexo_h\n",
      "sexo_m\n",
      "Datos_C_0\n",
      "Datos_C_1\n"
     ]
    }
   ],
   "source": [
    "for i in list(ejemplo.dummy.columns): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ES_NO_ES_s   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      995\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -689.18\n",
      "Date:                Tue, 21 Mar 2023   Deviance:                       1378.4\n",
      "Time:                        23:10:06   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.007860\n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Datos_Poisson_3     0.0279      0.020      1.384      0.166      -0.012       0.067\n",
      "Datos_Geom          0.2271      0.101      2.248      0.025       0.029       0.425\n",
      "Datos_F            -0.0002      0.000     -0.916      0.359      -0.001       0.000\n",
      "Datos_E            -0.0081      0.062     -0.131      0.896      -0.129       0.113\n",
      "const              -0.4676      0.268     -1.744      0.081      -0.993       0.058\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# solo se puede variables dummys (0 y 1)\n",
    "predictors=['Datos_Poisson_3','Datos_Geom',\"Datos_F\",\"Datos_E\"]\n",
    "\n",
    "ejemplo.GLM_datos(predictors,'ES_NO_ES_s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ES_NO_ES_s   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      987\n",
      "Model Family:                Binomial   Df Model:                           12\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -685.21\n",
      "Date:                Tue, 21 Mar 2023   Deviance:                       1370.4\n",
      "Time:                        23:10:06   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):            0.01571\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -0.8148      0.854     -0.954      0.340      -2.488       0.858\n",
      "bs(Datos_F, df=8)[0]     1.3506      0.902      1.498      0.134      -0.417       3.118\n",
      "bs(Datos_F, df=8)[1]    -0.0753      0.605     -0.124      0.901      -1.262       1.111\n",
      "bs(Datos_F, df=8)[2]     0.9778      0.713      1.372      0.170      -0.419       2.374\n",
      "bs(Datos_F, df=8)[3]     0.9078      0.620      1.465      0.143      -0.307       2.123\n",
      "bs(Datos_F, df=8)[4]     0.6454      0.664      0.972      0.331      -0.656       1.947\n",
      "bs(Datos_F, df=8)[5]     0.8139      0.705      1.155      0.248      -0.567       2.195\n",
      "bs(Datos_F, df=8)[6]     0.2034      0.777      0.262      0.794      -1.319       1.726\n",
      "bs(Datos_F, df=8)[7]     0.0603      0.658      0.092      0.927      -1.229       1.350\n",
      "Datos_Poisson_3          0.0273      0.020      1.342      0.179      -0.013       0.067\n",
      "bs(Datos_E, df=3)[0]    -0.5506      1.547     -0.356      0.722      -3.584       2.482\n",
      "bs(Datos_E, df=3)[1]     0.8775      0.676      1.298      0.194      -0.448       2.203\n",
      "bs(Datos_E, df=3)[2]    -1.1501      1.170     -0.983      0.326      -3.443       1.143\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "formula = ('ES_NO_ES_s ~ bs(Datos_F, df=8) + ' +\n",
    "            'Datos_Poisson_3 + bs(Datos_E, df=3)')\n",
    "ejemplo.GLM_datos_formula(predictors,'ES_NO_ES_s',formula)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión + curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Intercept  -0.4676027491548773\n",
      " - Classes [0 1]\n",
      "\n",
      "*******************************\n",
      "Confusion Matrix (Accuracy 0.5370)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 296 201\n",
      "     1 262 241\n",
      "\n",
      "*******************************\n",
      " - Precision 0.5304659498207885\n",
      " - Sensibilidad 0.5955734406438632\n",
      " - Especificidad 0.47912524850894633\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ejemplo.mat_conf(predictors,'ES_NO_ES_s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos no balanceados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Undersample: usar un numero menor de datos de las clases mas prevalentes\n",
    "- Oversample: Usar más datos de la clase rara, bootstrapping\n",
    "- up weight y downweight: Darle más peso a la clase rara o menos a la clase más prev.\n",
    "- Data generation: Parecifo al bootstrapping \n",
    "- z- core: el valor resultante despúes de la estandarización \n",
    "- k:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling y pesos up/downs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de valores predichos (weighting): \n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "ejemplo.oversampling(predictors,'ES_NO_ES_s')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de elemetos positivos predichos (SMOTE resampled):  50.0\n",
      "Porcentaje de elemetos positivos predichos  (SMOTE):  41.699999999999996\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ejemplo.data_gen(predictors,'ES_NO_ES_s')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploración de predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 27% (3 of 11) |######                   | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 81% (9 of 11) |####################     | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearGAM(callbacks=[Deviance(), Diffs()], fit_intercept=True, \n",
      "   max_iter=100, scale=None, terms=s(0) + s(1) + intercept, \n",
      "   tol=0.0001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "predictors=[\"Datos_F\",\"Datos_E\"]\n",
    "\n",
    "ejemplo.explo_predict(predictors,'ES_NO_ES_n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "609973a2d1f31d45d1c4d9f5c0b4ecf9cb33fe1a555b03392724c0cdbb5c54ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
