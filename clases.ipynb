{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import inspect\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from pygam import LinearGAM, s, f, l\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as stats2\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from statsmodels.formula.api import ols,glm\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error,r2_score, confusion_matrix, precision_recall_fscore_support,roc_curve, accuracy_score, roc_auc_score\n",
    "from dmba import stepwise_selection,AIC_score,classificationSummary\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prueba = pd.DataFrame({\n",
    "\"ES_NO_ES\":[np.random.choice(['s','n']) for _ in range(1000)],\n",
    "\"sexo\":[np.random.choice(['h','m']) for _ in range(1000)],\n",
    "\"Datos_C\":[np.random.choice([0,1]) for _ in range(1000)],\n",
    "\"Datos_D\": list(np.random.standard_normal(1000)),\n",
    "\"Datos_E\": list(np.random.standard_normal(1000)),\n",
    "\"Datos_Poisson_1\": list( stats.poisson.rvs(mu=4, size=1000)),\n",
    "\"Datos_Poisson_3\": list( np.random.poisson(lam=10, size=1000)),\n",
    "\"Datos_Geom\": list( stats.geom.rvs(0.75, size=1000)),\n",
    "\"Datos_F\": [np.random.randint(0,1000) for _ in range(1000)],\n",
    "\"Datos_G\": [np.random.randint(0,1000) for _ in range(1000)],\n",
    "\"Datos_cate_A\": ['Grupo '+str(np.random.randint(0,6)) for _ in range(1000)],\n",
    "\"Datos_cate_B\": ['Grupo '+str(np.random.randint(0,4)) for _ in range(1000)],\n",
    "\"Datos_cate_C\": [np.random.randint(0,60) for _ in range(1000)],\n",
    "\n",
    "})\n",
    "\n",
    "# for i in range(1,6):\n",
    "#     df_prueba['Datos_E'][random.randint(0,23)]=None\n",
    "\n",
    "\n",
    "# for i in range(1,10):\n",
    "#     df_prueba['Datos_F'][random.randint(0,23)]=None\n",
    "\n",
    "# for i in range(0,11):\n",
    "#     df_prueba['Datos_G'][i]=None\n",
    "\n",
    "    \n",
    "lista_de_items= ['Item '+str(np.random.randint(0,6)) for _ in range(30000)]\n",
    "num_fact= 30000\n",
    "\n",
    "def crear_lista (lista):\n",
    "    listafin=[]\n",
    "    for i in range (0,num_fact):\n",
    "        lista_aux=[]\n",
    "        for j in range(1, random.randint(1, 10)):\n",
    "            lista_aux.append(random.choice(lista))\n",
    "        \n",
    "        listafin.append(lista_aux)\n",
    "    \n",
    "    return listafin\n",
    "\n",
    "# facturas=crear_lista(lista_de_items)\n",
    "\n",
    "\n",
    "# df_prueb2 = pd.DataFrame({\n",
    "# \"Items\": lista_de_items,\n",
    "# \"facturas\": facturas,\n",
    "# })\n",
    "\n",
    "# pd.merge(df_prueba, df_prueb2,left_index=True, right_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DF_exploracion(pd.DataFrame):\n",
    "\n",
    "    def __init__(self, *args, **kw):\n",
    "        super(DF_exploracion, self).__init__(*args, **kw)\n",
    "        self.cuanti=pd.DataFrame\n",
    "        self.cuanti_antes_de_outliers_y_inputs=pd.DataFrame\n",
    "        self.cuali=pd.DataFrame\n",
    "        self.dico=pd.DataFrame\n",
    "        self.cate=pd.DataFrame\n",
    "        self.eliminado=pd.DataFrame\n",
    "        self.dummy=pd.DataFrame\n",
    "        self.df=pd.DataFrame\n",
    "        self.df_inputado=pd.DataFrame\n",
    "        self.df_limpio=pd.DataFrame\n",
    "        self.predicotres=pd.DataFrame\n",
    "        self.outcome=pd.DataFrame\n",
    "        # self.outcome_col=self.outcome.columns\n",
    "        self.normal_cuatis=[]\n",
    "        self.normal_grupos_dico=[]\n",
    "        self.normal_grupos_cate=[]\n",
    "        self.discreta=[]\n",
    "        self.stingg=[]\n",
    "        self.outliers_hecho=True\n",
    "        self.porcentaje_nulos_permitido=0.3\n",
    "\n",
    "    def variables(self):\n",
    "\n",
    "        dico=[]\n",
    "        cuantis=[]\n",
    "        categori=[]\n",
    "        eliminar=[]\n",
    "        \n",
    "\n",
    "        for i in self.columns: \n",
    "\n",
    "            try:\n",
    "                datos=self[i].dropna().to_numpy()\n",
    "                discreta=True\n",
    "                for j in datos:\n",
    "                    if (j%1 !=0):\n",
    "                        discreta=False\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                if (discreta):\n",
    "                    self.discreta.append(i)\n",
    "            except:\n",
    "                self.stingg.append(i)\n",
    "\n",
    "            nulos= (self[i].isnull().sum())/len(self[i])\n",
    "            \n",
    "            if ((len(self[i].dropna().unique())==2) and (nulos<=self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: DICOTOMICA\"\n",
    "                dico.append(i)\n",
    "\n",
    "            elif ((len(self[i].dropna().unique())>10) and  (nulos<=self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: CUANTITATIVA\"\n",
    "                cuantis.append(i)\n",
    "\n",
    "            elif ( (len(self[i].dropna().unique())<2) or (nulos>self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"SOLO {len(self[i].dropna().unique())} TIPOS, NO VALE LA COLUMNA\"\n",
    "                eliminar.append(i)\n",
    "            else:\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: CATEGORICA/CUANTI\"\n",
    "                categori.append(i)\n",
    "\n",
    "            print (f\"|  {i} \\n|   - Tipo de dato: {self[i].dtype} \\n|   - Valores repetidos: {tipo_de_var} \\n|   - Nulos: {nulos} \\n| \")\n",
    "\n",
    "        print (f\"|----------------------------------------------------------------------------------------------------\\n|  TODAS: {self.columns} \\n|  DICOTOMICAS: {dico} \\n|  CATEGORICAS: {categori} \\n|  CUANTITATIVAS: {cuantis} \\n|  ELIMINAR: {eliminar}\")\n",
    "        print(\"|----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        self.DF_cuantis(cuantis)\n",
    "        self.DF_cualis(categori+dico)\n",
    "        self.DF_dicotomica(dico)\n",
    "        self.DF_categorica(categori)\n",
    "        self.DF_elimiminado(eliminar)\n",
    "        self.df=self\n",
    "        \n",
    "    def todas_col(self):\n",
    "        return self.df\n",
    "    \n",
    "    def DF_cuantis(self,lista):\n",
    "        self.cuanti=self[lista]\n",
    "\n",
    "    def DF_elimiminado(self,lista):\n",
    "        self.eliminado=self[lista]\n",
    "        \n",
    "    def DF_cualis(self,lista):\n",
    "        self.cuali=self[lista]\n",
    "        \n",
    "    def DF_dicotomica(self, lista):\n",
    "        self.dico=self[lista]\n",
    "        \n",
    "    def DF_categorica(self, lista):\n",
    "        self.cate=self[lista]   \n",
    "\n",
    "\n",
    "\n",
    "    def limpiar_aux(self):\n",
    "        \n",
    "        try:\n",
    "            df_nuevo=pd.DataFrame\n",
    "            aux1=list(self.dico.columns)\n",
    "            aux=[]\n",
    "            df_nuevo=pd.get_dummies(self.df, columns=aux1)\n",
    "            \n",
    "            for columna in df_nuevo.columns:\n",
    "                for variables in list(self.dico.columns):\n",
    "                    if variables in columna:\n",
    "                        aux.append(columna)\n",
    "                    \n",
    "            self.dummy=df_nuevo[aux]\n",
    "            self[aux]=df_nuevo[aux]\n",
    "\n",
    "            # self.df=self.drop(columns=var, axis='columns')\n",
    "            # self.df= self[self.columns.difference(self.dico.columns)]\n",
    "            \n",
    "            print(\"********************** self.dummy ************\\n\")\n",
    "            print(self.dummy)\n",
    "            print(\"\\n********************** self.df o todas_las_col() ************\\n\")\n",
    "            print(self.df)\n",
    "\n",
    "        except:\n",
    "            print(\"---------------------- ERROR -----------------\")\n",
    "\n",
    "\n",
    "\n",
    "    def limpiar_dummys(self):\n",
    "\n",
    "        b=False\n",
    "        lista=list(self.dico.columns)\n",
    "        for ind, i in enumerate(lista):\n",
    "                if (ind+1<len(lista)):\n",
    "                    if( (i in lista [ind+1]) ):\n",
    "                        b=True\n",
    "                        break\n",
    "        if b:\n",
    "            nombres_nuevos=[]\n",
    "            if len(lista)>2:\n",
    "                for ind, i in enumerate(lista):\n",
    "                    if (ind+1<len(lista)):\n",
    "                        if( (i in lista [ind+1]) ):\n",
    "                            nombres_nuevos.append(i.upper())\n",
    "                        else:\n",
    "                            nombres_nuevos.append(i)\n",
    "                    else:\n",
    "                        nombres_nuevos.append(i)\n",
    "                        \n",
    "            aux_df=self.df\n",
    "\n",
    "            for i,j in zip(lista,nombres_nuevos):\n",
    "                aux_df.rename(columns={i:j},inplace=True)\n",
    "                \n",
    "            self.df=aux_df\n",
    "            self.dico.columns=nombres_nuevos\n",
    "            \n",
    "            self.limpiar_aux()\n",
    "        else: \n",
    "            self.limpiar_aux()\n",
    "\n",
    "\n",
    "\n",
    "    def estadistica_descriptiva_cuantis(self):\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\nDESCRIPCIÓN\")\n",
    "        print (self.cuanti.describe())\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\nCUARTILES\")\n",
    "        print (self.cuanti.quantile([0.05,0.25,0.5,0.75,0.95]))\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        # df_auxiliar = self.groupby('sexo').apply(lambda x: pd.Series(shapiro(x), index=['W','P'])).reset_index()\n",
    "        # print(df_auxiliar)\n",
    "                \n",
    "        for a in list(aux1.values):\n",
    "            \n",
    "            for b in list(aux.values):\n",
    "                \n",
    "                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                agrupado=self.groupby(a)[b]\n",
    "                titulo=f\"Agrupado por {a} y por {b}\"\n",
    "                print(titulo)\n",
    "                print(agrupado.describe().reset_index())\n",
    "                # df.groupby(['cat1', 'cat2'])['purchases','sales'].apply(stats.shapiro)\n",
    "                print(\"////////////////////////// TEST DE SHAPIRO ////////////////////////////\")\n",
    "                aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                print(aux_shapiro)\n",
    "        \n",
    "                \n",
    "                print(\"\\n\")\n",
    "                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "    def estadistica_descriptiva_cualis(self):\n",
    "\n",
    "        print(\"\\n--------------------- Variables dico ---------------------\")\n",
    "        print(\"\\n\")\n",
    "        for i in self.dico.columns:\n",
    "            print(f\"...........Frecuencia variable {i} ....................\")\n",
    "            print(self[i].value_counts()/(self[i].count()))\n",
    "            print(\"\\n\")\n",
    "\n",
    "        print(\"\\n-------------------- Variables categoricas --------------------\")\n",
    "        print(\"\\n\")\n",
    "        for i in self.cate.columns:\n",
    "            print(f\"...........Frecuencia variable {i} ....................\")\n",
    "            print(self[i].value_counts()/(self[i].count()))\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # crosstab variables cualis con cate\n",
    "        aux=list(self.cate.columns)\n",
    "\n",
    "        a=0\n",
    "        for i in aux:\n",
    "            a=a+1\n",
    "            if a<len(aux)/2:\n",
    "                b=0\n",
    "                for j in aux[:-1]:\n",
    "                    b=b+1\n",
    "                    if b > a:\n",
    "                        print(f\"*************** TABAL DE VARIABLES CATEGORICAS {i} y {j} *********************\\n \")\n",
    "                        tab = pd.crosstab (index=self[i], columns=self[j])\n",
    "                        x=(tab/tab.sum())\n",
    "                        print(tab)\n",
    "                        print(\"\\n\")\n",
    "                        print(f\"/////////////////// EN PROPORCION //////////////////\\n\")\n",
    "                        print(x)\n",
    "                        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    def anova(self):\n",
    "\n",
    "        aux_cate=list(self.cate.columns)\n",
    "        aux_cuati=list(self.cuanti.columns)\n",
    "\n",
    "        for i in aux_cate:\n",
    "            for j in aux_cuati:\n",
    "                try:\n",
    "                    print(f\"\\n----------- ANOVA Categoria {i} y variable continua {j} ----------\\n\")\n",
    "                    model = ols(f\"{j} ~ {i}\", data=self).fit()\n",
    "                    a=sm.stats.anova_lm(model, typ=2)\n",
    "                    print(a)\n",
    "                except:\n",
    "                    print(f\"\\n - - - - - Fallo en variable {i} y {j} - - - - - - \\n\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Chi(self):\n",
    "\n",
    "        aux_dico=list(self.dico.columns)\n",
    "\n",
    "        if len(aux_dico)>1:\n",
    "            for ind, i in enumerate(aux_dico):\n",
    "                for j in range(ind+1,len(aux_dico)):\n",
    "                    chi, p, dof, expected = stats.chi2_contingency(pd.crosstab(self[i],self[aux_dico[j]]), correction=False)\n",
    "                    print(f\"\\n-------------- Chi2 entre {i} y {aux_dico[j]} ----------------\")\n",
    "                    print(f\"p: {p} \\n\") \n",
    "        else:\n",
    "            print(\"******************** No suficientes argumentos ********************\")\n",
    "\n",
    "\n",
    "    def t_test_aux(self, columns):\n",
    "        results = []\n",
    "        for i, col1 in enumerate(columns[:-1]):\n",
    "            for col2 in columns[i+1:]:\n",
    "                t, p = stats.ttest_ind(self[col1].dropna(), self[col2].dropna(), equal_var=False)\n",
    "                # results.append((col1, col2, t, p))\n",
    "                if p < 0.05:\n",
    "                    print( f\"+++++ Variable{col1}, variable 2 {col2} con p de: \\033[1m{p}\\033[0m  Se RECHAZA H0 ++++\") \n",
    "                else:\n",
    "                    print( f\"+++++ Variable{col1}, variable 2 {col2}  con p de: {p} SE ACEPTA H0 ++++\") \n",
    "    \n",
    "    def wilcoxon_test_aux(self,col1, col2):\n",
    "        if (col1== col2).all():\n",
    "            print (\"\\nLas coluimnas son iguales\\n\")\n",
    "        res = stats.wilcoxon(col1, col2)\n",
    "        if res.pvalue < 0.05:\n",
    "            print(f\"Reject null hypothesis. Significant difference  (p-value={res.pvalue:.4f})\")\n",
    "        else:\n",
    "            print (f\"Fail to reject null hypothesis. No significant difference (p-value={res.pvalue:.4f})\")\n",
    "\n",
    "    def wilconxon(self, lista):\n",
    "        # lista=[grupo, var]\n",
    "        a,b=self.agrupar(lista)\n",
    "        print(f\"\\n- Variable: {lista[1]}, Grupo: {lista[0]}\")\n",
    "        self.wilcoxon_test_aux(a, b)\n",
    "\n",
    "    def agrupar (self, lista):\n",
    "        groupby_col=lista[0]\n",
    "        col=lista[1]\n",
    "        valor=self[groupby_col].unique()\n",
    "        group= self.where(self[groupby_col]== valor[0])[col]\n",
    "        group2= self.where(self[groupby_col]== valor[1])[col] \n",
    "        return group,group2\n",
    "\n",
    "    # def t_test_groupby_one_col(self, col, groupby_col):\n",
    "        \n",
    "    #     group= self.where(self[groupby_col]== self[groupby_col][0]).dropna()[col]\n",
    "    #     group2= self.where(self[groupby_col]== self[groupby_col][1]).dropna()[col]\n",
    "    #     t, p = stats.ttest_ind(group, group2, equal_var=False)\n",
    "    #     print( col, groupby_col,p) \n",
    "\n",
    "    def t_test_all(self):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        aux2=list(self.dico.columns)\n",
    "        self.t_test_aux(self.normal_cuatis) #aqui ya hace todas las cuantis entre ellas faltan los grupos\n",
    "        for i in self.normal_grupos_dico:\n",
    "            a,b=self.agrupar(i)\n",
    "            t, p = stats.ttest_ind(a.dropna(), b.dropna(), equal_var=False)\n",
    "            if p < 0.05:\n",
    "                print( f\"+++++ Variable{i[1]}, Agrupado por {i[0]} con p de: \\033[1m{p}\\033[0m  Se RECHAZA H0 ++++\") \n",
    "            else:\n",
    "                print( f\"+++++ Variable{i[1]}, Agrupado por {i[0]} con p de: {p} SE ACEPTA H0 ++++\") \n",
    "    # df_prueba.groupby('sexo').apply(lambda df: stats.ttest_ind(df['Datos_D'].dropna(), df['Datos_E'].dropna())[1])\n",
    "\n",
    "\n",
    "    def plot_confidence_interval(self, col, confidence_level= 0.95):\n",
    "        data = self[col].to_numpy()\n",
    "        n = len(data)\n",
    "        mean =self[col].mean(axis=0)\n",
    "        # std_error = stats.sem( self[col].dropna())\n",
    "        std_error = self[col].dropna().std()\n",
    "        lower_bound = stats.t.ppf(0.025, n - 1, loc = mean, scale = std_error)  # =>  99.23452406698323\n",
    "        upper_bound = stats.t.ppf(0.975, n - 1, loc = mean, scale = std_error)\n",
    "        # h = std_error * stats.t.ppf((1 + confidence_level) / 2, n - 1)\n",
    "        \n",
    "        # lower_bound = mean - h\n",
    "        # upper_bound = mean + h\n",
    "        # plt.hist(data, bins=30, edgecolor='black', alpha=0.5)\n",
    "        # plt.axvspan(lower_bound, upper_bound, color='gray', alpha=0.2, label=f'{confidence_level * 100}% Confidence Interval')\n",
    "        # plt.axvline(x=mean, color='red', label='Sample Mean')\n",
    "        # plt.legend()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(data, bins=30, edgecolor='black', alpha=0.5)\n",
    "        ax.axvline(x=mean, color='red', label='Sample Mean')\n",
    "        ax.axvspan(lower_bound, upper_bound, color='grey', alpha=0.5, label=f'{confidence_level * 100}% Confidence Interval')\n",
    "        ax.annotate(\n",
    "            f'lower_bound:\\n {lower_bound:.2f}',\n",
    "            xy=(lower_bound, 0), xytext=(lower_bound-0.5, 50)\n",
    "        )\n",
    "        ax.annotate(\n",
    "            f'upper_bound:\\n  {upper_bound:.2f}',\n",
    "            xy=(upper_bound, 0), xytext=(upper_bound-0.5, 50)\n",
    "        )\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_normailidad(self):\n",
    "        aux=self.cuanti.columns\n",
    "        for i in aux:\n",
    "            stats.probplot(self[i], dist=\"norm\", plot=plt)\n",
    "            plt.title(\"Probability Plot - \" )\n",
    "            plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    def plot_bigotes(self):\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "        print(\"-------------- Graficas de bigotes cualitativas-------------------\")\n",
    "        # fig = plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        (self.cuanti).plot(kind='box', title='Variables cuantitativas',figsize=(12, 8))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        print(\"-------------- Graficas de bigotes por dicotomicas-------------------\")   \n",
    "        \n",
    "        for a in aux1:\n",
    "\n",
    "            # fig = plt.figure(figsize=(12, 8))\n",
    "            self.boxplot(column=list(aux.values), by=a,figsize=(12, 8))\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        print(\"-------------- Graficas de bigotes por categoricas-------------------\") \n",
    "\n",
    "        for a in aux2:\n",
    "            # fig = plt.figure(figsize=(12, 8))\n",
    "            ax= self.boxplot(column=list(aux.values), by=a, figsize=(12, 8))\n",
    "            # ax = sns.swarmplot(column=list(aux.values), by=a,data=self, color='#7d0013')\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        \n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    def plot_corr(self):\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        print(\"-------------- MATRIZ DE CORRELACIONES ENTRE CUANTITATIVAS -------------------\\n\") \n",
    "\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        matrix = self.cuanti.corr().round(2)\n",
    "        mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "        sns.heatmap(matrix, annot=True, vmax=1, vmin=-1, center=0, cmap='vlag', mask=mask)  \n",
    "        plt.show()\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "    def plot_barras(self):\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"-------------- GRAFICA DE BARRAS DE TODAS LAS CUANTITATIVAS -------------------\\n\") \n",
    "        # fig = plt.figure(figsize=(15, 20))\n",
    "        self.cuanti.plot.bar(figsize=(18, 8))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"-------------- GRAFICA DE BARRAS CON DISTRIBUCIÓN DE DENSIDAD DE CADA CUANTITATIVA  -------------------\\n\") \n",
    "        for i in list(aux.values):\n",
    "            fig = plt.figure(figsize=(12, 8))\n",
    "            print(f\"\\n.............. GRAFICA DE BARRAS  DE {i} ............\\n\") \n",
    "            ax=self[i].plot.hist(density=True)\n",
    "            self[i].plot.density(ax=ax)\n",
    "            plt.show()\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")    \n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "    def todos_plots(self):\n",
    "\n",
    "        self.plot_bigotes()\n",
    "        self.plot_corr()\n",
    "        self.plot_barras()\n",
    "        self.violines()\n",
    "        \n",
    "        \n",
    "\n",
    "    def violines(self):\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        print(\"--------------  GRAFICA DE VIOLINES  -------------------\\n\") \n",
    "        sns.set(style=\"whitegrid\")\n",
    "        for i in aux2:\n",
    "            for j in aux:\n",
    "                ax= sns.violinplot(x=self[i], y=self[j], palette=\"Set2\", split=True, inner=\"quartile\",scale=\"count\")\n",
    "                plt.show()\n",
    "\n",
    "        print(\"\\n\\n/////////-------------- GRAFICA DE VIOLINES POR DICOTOMICAS -------------------/////////////\\n\") \n",
    "        \n",
    "        for i in aux2:\n",
    "            for j in aux:\n",
    "                for k in aux1:\n",
    "                    ax= sns.violinplot(x=self[i], y=self[j], hue=self[k],palette=\"Set2\", split=True, inner=\"quartile\",scale=\"count\")\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "    def cross_var_cualis_con_ciantis(self):\n",
    "\n",
    "        aux=list(self.cate.columns)\n",
    "        aux_cuati=list(self.cuanti.columns)\n",
    "\n",
    "        for k in aux_cuati:\n",
    "            a=0\n",
    "            for i in aux:\n",
    "                a=a+1\n",
    "                if a<len(aux)/2:\n",
    "                    b=0\n",
    "                    for j in aux[:-1]:\n",
    "                        b=b+1\n",
    "                        if b > a:\n",
    "                            print(f\"\\n\\n*************** TABAL DE VARIABLES CATEGORICAS {i} y {j} con valores de {k} MEDIA *********************\\n \")\n",
    "                            tab = pd.crosstab (index=self[i], columns=self[j],values=self[k],aggfunc=np.mean)\n",
    "                            print(tab)\n",
    "                            print(\"\\n\\n\")\n",
    "\n",
    "    def nulos(self):\n",
    "        aux_df=list(self.cuanti.columns)\n",
    "        self.inputado=self.df\n",
    "        for i in aux_df:\n",
    "            nulos=self[i].isna().sum()\n",
    "            total=len(self[i])\n",
    "            porcentaje=nulos/total\n",
    "            if ((nulos>0)):\n",
    "                percen=self[i].quantile([0.2,0.8]).to_list()\n",
    "                self[i]=self[i].apply(lambda x: ( random.randint ( round(percen[0]) , round(percen[1]) )) if pd.isna(x) else x )\n",
    "                print(f\"\\n- Se han inputado {nulos} nulos a la variable {i} (tenía porcentaje de nulos de: {porcentaje}) \\n\")\n",
    "            elif (porcentaje>self.porcentaje_nulos_permitido):\n",
    "                print(f\"\\n - No se ha podido inputar a la variable {i} porque el porcentaje de nulos era de {porcentaje}\\n\")\n",
    "                \n",
    "\n",
    "    def normalidad(self):\n",
    "        \n",
    "        DataF=self.df\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "                \n",
    "        for b in list(aux.values):\n",
    "            aux_shapiro=(stats.shapiro(DataF[b]))\n",
    "            if(aux_shapiro.pvalue<0.05):\n",
    "                print(\"////////////////////////// TEST DE SHAPIRO CUANTITATIVAS ////////////////////////////\")\n",
    "                print(\"++++++++++++++++++++++++++++  \"+ b +\"  ++++++++++++++++++++++++++\\n\")\n",
    "                titulo=f\"Variable cuantitativa {b} y test Shapiro < 0.05\"\n",
    "                print(titulo)\n",
    "                print(aux_shapiro)\n",
    "                print(\"\\n\")\n",
    "                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                self.normal_cuatis.append(b)\n",
    "\n",
    "        for a in list(aux1.values):\n",
    "            for b in list(aux.values):\n",
    "                    agrupado=DataF.groupby(a)[b]\n",
    "                    try:\n",
    "                        aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                        for h in aux_shapiro:\n",
    "                            if(h.pvalue<0.05):\n",
    "                                print(\"////////////////////////// TEST DE SHAPIRO DICOTOMICAS ////////////////////////////\")\n",
    "                                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                                titulo=f\"Agrupado por {a} y por {b} y test Shapiro < 0.05\"\n",
    "                                print(titulo)\n",
    "                                print(aux_shapiro)\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                                self.normal_grupos_dico.append([a,b])\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "        for a in list(aux2.values):\n",
    "            for b in list(aux.values):\n",
    "                    agrupado=DataF.groupby([a])[b]\n",
    "                    try:\n",
    "                        aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                        for h in aux_shapiro:\n",
    "                            if(h.pvalue<0.05):\n",
    "                                print(\"////////////////////////// TEST DE SHAPIRO CATEGORICAS ////////////////////////////\")\n",
    "                                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                                titulo=f\"Agrupado por {a} y por {b} y test Shapiro < 0.05\"\n",
    "                                print(titulo)\n",
    "                                print(h)\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                                self.normal_grupos_cate.append([a,b])\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "        self.normal_grupos_dico=[i for n, i in enumerate(self.normal_grupos_dico) if i not in self.normal_grupos_dico[:n]]\n",
    "        self.normal_grupos_cate=[i for n, i in enumerate(self.normal_grupos_cate) if i not in self.normal_grupos_cate[:n]]\n",
    "        \n",
    "    def detec_outlaiers(self):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        aux_DF=self.cuanti\n",
    "        for i in aux:\n",
    "            z = np.abs(stats.zscore(aux_DF[i]))\n",
    "            print(z)\n",
    "    \n",
    "    def seleccionar_distribuciones(self,familia='realall', verbose=False):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        familia : {'realall', 'realline', 'realplus', 'real0to1', 'discreta'}\n",
    "            realall: distribuciones de la familia `realline` + `realplus`\n",
    "            realline: distribuciones continuas en el dominio (-inf, +inf)\n",
    "            realplus: distribuciones continuas en el dominio [0, +inf)\n",
    "            real0to1: distribuciones continuas en el dominio [0,1]\n",
    "            discreta: distribuciones discretas\n",
    "            \n",
    "        verbose : bool\n",
    "            Si se muestra información de las distribuciones seleccionadas\n",
    "            (the default `False`)\n",
    "        '''\n",
    "    \n",
    "        distribuciones = [getattr(stats,d) for d in dir(stats) \\\n",
    "                        if isinstance(getattr(stats,d), (stats.rv_continuous, stats.rv_discrete))]\n",
    "        \n",
    "        exclusiones = ['levy_stable', 'vonmises']\n",
    "        distribuciones = [dist for dist in distribuciones if dist.name not in exclusiones]\n",
    "                \n",
    "        dominios = {\n",
    "            'realall' : [-np.inf, np.inf],\n",
    "            'realline': [np.inf,np.inf],\n",
    "            'realplus': [0, np.inf],\n",
    "            'real0to1': [0, 1], \n",
    "            'discreta': [None, None],\n",
    "        }\n",
    "\n",
    "        distribucion = []\n",
    "        tipo = []\n",
    "        dominio_inf = []\n",
    "        dominio_sup = []\n",
    "\n",
    "        for dist in distribuciones:\n",
    "            distribucion.append(dist.name)\n",
    "            tipo.append(np.where(isinstance(dist, stats.rv_continuous), 'continua', 'discreta'))\n",
    "            dominio_inf.append(dist.a)\n",
    "            dominio_sup.append(dist.b)\n",
    "        \n",
    "        info_distribuciones = pd.DataFrame({\n",
    "                                'distribucion': distribucion,\n",
    "                                'tipo': tipo,\n",
    "                                'dominio_inf': dominio_inf,\n",
    "                                'dominio_sup': dominio_sup\n",
    "                            })\n",
    "\n",
    "        info_distribuciones = info_distribuciones \\\n",
    "                            .sort_values(by=['dominio_inf', 'dominio_sup'])\\\n",
    "                            .reset_index(drop=True)\n",
    "        \n",
    "        if familia in ['realall', 'realline', 'realplus', 'real0to1']:\n",
    "            info_distribuciones = info_distribuciones[info_distribuciones['tipo']=='continua']\n",
    "            condicion = (info_distribuciones['dominio_inf'] == dominios[familia][0]) & \\\n",
    "                        (info_distribuciones['dominio_sup'] == dominios[familia][1]) \n",
    "            info_distribuciones = info_distribuciones[condicion].reset_index(drop=True)\n",
    "            \n",
    "        if familia in ['discreta']:\n",
    "            info_distribuciones = info_distribuciones[info_distribuciones['tipo']=='discreta']\n",
    "            \n",
    "        seleccion = [dist for dist in distribuciones \\\n",
    "                    if dist.name in info_distribuciones['distribucion'].values]\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            print(\"---------------------------------------------------\")\n",
    "            print(\"       Distribuciones seleccionadas                \")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "                print(info_distribuciones)\n",
    "        \n",
    "        return seleccion\n",
    "\n",
    "\n",
    "    def plot_multiple_distribuciones(self, nombre_distribuciones):\n",
    "\n",
    "        aux=list(self.cuanti.columns)\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "        for i in aux:\n",
    "            x=self[i]\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots(figsize=(7,4))\n",
    "                \n",
    "            ax.hist(x=x, density=True, bins=30, color=\"#3182bd\", alpha=0.5)\n",
    "            ax.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "            ax.set_title('Ajuste distribuciones')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('Densidad de probabilidad')\n",
    "            \n",
    "            for nombre in nombre_distribuciones:\n",
    "                \n",
    "                distribucion = getattr(stats, nombre)\n",
    "\n",
    "                parametros = distribucion.fit(data=x)\n",
    "\n",
    "                nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                    if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "\n",
    "                log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "\n",
    "                aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "\n",
    "                x_hat = np.linspace(min(x), max(x), num=100)\n",
    "                y_hat = distribucion.pdf(x_hat, *parametros)\n",
    "                ax.plot(x_hat, y_hat, linewidth=2, label=distribucion.name)\n",
    "            \n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "    def fit_discrete(self,datos):\n",
    "\n",
    "        # self.discreta\n",
    "\n",
    "        mean = datos.mean()\n",
    "        var = datos.var()\n",
    "        likelihoods = {}  \n",
    "        log_likelihoods = {}\n",
    "\n",
    "        p = 1 - mean / var  \n",
    "        r = (1-p) * mean / p\n",
    "\n",
    "\n",
    "\n",
    "        log_likelihoods['nbinom'] = datos.map(lambda val: stats.nbinom.logpmf(val, r, p)).sum()\n",
    "\n",
    "        lambda_ = mean\n",
    "\n",
    "        log_likelihoods['poisson'] = datos.map(lambda val: stats.poisson.logpmf(val, lambda_)).sum()\n",
    "\n",
    "\n",
    "        best_fit = max(log_likelihoods, key=lambda x: log_likelihoods[x])\n",
    "        print(\"**** Best fit between poisson and nbinorm :\", best_fit)\n",
    "        \n",
    "\n",
    "    \n",
    "        plt.hist(datos, bins=int(np.max(datos)), density=True, alpha=0.5)\n",
    "\n",
    "        mean = datos.mean()\n",
    "        var = datos.var()\n",
    "\n",
    "\n",
    "        def loss_function_poisson(params, datos_in):\n",
    "\n",
    "            mu = params[0]\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            for i in range(len(datos_in)):\n",
    "\n",
    "                loglikelihood = stats.poisson.logpmf(datos_in[i], mu)\n",
    "\n",
    "                loss_to_add = -loglikelihood\n",
    "\n",
    "                loss += loss_to_add\n",
    "\n",
    "            return(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        params0 = np.array([20])\n",
    "        minimum = stats2.optimize.fmin(loss_function_poisson, params0, args=(datos,))\n",
    "\n",
    "        mu_fit = minimum[0]\n",
    "\n",
    "        print(\"***********  The best mu_fit is:  \",  mu_fit)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        x = list(range(int(np.min(datos)), int(np.max(datos))+1))\n",
    "        plt.scatter(x, stats.poisson.pmf(x, mu_fit),color=\"red\")\n",
    "        plt.show()   \n",
    "\n",
    "        print(\"\\n\\n Otras variables discretas:  \",  self.discreta)\n",
    "\n",
    "\n",
    "    def comparar_distribuciones_caunti_cont(self, ordenar='aic', verbose=False):\n",
    "\n",
    "            '''\n",
    "            resultados: data.frame\n",
    "                distribucion: nombre de la distribución.\n",
    "                log_likelihood: logaritmo del likelihood del ajuste.\n",
    "                aic: métrica AIC.\n",
    "                bic: métrica BIC.\n",
    "                n_parametros: número de parámetros de la distribución de la distribución.\n",
    "                parametros: parámetros del tras el ajuste\n",
    "                \n",
    "            Raises\n",
    "            ------\n",
    "            Exception\n",
    "                Si `familia` es distinto de 'realall', 'realline', 'realplus', 'real0to1',\n",
    "                o 'discreta'.\n",
    "                \n",
    "            Notes\n",
    "            -----\n",
    "            '''\n",
    "            aux=list(self.cuanti.columns)\n",
    "            \n",
    "            for i in aux:\n",
    "                print(f\"\\n ******************** Variable: {i} ******************** \\n\")\n",
    "                x=self[i]\n",
    "                distribuciones = self.seleccionar_distribuciones(familia='realall',verbose=verbose)\n",
    "                distribucion_ = []\n",
    "                log_likelihood_= []\n",
    "                aic_ = []\n",
    "                bic_ = []\n",
    "                n_parametros_ = []\n",
    "                parametros_ = []\n",
    "                \n",
    "                for j, distribucion in enumerate(distribuciones):\n",
    "                    \n",
    "                    # print(f\"{j+1}/{len(distribuciones)} Ajustando distribución: {distribucion.name}\")\n",
    "                    \n",
    "                    try:\n",
    "                        parametros = distribucion.fit(data=x)\n",
    "                        nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                            if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                        parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "                        log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "                        aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                        bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "                        \n",
    "                        distribucion_.append(distribucion.name)\n",
    "                        log_likelihood_.append(log_likelihood)\n",
    "                        aic_.append(aic)\n",
    "                        bic_.append(bic)\n",
    "                        n_parametros_.append(len(parametros))\n",
    "                        parametros_.append(parametros_dict)\n",
    "                        \n",
    "                        resultados = pd.DataFrame({\n",
    "                                        'distribucion': distribucion_,\n",
    "                                        'log_likelihood': log_likelihood_,\n",
    "                                        'aic': aic_,\n",
    "                                        'bic': bic_,\n",
    "                                        'n_parametros': n_parametros_,\n",
    "                                        'parametros': parametros_,\n",
    "                            \n",
    "                                    })\n",
    "                        \n",
    "                        resultados = resultados.sort_values(by=ordenar).reset_index(drop=True)\n",
    "\n",
    "                        \n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al tratar de ajustar la distribución {distribucion.name}\")\n",
    "                        print(e)\n",
    "                        print(\"\")\n",
    "\n",
    "                nombre_distribuciones=resultados['distribucion'][:5]\n",
    "                fig, ax = plt.subplots(figsize=(7,4))\n",
    "                \n",
    "                \n",
    "                ax.hist(x=x, density=True, bins=30, color=\"#3182bd\", alpha=0.5)\n",
    "                ax.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "                ax.set_title('Ajuste distribuciones')\n",
    "                ax.set_xlabel('x')\n",
    "                ax.set_ylabel('Densidad de probabilidad')\n",
    "                \n",
    "                for nombre in nombre_distribuciones:\n",
    "                    \n",
    "                    distribucion = getattr(stats, nombre)\n",
    "\n",
    "                    parametros = distribucion.fit(data=x)\n",
    "\n",
    "                    nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                        if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                    parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "\n",
    "                    log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "\n",
    "                    aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                    bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "\n",
    "                    x_hat = np.linspace(min(x), max(x), num=100)\n",
    "                    y_hat = distribucion.pdf(x_hat, *parametros)\n",
    "                    ax.plot(x_hat, y_hat, linewidth=2, label=distribucion.name)\n",
    "            \n",
    "                ax.legend()\n",
    "                plt.show()\n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(resultados.head(5))    \n",
    "                print(\"\\n------------------------------------------------------------------\\n\")\n",
    "\n",
    "    def remove_outliers(self, k=1.5):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        for column in aux:\n",
    "            print(f\"\\n\\n                    <<<<<<<<<<<<<<<<<<<<<<<< {column} >>>>>>>>>>>>>>>>>>>>>>>>\\n\\n\")\n",
    "            self.plot_outliers2(column, k=1.5)\n",
    "            q1, q3 = self[column].quantile([0.25, 0.75])\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - (k * iqr)\n",
    "            upper_bound = q3 + (k * iqr)\n",
    "            self.loc[(self[column] < lower_bound) | (self[column] > upper_bound), column] = None    \n",
    "        self.nulos()\n",
    "        self.outliers_hecho=False\n",
    "\n",
    "\n",
    "    def plot_outliers(self, column, k=1.5):\n",
    "        \n",
    "        q1, q3 = self[column].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (k * iqr)\n",
    "        upper_bound = q3 + (k * iqr)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(self.index, self[column], color='blue', label='inlier')\n",
    "        ax.scatter(self[(self[column] < lower_bound) | (self[column] > upper_bound)].index,\n",
    "                self[(self[column] < lower_bound) | (self[column] > upper_bound)][column],\n",
    "                color='red', label='outlier')\n",
    "        ax.axhline(lower_bound, color='gray', linestyle='--')\n",
    "        ax.axhline(upper_bound, color='gray', linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.show() \n",
    "\n",
    "    \n",
    "    def plot_outliers2(df, column, k=1.5):\n",
    "        q1, q3 = df[column].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (k * iqr)\n",
    "        upper_bound = q3 + (k * iqr)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(df.index, df[column], color='blue')\n",
    "        ax.scatter(df[df[column].isnull()].index,\n",
    "                df[df[column].isnull()][column],\n",
    "                color='red', marker='x')\n",
    "        ax.axhline(lower_bound, color='red', linestyle='--')\n",
    "        ax.axhline(upper_bound, color='red', linestyle='--')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_xy_data(df, x_column, y_column):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(df[x_column], df[y_column])\n",
    "        plt.xlabel(x_column)\n",
    "        plt.ylabel(y_column)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def reg_lineal(self, predictores, OUTCOME):\n",
    "        aux1=set(predictores)\n",
    "        aux2=set(list(self.cuali.columns))\n",
    "        \n",
    "\n",
    "        if (aux1.intersection(aux2)): \n",
    "            print(\"Tienes alguna variable cualitativa en los predictores\")\n",
    "        elif(OUTCOME in list(self.cuali.columns)):\n",
    "            print(\"OUTCOME es cualitativa\") \n",
    "        #No funciona con NA ni con distinta longitud dentro de los DF\n",
    "        if (self.outliers_hecho):\n",
    "            try:\n",
    "                self.remove_outliers()\n",
    "                self.predicotres=self[predictores]\n",
    "                self.outcome=self[OUTCOME]\n",
    "                ej_lm=LinearRegression()\n",
    "                ej_lm.fit(self.predicotres,self.outcome)\n",
    "\n",
    "                for name, coef in zip(predictores,ej_lm.coef_):\n",
    "                    print(f\"{name}: {coef}\")\n",
    "\n",
    "                fitted= ej_lm.predict(self.predicotres)\n",
    "                RMSE= np.sqrt(mean_squared_error(self.outcome,fitted))\n",
    "                r2= r2_score(self.outcome,fitted) \n",
    "\n",
    "                # RMSE es como el accuracy del modelo (es practicamente igual al RSE)\n",
    "                print(f\"- RMSE: {RMSE:.0f}\")\n",
    "\n",
    "                # coeficiente de determinación:  0-1 proporción de varianza en los datos\n",
    "                # que estan contabilizados en el modelo\n",
    "                print(f\"- R2: {r2:.4f}\")\n",
    "                model=sm.OLS(self.outcome,self.predicotres.assign(const=1) )\n",
    "                resul=model.fit()\n",
    "                print(\"\\n - RESUMEN \\n\")\n",
    "                print( resul.summary())\n",
    "                return ej_lm\n",
    "            except:\n",
    "                print(\"Puede que haya columans con distinta longitud\")\n",
    "\n",
    "        elif (self[predictores].isna().any().any()):\n",
    "            print(\"HAY VALORES NULOS EN LAS COLUMNAS Y YA HAS HECHO LA FUNCIÓN DE OUTLIERS\")\n",
    "\n",
    "        else :\n",
    "            try:\n",
    "                self.predicotres=self[predictores]\n",
    "                self.outcome=self[OUTCOME]\n",
    "                ej_lm=LinearRegression()\n",
    "                ej_lm.fit(self.predicotres,self.outcome)\n",
    "\n",
    "                for name, coef in zip(predictores,ej_lm.coef_):\n",
    "                    print(f\"{name}: {coef}\")\n",
    "\n",
    "                fitted= ej_lm.predict(self.predicotres)\n",
    "                RMSE= np.sqrt(mean_squared_error(self.outcome,fitted))\n",
    "                r2= r2_score(self.outcome,fitted) \n",
    "\n",
    "                # RMSE es como el accuracy del modelo (es practicamente igual al RSE)\n",
    "                print(f\"- RMSE: {RMSE:.0f}\")\n",
    "\n",
    "                # coeficiente de determinación:  0-1 proporción de varianza en los datos\n",
    "                # que estan contabilizados en el modelo\n",
    "                print(f\"- R2: {r2:.4f}\")\n",
    "                model=sm.OLS(self.outcome,self.predicotres.assign(const=1) )\n",
    "                resul=model.fit()\n",
    "                print(\"\\n ------------------------- RESUMEN --------------------------- \\n\")\n",
    "                print( resul.summary())\n",
    "                return ej_lm\n",
    "            except:\n",
    "                print(\"Puede que haya columans con distinta longitud\")\n",
    "\n",
    "\n",
    "    def forward_selected(self):\n",
    "        \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "        response: string, name of response column in data\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        model: an \"optimal\" fitted statsmodels linear model\n",
    "            with an intercept\n",
    "            selected by forward selection\n",
    "            evaluated by adjusted R-squared\n",
    "        \"\"\"\n",
    "        data=pd.merge(self.predicotres, self.outcome,left_index=True, right_index=True)\n",
    "        response=self.outcome.columns[0]\n",
    "\n",
    "        remaining = set(data.columns)\n",
    "        remaining.remove(response)\n",
    "        selected = []\n",
    "        current_score, best_new_score = 0.0, 0.0\n",
    "        while remaining and current_score == best_new_score:\n",
    "            scores_with_candidates = []\n",
    "            for candidate in remaining:\n",
    "                formula = \"{} ~ {} + 1\".format(response,\n",
    "                                            ' + '.join(selected + [candidate]))\n",
    "                score = ols(formula, data).fit().rsquared_adj\n",
    "                scores_with_candidates.append((score, candidate))\n",
    "            scores_with_candidates.sort()\n",
    "            best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "            if current_score < best_new_score:\n",
    "                remaining.remove(best_candidate)\n",
    "                selected.append(best_candidate)\n",
    "                current_score = best_new_score\n",
    "        formula = \"{} ~ {} + 1\".format(response,\n",
    "                                    ' + '.join(selected))\n",
    "        model = ols(formula, data).fit()\n",
    "\n",
    "        print (f\"Formula: {model.model.formula}\")\n",
    "        print (f\"Ajuste por R2: {model.rsquared_adj}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def weighted_regression(self, weights):\n",
    "        X = self.predicotres.values\n",
    "        y = self.outcome.values\n",
    "        w = weights.values\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y, sample_weight=w)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def codificar_catego(self,modelo,cate_var:str):\n",
    "        self['residuos']=(self.outcome-modelo.predict(self.predicotres))\n",
    "        self['residuos']\n",
    "        self[cate_var]= self[cate_var]\n",
    "        grupos1_aux= pd.merge(self[cate_var], self['residuos'],left_index=True, right_index=True)\n",
    "        grupos1_agrupado=grupos1_aux.groupby([cate_var])\n",
    "\n",
    "        summary_function = lambda x: {\n",
    "            cate_var: x.iloc[0,0],\n",
    "            'count': len(x),\n",
    "            'residuo_medio': x.residuos.median()\n",
    "        }\n",
    "        \n",
    "        group_summaries = grupos1_agrupado.apply(summary_function)\n",
    "        final_df = pd.DataFrame([    *group_summaries])\n",
    "        grupos1 = final_df.sort_values('residuo_medio')\n",
    "        grupos1['cum_count']=np.cumsum(grupos1['count'])\n",
    "        grupos1['Col_a_codificar_grupos']=pd.qcut(grupos1['cum_count'],5,labels=False,retbins=False)\n",
    "        to_join= grupos1[[cate_var,'Col_a_codificar_grupos']].set_index(cate_var)\n",
    "\n",
    "        self=self.join(to_join, on=cate_var)\n",
    "        return (self[[cate_var,'Col_a_codificar_grupos']])\n",
    "    \n",
    "    def regre_con_interaccion_de_var(self,outcome,predictores,lista_predictores_condicionados):\n",
    "        frase=outcome+\" ~\"\n",
    "        frase_aux1=\"\"\n",
    "        frase_aux2=\"\"\n",
    "        aux=0\n",
    "        for i, j in lista_predictores_condicionados:\n",
    "            if aux==0:\n",
    "                frase_aux1=i+\"*\"+j\n",
    "            else:\n",
    "                frase_aux1=frase_aux1+\"+\"+i+\"*\"+j\n",
    "            aux=aux+1\n",
    "        for i in predictores:\n",
    "            frase_aux2=frase_aux2+\"+\"+i\n",
    "        frase=frase+frase_aux1+frase_aux2\n",
    "        print(f\" Formula final: {frase} \\n\\n\")\n",
    "        model=smf.ols(formula= frase,data=self )\n",
    "        results=model.fit()\n",
    "        return results.summary()\n",
    "    \n",
    "\n",
    "    def regre_outliers(self, cate=None, grupo=None):\n",
    "\n",
    "        if cate==None:\n",
    "            ej_outliers=sm.OLS(self.outcome, self.predicotres.assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "\n",
    "            influence=OLSInfluence(resul_1)\n",
    "            sresiduals= influence.resid_studentized_internal\n",
    "\n",
    "            outliers=self.loc[sresiduals.idxmin(), :]\n",
    "            print(\"resultado\", outliers[list(self.outcome.columns)])\n",
    "            print(outliers[list(self.predicotres.columns)])\n",
    "\n",
    "\n",
    "            print(\"puntos con alta influencia y distancia de Cooks mayor de 0.08\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            ax.axhline(-2.5, linestyle='--', color='C1')\n",
    "            ax.axhline(2.5, linestyle='--', color='C1')\n",
    "            ax.scatter(influence.hat_matrix_diag, \n",
    "                    influence.resid_studentized_internal,\n",
    "                    s=1000*np.sqrt(influence.cooks_distance[0]), \n",
    "                    alpha=0.5)\n",
    "            ax.set_xlabel('hat values')\n",
    "            ax.set_ylabel('studentized residuals')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            print(\"predictores vs residuos para ver heteroskedascity\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            df = pd.DataFrame({'fitted': resul_1.fittedvalues, \n",
    "                            'residuals': np.abs(resul_1.resid)})\n",
    "            sns.regplot(x='fitted', y='residuals', data=df, scatter_kws={'alpha':0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax)\n",
    "            ax.set_xlabel('predictos')\n",
    "            ax.set_ylabel('abs(residuos)')\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "            ej_outliers=sm.OLS(datos_agru[list(self.outcome.columns)], datos_agru[list(self.predicotres.columns)].assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "\n",
    "            influence=OLSInfluence(resul_1)\n",
    "            sresiduals= influence.resid_studentized_internal\n",
    "\n",
    "            outliers=datos_agru.loc[sresiduals.idxmin(), :]\n",
    "            print(\"resultado\", outliers[list(self.outcome.columns)])\n",
    "            print(outliers[list(self.predicotres.columns)])\n",
    "\n",
    "            print(\"puntos con alta influencia y distancia de Cooks mayor de 0.08\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            ax.axhline(-2.5, linestyle='--', color='C1')\n",
    "            ax.axhline(2.5, linestyle='--', color='C1')\n",
    "            ax.scatter(influence.hat_matrix_diag, \n",
    "                    influence.resid_studentized_internal,\n",
    "                    s=1000*np.sqrt(influence.cooks_distance[0]), \n",
    "                    alpha=0.5)\n",
    "            ax.set_xlabel('hat values')\n",
    "            ax.set_ylabel('studentized residuals')\n",
    "            plt.show()\n",
    "\n",
    "            print(\"predictores vs residuos para ver heteroskedascity\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            df = pd.DataFrame({'fitted': resul_1.fittedvalues, \n",
    "                            'residuals': np.abs(resul_1.resid)})\n",
    "            sns.regplot(x='fitted', y='residuals', data=df, scatter_kws={'alpha':0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax)\n",
    "            ax.set_xlabel('predictos')\n",
    "            ax.set_ylabel('abs(residuos)')\n",
    "            plt.show()\n",
    "\n",
    "    def infl_residual_modelo(self, var_influ, cate=None, grupo=None):\n",
    "        if cate==None:\n",
    "            ej_outliers=sm.OLS(self.outcome, self.predicotres.assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "            sm.graphics.plot_ccpr(resul_1,var_influ)\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fig = sm.graphics.plot_ccpr_grid(resul_1, fig=fig)\n",
    "        \n",
    "        else:\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "            ej_outliers=sm.OLS(datos_agru[list(self.outcome.columns)], datos_agru[list(self.predicotres.columns)].assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "            sm.graphics.plot_ccpr(resul_1,var_influ)\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fig = sm.graphics.plot_ccpr_grid(resul_1, fig=fig)\n",
    "\n",
    "    def regre_poly(self,variables_exp,expo,cate=None, grupo=None,verbose=False):\n",
    "\n",
    "        if cate==None:\n",
    "\n",
    "            out=list(self.outcome.columns)\n",
    "            predic=list(self.predicotres.columns)\n",
    "\n",
    "            frase=out[0]+\" ~ \"\n",
    "            variables_no_exp = [element for element in predic if element not in variables_exp]\n",
    "            frase_expo=\"\"\n",
    "            frase_no_expo=\"\"\n",
    "\n",
    "            for i,j in zip(variables_exp,expo):\n",
    "                frase_expo=frase_expo + f\"np.power({i}, {j}) + \" \n",
    "\n",
    "            for indice,i in enumerate(variables_no_exp):\n",
    "                if indice == len(variables_no_exp)-1:\n",
    "                    frase_no_expo=frase_no_expo+i    \n",
    "                else: \n",
    "                    frase_no_expo=frase_no_expo+i+ \"+\"   \n",
    "\n",
    "            frase=frase+frase_expo+frase_no_expo\n",
    "            print(frase)\n",
    "            \n",
    "            model_poly = smf.ols(formula=frase, data=self)\n",
    "            result_poly = model_poly.fit()\n",
    "            if (verbose):\n",
    "             print(result_poly.summary())\n",
    "\n",
    "        else:\n",
    "\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "\n",
    "            out=list(self.outcome.columns)\n",
    "            predic=list(self.predicotres.columns)\n",
    "\n",
    "            frase=out[0]+\" ~ \"\n",
    "            variables_no_exp = [element for element in predic if element not in variables_exp]\n",
    "            frase_expo=\"\"\n",
    "            frase_no_expo=\"\"\n",
    "\n",
    "            for i,j in zip(variables_exp,expo):\n",
    "                frase_expo=frase_expo + f\"np.power({i}, {j}) + \" \n",
    "\n",
    "            for indice,i in enumerate(variables_no_exp):\n",
    "                if indice == len(variables_no_exp)-1:\n",
    "                    frase_no_expo=frase_no_expo+i    \n",
    "                else: \n",
    "                    frase_no_expo=frase_no_expo+i+ \"+\"   \n",
    "\n",
    "            frase=frase+frase_expo+frase_no_expo\n",
    "            print(frase)\n",
    "            \n",
    "            model_poly = smf.ols(formula=frase, data=datos_agru)\n",
    "            result_poly = model_poly.fit()\n",
    "            if (verbose):\n",
    "                print(result_poly.summary())\n",
    "\n",
    "        return result_poly\n",
    "        \n",
    "\n",
    "    def partialResidualPlot(self, model, feature):\n",
    "        df= pd.merge(self.predicotres, self.outcome, left_index=True, right_index=True)\n",
    "        outcome= list(self.outcome.columns)\n",
    "\n",
    "        y_pred = model.predict(df)\n",
    "        copy_df = df.copy()\n",
    "        for c in copy_df.columns:\n",
    "            if c == feature:\n",
    "                continue\n",
    "            copy_df[c] = 0.0\n",
    "        feature_prediction = model.predict(copy_df)\n",
    "        \n",
    "        \n",
    "        residual=df[outcome].values - y_pred.values\n",
    "        results = pd.DataFrame({\n",
    "            'feature': df[feature].values,\n",
    "            'residual': residual[0],\n",
    "            'ypartial': feature_prediction.values - model.params[0],\n",
    "        })\n",
    "\n",
    "        results = results.sort_values(by=['feature'])\n",
    "        smoothed = sm.nonparametric.lowess(results.ypartial, results.feature, frac=1/3)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "        ax.scatter(results.feature, results.ypartial + results.residual)\n",
    "        ax.plot(smoothed[:, 0], smoothed[:, 1], color='gray')\n",
    "        ax.plot(results.feature, results.ypartial, color='black')\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(f'Residual + {feature} contribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def plot_partial_residuals_poly(self,variables_exp,expo,variable ,cate=None, grupo=None):\n",
    "        model=self.regre_poly(variables_exp,expo,cate, grupo)\n",
    "        self.partialResidualPlot(model,variable)\n",
    "\n",
    "    \n",
    "    def clasificador_bayes(self,predictores,outcome,new):\n",
    "        X =self[predictores]\n",
    "        y = self[outcome]\n",
    "\n",
    "        naive_model = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "        naive_model = MultinomialNB(alpha=1e-10, fit_prior=False)\n",
    "        naive_model.fit(X, y)\n",
    "\n",
    "        print(\"Input en el modelo bayesiano: \")\n",
    "        print(new)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print('Clase más probable: ', naive_model.predict(new)[0])\n",
    "\n",
    "        probabilities = pd.DataFrame(naive_model.predict_proba(new),columns=naive_model.classes_)\n",
    "        print('Probabilidades de cada clase:',)\n",
    "        print(probabilities)\n",
    "\n",
    "    def accuracy_bayes(self,predictores,outcome):\n",
    "        X =self[predictores]\n",
    "        y = self[outcome]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        modelo_gausian = GaussianNB()\n",
    "        \n",
    "        modelo_gausian .fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo_gausian .predict(X_test)\n",
    "\n",
    "        precision_gausian  = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"La precisión del modelo gaussiano de bayes es: {precision_gausian }\")\n",
    "\n",
    "        modelo_multino=MultinomialNB()\n",
    "\n",
    "        modelo_multino.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo_multino.predict(X_test)\n",
    "\n",
    "        precision_multino = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"La precisión del modelo multinomial de bayes es: {precision_multino}\")\n",
    "\n",
    "    def predict_lda(self,predictors,outcome):\n",
    "        X=self[predictors]\n",
    "        y=self[outcome]\n",
    "\n",
    "        modelo_lda = LinearDiscriminantAnalysis()\n",
    "        modelo_lda.fit(X, y)\n",
    "        y_pred = modelo_lda.predict(X)\n",
    "\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        print(\"Accuracy modelo LDA:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACIÓN DE LA CLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo=DF_exploracion(df_prueba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas._libs.properties.AxisProperty at 0x1607fd12860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.cuanti.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINICIÓN DE LAS VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  ES_NO_ES \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  sexo \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_C \n",
      "|   - Tipo de dato: int32 \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_D \n",
      "|   - Tipo de dato: float64 \n",
      "|   - Valores repetidos: 1000 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_E \n",
      "|   - Tipo de dato: float64 \n",
      "|   - Valores repetidos: 1000 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Poisson_1 \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 13 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Poisson_3 \n",
      "|   - Tipo de dato: int32 \n",
      "|   - Valores repetidos: 19 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Geom \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 5 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_F \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 618 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_G \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 649 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_A \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 6 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_B \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 4 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_C \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 60 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|----------------------------------------------------------------------------------------------------\n",
      "|  TODAS: Index(['ES_NO_ES', 'sexo', 'Datos_C', 'Datos_D', 'Datos_E', 'Datos_Poisson_1',\n",
      "       'Datos_Poisson_3', 'Datos_Geom', 'Datos_F', 'Datos_G', 'Datos_cate_A',\n",
      "       'Datos_cate_B', 'Datos_cate_C'],\n",
      "      dtype='object') \n",
      "|  DICOTOMICAS: ['ES_NO_ES', 'sexo', 'Datos_C'] \n",
      "|  CATEGORICAS: ['Datos_Geom', 'Datos_cate_A', 'Datos_cate_B'] \n",
      "|  CUANTITATIVAS: ['Datos_D', 'Datos_E', 'Datos_Poisson_1', 'Datos_Poisson_3', 'Datos_F', 'Datos_G', 'Datos_cate_C'] \n",
      "|  ELIMINAR: []\n",
      "|----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ejemplo.variables()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de variables dummys a traves de dicotómicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** self.dummy ************\n",
      "\n",
      "     ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  Datos_C_1\n",
      "0             1           0       1       0          1          0\n",
      "1             0           1       1       0          1          0\n",
      "2             0           1       1       0          0          1\n",
      "3             1           0       0       1          0          1\n",
      "4             0           1       0       1          0          1\n",
      "..          ...         ...     ...     ...        ...        ...\n",
      "995           0           1       1       0          0          1\n",
      "996           0           1       1       0          1          0\n",
      "997           0           1       0       1          1          0\n",
      "998           0           1       0       1          1          0\n",
      "999           0           1       0       1          1          0\n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "\n",
      "********************** self.df o todas_las_col() ************\n",
      "\n",
      "    ES_NO_ES sexo  Datos_C   Datos_D   Datos_E  Datos_Poisson_1  \\\n",
      "0          n    h        0 -0.959953 -0.773658                3   \n",
      "1          s    h        0 -0.328371  0.012776                6   \n",
      "2          s    h        1 -0.946527  0.145006                4   \n",
      "3          n    m        1 -0.726721  0.889954                2   \n",
      "4          s    m        1  0.900574 -0.074418                3   \n",
      "..       ...  ...      ...       ...       ...              ...   \n",
      "995        s    h        1  0.136736  1.000814                5   \n",
      "996        s    h        0 -0.005761  0.329771                5   \n",
      "997        s    m        0 -1.655294 -0.000892                9   \n",
      "998        s    m        0  0.163652 -0.014762                3   \n",
      "999        s    m        0 -2.564231 -1.363363                3   \n",
      "\n",
      "     Datos_Poisson_3  Datos_Geom  Datos_F  Datos_G Datos_cate_A Datos_cate_B  \\\n",
      "0                 10           1      950      986      Grupo 3      Grupo 1   \n",
      "1                 11           1      425      802      Grupo 0      Grupo 2   \n",
      "2                 11           1      465      391      Grupo 2      Grupo 2   \n",
      "3                 15           1      951      201      Grupo 2      Grupo 1   \n",
      "4                  9           2      238      372      Grupo 4      Grupo 3   \n",
      "..               ...         ...      ...      ...          ...          ...   \n",
      "995               14           3      888      432      Grupo 0      Grupo 0   \n",
      "996                9           2      694      794      Grupo 3      Grupo 0   \n",
      "997               10           1      221      893      Grupo 2      Grupo 1   \n",
      "998               13           1      737      816      Grupo 3      Grupo 2   \n",
      "999               10           1      262      392      Grupo 2      Grupo 0   \n",
      "\n",
      "     Datos_cate_C  ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  \\\n",
      "0              40           1           0       1       0          1   \n",
      "1               5           0           1       1       0          1   \n",
      "2              40           0           1       1       0          0   \n",
      "3              19           1           0       0       1          0   \n",
      "4              35           0           1       0       1          0   \n",
      "..            ...         ...         ...     ...     ...        ...   \n",
      "995             0           0           1       1       0          0   \n",
      "996            45           0           1       1       0          1   \n",
      "997            30           0           1       0       1          1   \n",
      "998            24           0           1       0       1          1   \n",
      "999             5           0           1       0       1          1   \n",
      "\n",
      "     Datos_C_1  \n",
      "0            0  \n",
      "1            0  \n",
      "2            1  \n",
      "3            1  \n",
      "4            1  \n",
      "..         ...  \n",
      "995          1  \n",
      "996          0  \n",
      "997          0  \n",
      "998          0  \n",
      "999          0  \n",
      "\n",
      "[1000 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "ejemplo.limpiar_dummys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES_NO_ES</th>\n",
       "      <th>sexo</th>\n",
       "      <th>Datos_C</th>\n",
       "      <th>Datos_D</th>\n",
       "      <th>Datos_E</th>\n",
       "      <th>Datos_Poisson_1</th>\n",
       "      <th>Datos_Poisson_3</th>\n",
       "      <th>Datos_Geom</th>\n",
       "      <th>Datos_F</th>\n",
       "      <th>Datos_G</th>\n",
       "      <th>Datos_cate_A</th>\n",
       "      <th>Datos_cate_B</th>\n",
       "      <th>Datos_cate_C</th>\n",
       "      <th>ES_NO_ES_n</th>\n",
       "      <th>ES_NO_ES_s</th>\n",
       "      <th>sexo_h</th>\n",
       "      <th>sexo_m</th>\n",
       "      <th>Datos_C_0</th>\n",
       "      <th>Datos_C_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.959953</td>\n",
       "      <td>-0.773658</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>950</td>\n",
       "      <td>986</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.328371</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>802</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.946527</td>\n",
       "      <td>0.145006</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>391</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.726721</td>\n",
       "      <td>0.889954</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>951</td>\n",
       "      <td>201</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900574</td>\n",
       "      <td>-0.074418</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>238</td>\n",
       "      <td>372</td>\n",
       "      <td>Grupo 4</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136736</td>\n",
       "      <td>1.000814</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>888</td>\n",
       "      <td>432</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005761</td>\n",
       "      <td>0.329771</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>694</td>\n",
       "      <td>794</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.655294</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>893</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>0.163652</td>\n",
       "      <td>-0.014762</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>737</td>\n",
       "      <td>816</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.564231</td>\n",
       "      <td>-1.363363</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>262</td>\n",
       "      <td>392</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ES_NO_ES sexo  Datos_C   Datos_D   Datos_E  Datos_Poisson_1  \\\n",
       "0          n    h        0 -0.959953 -0.773658                3   \n",
       "1          s    h        0 -0.328371  0.012776                6   \n",
       "2          s    h        1 -0.946527  0.145006                4   \n",
       "3          n    m        1 -0.726721  0.889954                2   \n",
       "4          s    m        1  0.900574 -0.074418                3   \n",
       "..       ...  ...      ...       ...       ...              ...   \n",
       "995        s    h        1  0.136736  1.000814                5   \n",
       "996        s    h        0 -0.005761  0.329771                5   \n",
       "997        s    m        0 -1.655294 -0.000892                9   \n",
       "998        s    m        0  0.163652 -0.014762                3   \n",
       "999        s    m        0 -2.564231 -1.363363                3   \n",
       "\n",
       "     Datos_Poisson_3  Datos_Geom  Datos_F  Datos_G Datos_cate_A Datos_cate_B  \\\n",
       "0                 10           1      950      986      Grupo 3      Grupo 1   \n",
       "1                 11           1      425      802      Grupo 0      Grupo 2   \n",
       "2                 11           1      465      391      Grupo 2      Grupo 2   \n",
       "3                 15           1      951      201      Grupo 2      Grupo 1   \n",
       "4                  9           2      238      372      Grupo 4      Grupo 3   \n",
       "..               ...         ...      ...      ...          ...          ...   \n",
       "995               14           3      888      432      Grupo 0      Grupo 0   \n",
       "996                9           2      694      794      Grupo 3      Grupo 0   \n",
       "997               10           1      221      893      Grupo 2      Grupo 1   \n",
       "998               13           1      737      816      Grupo 3      Grupo 2   \n",
       "999               10           1      262      392      Grupo 2      Grupo 0   \n",
       "\n",
       "     Datos_cate_C  ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  \\\n",
       "0              40           1           0       1       0          1   \n",
       "1               5           0           1       1       0          1   \n",
       "2              40           0           1       1       0          0   \n",
       "3              19           1           0       0       1          0   \n",
       "4              35           0           1       0       1          0   \n",
       "..            ...         ...         ...     ...     ...        ...   \n",
       "995             0           0           1       1       0          0   \n",
       "996            45           0           1       1       0          1   \n",
       "997            30           0           1       0       1          1   \n",
       "998            24           0           1       0       1          1   \n",
       "999             5           0           1       0       1          1   \n",
       "\n",
       "     Datos_C_1  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "..         ...  \n",
       "995          1  \n",
       "996          0  \n",
       "997          0  \n",
       "998          0  \n",
       "999          0  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo.df\n",
    "# ejemplo.cuanti\n",
    "# ejemplo.dummy\n",
    "# ejemplo.dico\n",
    "ejemplo.df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de variables agrupadas automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datos con distribución discreta: ['Datos_C', 'Datos_Poisson_1', 'Datos_Poisson_3', 'Datos_Geom', 'Datos_F', 'Datos_G', 'Datos_cate_C']\n",
      "Datos de tipos string seguramente: ['ES_NO_ES', 'sexo', 'Datos_cate_A', 'Datos_cate_B']\n"
     ]
    }
   ],
   "source": [
    "print(f\" Datos con distribución discreta: {ejemplo.discreta}\")\n",
    "print(f\"Datos de tipos string seguramente: {ejemplo.stingg}\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTADISTICA DESCRIPTIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.estadistica_descriptiva_cuantis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.estadistica_descriptiva_cualis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.cross_var_cualis_con_ciantis()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables normales y no normales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.normalidad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación normal por categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.normal_grupos_cate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación normalidad por dicotomicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.normal_grupos_dico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitar outlayers e inputar datos en columnas variables cuantitativas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.remove_outliers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar a distribuciones variables cuantitativas (No puede haber nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.comparar_distribuciones_caunti_cont()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar a distribuciones variables discretas (No puede haber nulos) (Solo poisson y binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.fit_discrete(df_prueba[\"Datos_Poisson_1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejemplo.todos_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_bigotes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_barras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.violines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_normailidad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ESTADISTICOS NO MULTIVARIANTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables cualitativas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.Chi()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables cuantitativas no pareadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.t_test_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilconxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.wilconxon( [\"sexo\",\"Datos_D\" ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.anova()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_confidence_interval(\"Datos_D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictores=['Datos_D','Datos_E','Datos_F']\n",
    "# OUTCOME=['Datos_G']\n",
    "\n",
    "# modelo=ejemplo.reg_lineal(predictores,OUTCOME)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables predictoras en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.forward_selected()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal por pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights=ejemplo[\"Datos_Poisson_1\"]\n",
    "# ejemplo.weighted_regression( weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificar variables categoricas si son muy largas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # si tienes variables con muchas categorias pues \n",
    "    # tendrías un monton de dummys y no es la cosa tampoco \n",
    "    # que va a parecer esto un sudoku (es que además pueden incluso ser practicamente iguales)\n",
    "    # Entonces los puedes codificar usando los residuos de la regresión\n",
    "    # DESPUES NO SE GUARDA COL_A_CODIFICAR_GRUPOS!!!\n",
    "\n",
    "# ejemplo.codificar_catego(modelo,'Datos_cate_C')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadir en el modelo variables correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # interacciones entre variables que entre ellas hacen efecto en el outcome\n",
    "\n",
    "# predictores=[\"Datos_E\",\"Datos_F\"]\n",
    "# lista_predictores_condicionados=[[\"Datos_D\",\"Datos_E\"],[\"Datos_Poisson_1\",\"Datos_Poisson_3\"]]\n",
    "# outcome=\"Datos_G\"\n",
    "# ejemplo.regre_con_interaccion_de_var(outcome,predictores,lista_predictores_condicionados)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Outliers no es lo mismo que en la distribución porque aqui se usa el \n",
    "\n",
    "# ejemplo.regre_outliers(cate=\"Datos_cate_C\",grupo=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuos parciales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # residuos parciales \n",
    "\n",
    "    # La función sm.graphics.plot_ccpr de la biblioteca statsmodels es una función para \n",
    "    # crear un gráfico de la influencia residual del modelo lineal. \n",
    "    # La función toma como argumentos un objeto de resultado de modelo lineal (resul_1) \n",
    "    # y un nombre de variable independiente ('Datos_F').\n",
    "\n",
    "    # El gráfico de influencia residual se utiliza para evaluar la influencia de cada \n",
    "    # punto en el ajuste del modelo lineal. En la gráfica, los ejes representan las \n",
    "    # predicciones del modelo y los residuales absolutos respectivamente. \n",
    "    # Los puntos son una representación de cada observación en el conjunto de datos, \n",
    "    # con la posición de cada punto indicando la influencia de esa observación en el modelo.\n",
    "\n",
    "    # El gráfico de influencia residual se utiliza para detectar outliers y puntos \n",
    "    # con influencia anormal en el modelo lineal. Si un punto tiene una influencia \n",
    "    # anormal en el modelo, puede ser necesario revisar ese punto en el conjunto de datos \n",
    "    # y considerar si debería ser incluido o excluido del modelo.\n",
    "\n",
    "    # En general, un gráfico de influencia residual es una herramienta útil para \n",
    "    # comprender la calidad del ajuste del modelo lineal y para detectar posibles \n",
    "    # problemas en los datos o en el modelo.\n",
    "\n",
    "# ejemplo.infl_residual_modelo(var_influ='Datos_F', cate=\"Datos_cate_C\",grupo=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_exp=[\"Datos_E\",\"Datos_F\"]\n",
    "# expo=[2,3]\n",
    "\n",
    "# ejemplo.regre_poly(variables_exp,expo, cate=\"Datos_cate_C\",grupo=1,verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot de residuos parciales con regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_exp=[\"Datos_E\",\"Datos_F\"]\n",
    "# expo=[2,3]\n",
    "# grupo=1\n",
    "# variable=\"Datos_F\"\n",
    "# cate=\"Datos_cate_C\"\n",
    "\n",
    "# ejemplo.plot_partial_residuals_poly(variables_exp,expo,variable ,cate, grupo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input en el modelo bayesiano: \n",
      "   Datos_Poisson_3  Datos_Poisson_1  Datos_Geom\n",
      "3               15                2           1\n",
      "\n",
      "\n",
      "Clase más probable:  Grupo 2\n",
      "Probabilidades de cada clase:\n",
      "    Grupo 0   Grupo 1   Grupo 2   Grupo 3   Grupo 4   Grupo 5\n",
      "0  0.145548  0.149342  0.193616  0.177322  0.150951  0.183221\n"
     ]
    }
   ],
   "source": [
    "predictors=['Datos_Poisson_3','Datos_Poisson_1','Datos_Geom']\n",
    "outcome=['Datos_cate_A']\n",
    "\n",
    "#LOS PREDICTORES TODOS EN NÚMEROS, SI SON DICO SE PASAN A DUMMYS\n",
    "# Naive porque predictores independientes \n",
    "\n",
    "ejemplo.clasificador_bayes(predictors,outcome,df_prueba[predictors].loc[3:3, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo gaussiano de bayes es: 0.172\n",
      "La precisión del modelo multinomial de bayes es: 0.148\n"
     ]
    }
   ],
   "source": [
    "ejemplo.accuracy_bayes(predictors,outcome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy modelo LDA: 0.533\n"
     ]
    }
   ],
   "source": [
    "# limitado al número de filas, da igual cuantos predictores mientras \n",
    "# distribución normal pero vamos que puede valer para todo\n",
    "# Outcome categorico \n",
    "\n",
    "predictors=['Datos_Poisson_3','Datos_Geom']\n",
    "outcome=['sexo']\n",
    "\n",
    "ejemplo.predict_lda(predictors,outcome)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES_NO_ES_s</th>\n",
       "      <th>sexo_h</th>\n",
       "      <th>Datos_C_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ES_NO_ES_s  sexo_h  Datos_C_1\n",
       "0             0       1          0\n",
       "1             1       1          0\n",
       "2             1       1          1\n",
       "3             0       0          1\n",
       "4             1       0          1\n",
       "..          ...     ...        ...\n",
       "995           1       1          1\n",
       "996           1       1          0\n",
       "997           1       0          0\n",
       "998           1       0          0\n",
       "999           1       0          0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummys=ejemplo[[ \"ES_NO_ES_s\",  \"sexo_h\" ,  \"Datos_C_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ES_NO_ES_s   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      995\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -689.99\n",
      "Date:                Mon, 20 Mar 2023   Deviance:                       1380.0\n",
      "Time:                        23:44:46   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.006109\n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Datos_Poisson_3    -0.0050      0.020     -0.251      0.802      -0.044       0.034\n",
      "Datos_Geom         -0.0931      0.094     -0.995      0.320      -0.277       0.090\n",
      "Datos_F             0.0002      0.000      0.868      0.386      -0.000       0.001\n",
      "Datos_E             0.1335      0.064      2.098      0.036       0.009       0.258\n",
      "const               0.0461      0.263      0.176      0.861      -0.469       0.561\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# solo se puede variables dummys (0 y 1)\n",
    "predictors=['Datos_Poisson_3','Datos_Geom',\"Datos_F\",\"Datos_E\"]\n",
    "y= ejemplo[[ \"ES_NO_ES_s\"]]\n",
    "X= ejemplo[predictors]\n",
    "\n",
    "logit_reg_sm = sm.GLM(y, X.assign(const=1), \n",
    "                      family=sm.families.Binomial())\n",
    "logit_result = logit_reg_sm.fit()\n",
    "print(logit_result.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ES_NO_ES_s   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      987\n",
      "Model Family:                Binomial   Df Model:                           12\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -688.30\n",
      "Date:                Mon, 20 Mar 2023   Deviance:                       1376.6\n",
      "Time:                        23:44:48   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.009448\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -2.1694      1.346     -1.611      0.107      -4.808       0.469\n",
      "bs(Datos_F, df=8)[0]    -0.6213      0.922     -0.674      0.500      -2.428       1.185\n",
      "bs(Datos_F, df=8)[1]    -0.0745      0.562     -0.133      0.894      -1.176       1.026\n",
      "bs(Datos_F, df=8)[2]    -0.2729      0.664     -0.411      0.681      -1.575       1.029\n",
      "bs(Datos_F, df=8)[3]    -0.0681      0.570     -0.120      0.905      -1.185       1.049\n",
      "bs(Datos_F, df=8)[4]    -0.1777      0.624     -0.285      0.776      -1.400       1.044\n",
      "bs(Datos_F, df=8)[5]    -0.0130      0.679     -0.019      0.985      -1.343       1.317\n",
      "bs(Datos_F, df=8)[6]    -0.0960      0.731     -0.131      0.896      -1.529       1.337\n",
      "bs(Datos_F, df=8)[7]    -0.3464      0.672     -0.515      0.606      -1.664       0.971\n",
      "Datos_Poisson_3         -0.0072      0.020     -0.361      0.718      -0.046       0.032\n",
      "bs(Datos_E, df=3)[0]     4.6753      2.631      1.777      0.076      -0.482       9.833\n",
      "bs(Datos_E, df=3)[1]     0.2914      0.924      0.315      0.752      -1.520       2.103\n",
      "bs(Datos_E, df=3)[2]     4.2542      2.046      2.080      0.038       0.245       8.264\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data=pd.merge(y, X,left_index=True, right_index=True)\n",
    "formula = ('ES_NO_ES_s ~ bs(Datos_F, df=8) + ' +\n",
    "           'Datos_Poisson_3 + bs(Datos_E, df=3)')\n",
    "model = glm(formula=formula, data=data, family=sm.families.Binomial())\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  0.04598269377393815\n",
      "classes [0 1]\n",
      "                           Yhat = 1                         Yhat = 0\n",
      "Y = 0  ES_NO_ES_s    0\n",
      "dtype: int64     ES_NO_ES_s    0\n",
      "dtype: int64\n",
      "Y = 1  ES_NO_ES_s    0\n",
      "dtype: int64  ES_NO_ES_s    1000\n",
      "dtype: int64\n",
      "[[295 212]\n",
      " [276 217]]\n",
      "Confusion Matrix (Accuracy 0.5120)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 295 212\n",
      "     1 276 217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logit_reg = LogisticRegression(penalty='l2', C=1e42, solver='liblinear')\n",
    "logit_reg.fit(X, y)\n",
    "\n",
    "print('intercept ', logit_reg.intercept_[0])\n",
    "print('classes', logit_reg.classes_)\n",
    "pd.DataFrame({'coeff': logit_reg.coef_[0]}, \n",
    "             index=X.columns)\n",
    "\n",
    "# Confusion matrix\n",
    "pred = logit_reg.predict(X)\n",
    "pred_y = logit_reg.predict(X) == \"0\"\n",
    "true_y = y == \"0\"\n",
    "true_pos = true_y & pred_y\n",
    "true_neg = ~true_y & ~pred_y\n",
    "false_pos = ~true_y & pred_y\n",
    "false_neg = true_y & ~pred_y\n",
    "\n",
    "conf_mat = pd.DataFrame([[np.sum(true_pos), np.sum(false_neg)], [np.sum(false_pos), np.sum(true_neg)]],\n",
    "                       index=['Y = 0', 'Y = 1'],\n",
    "                       columns=['Yhat = 1', 'Yhat = 0'])\n",
    "print(conf_mat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(confusion_matrix(y, logit_reg.predict(X)))\n",
    "\n",
    "classificationSummary(y, logit_reg.predict(X), \n",
    "                      class_names=logit_reg.classes_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión, sensivilidad y especificidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.5166374781085814\n",
      "Recall 0.5818540433925049\n",
      "Specificity 0.44016227180527384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.51663748, 0.50582751]),\n",
       " array([0.58185404, 0.44016227]),\n",
       " array([0.54730983, 0.47071584]),\n",
       " array([507, 493], dtype=int64))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y, logit_reg.predict(X))\n",
    "print('Precision', conf_mat[0, 0] / sum(conf_mat[:, 0]))\n",
    "print('Recall', conf_mat[0, 0] / sum(conf_mat[0, :]))\n",
    "print('Specificity', conf_mat[1, 1] / sum(conf_mat[1, :]))\n",
    "\n",
    "precision_recall_fscore_support(y, logit_reg.predict(X), \n",
    "                                labels=['0', '1'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### curva ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:, 0], pos_label=0)\n",
    "roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "\n",
    "ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(1, 0)\n",
    "ax.plot((1, 0), (0, 1))\n",
    "ax.set_xlabel('specificity')\n",
    "ax.set_ylabel('recall')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:,0], \n",
    "                                 pos_label=0)\n",
    "roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "\n",
    "ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(1, 0)\n",
    "# ax.plot((1, 0), (0, 1))\n",
    "ax.set_xlabel('specificity')\n",
    "ax.set_ylabel('recall')\n",
    "ax.fill_between(roc_df.specificity, 0, roc_df.recall, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "609973a2d1f31d45d1c4d9f5c0b4ecf9cb33fe1a555b03392724c0cdbb5c54ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
