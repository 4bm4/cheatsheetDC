{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import inspect\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from pygam import LinearGAM, s, f, l\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as stats2\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from statsmodels.formula.api import ols,glm\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.metrics import mean_squared_error,r2_score, confusion_matrix, precision_recall_fscore_support,roc_curve, accuracy_score, roc_auc_score\n",
    "from dmba import stepwise_selection,AIC_score,classificationSummary,textDecisionTree\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prueba = pd.DataFrame({\n",
    "\"ES_NO_ES\":[np.random.choice(['s','n']) for _ in range(1000)],\n",
    "\"sexo\":[np.random.choice(['h','m']) for _ in range(1000)],\n",
    "\"Datos_C\":[np.random.choice([0,1]) for _ in range(1000)],\n",
    "\"Datos_D\": list(np.random.standard_normal(1000)),\n",
    "\"Datos_E\": list(np.random.standard_normal(1000)),\n",
    "\"Datos_Poisson_1\": list( stats.poisson.rvs(mu=4, size=1000)),\n",
    "\"Datos_Poisson_3\": list( np.random.poisson(lam=10, size=1000)),\n",
    "\"Datos_Geom\": list( stats.geom.rvs(0.75, size=1000)),\n",
    "\"Datos_F\": [np.random.randint(0,1000) for _ in range(1000)],\n",
    "\"Datos_G\": [np.random.randint(0,1000) for _ in range(1000)],\n",
    "\"Datos_cate_A\": ['Grupo '+str(np.random.randint(0,6)) for _ in range(1000)],\n",
    "\"Datos_cate_B\": ['Grupo '+str(np.random.randint(0,4)) for _ in range(1000)],\n",
    "\"Datos_cate_C\": [np.random.randint(0,60) for _ in range(1000)],\n",
    "\n",
    "})\n",
    "\n",
    "# for i in range(1,6):\n",
    "#     df_prueba['Datos_E'][random.randint(0,23)]=None\n",
    "\n",
    "\n",
    "# for i in range(1,10):\n",
    "#     df_prueba['Datos_F'][random.randint(0,23)]=None\n",
    "\n",
    "# for i in range(0,11):\n",
    "#     df_prueba['Datos_G'][i]=None\n",
    "\n",
    "    \n",
    "lista_de_items= ['Item '+str(np.random.randint(0,6)) for _ in range(30000)]\n",
    "num_fact= 30000\n",
    "\n",
    "def crear_lista (lista):\n",
    "    listafin=[]\n",
    "    for i in range (0,num_fact):\n",
    "        lista_aux=[]\n",
    "        for j in range(1, random.randint(1, 10)):\n",
    "            lista_aux.append(random.choice(lista))\n",
    "        \n",
    "        listafin.append(lista_aux)\n",
    "    \n",
    "    return listafin\n",
    "\n",
    "# facturas=crear_lista(lista_de_items)\n",
    "\n",
    "\n",
    "# df_prueb2 = pd.DataFrame({\n",
    "# \"Items\": lista_de_items,\n",
    "# \"facturas\": facturas,\n",
    "# })\n",
    "\n",
    "# pd.merge(df_prueba, df_prueb2,left_index=True, right_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DF_exploracion(pd.DataFrame):\n",
    "\n",
    "    def __init__(self, *args, **kw):\n",
    "        super(DF_exploracion, self).__init__(*args, **kw)\n",
    "        self.cuanti=pd.DataFrame\n",
    "        self.cuanti_antes_de_outliers_y_inputs=pd.DataFrame\n",
    "        self.cuali=pd.DataFrame\n",
    "        self.dico=pd.DataFrame\n",
    "        self.cate=pd.DataFrame\n",
    "        self.eliminado=pd.DataFrame\n",
    "        self.dummy=pd.DataFrame\n",
    "        self.df=pd.DataFrame\n",
    "        self.df_inputado=pd.DataFrame\n",
    "        self.df_limpio=pd.DataFrame\n",
    "        self.predicotres=pd.DataFrame\n",
    "        self.outcome=pd.DataFrame\n",
    "        # self.outcome_col=self.outcome.columns\n",
    "        self.normal_cuatis=[]\n",
    "        self.normal_grupos_dico=[]\n",
    "        self.normal_grupos_cate=[]\n",
    "        self.discreta=[]\n",
    "        self.stingg=[]\n",
    "        self.outliers_hecho=True\n",
    "        self.porcentaje_nulos_permitido=0.3\n",
    "\n",
    "    def variables(self):\n",
    "\n",
    "        dico=[]\n",
    "        cuantis=[]\n",
    "        categori=[]\n",
    "        eliminar=[]\n",
    "        \n",
    "\n",
    "        for i in self.columns: \n",
    "\n",
    "            try:\n",
    "                datos=self[i].dropna().to_numpy()\n",
    "                discreta=True\n",
    "                for j in datos:\n",
    "                    if (j%1 !=0):\n",
    "                        discreta=False\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                if (discreta):\n",
    "                    self.discreta.append(i)\n",
    "            except:\n",
    "                self.stingg.append(i)\n",
    "\n",
    "            nulos= (self[i].isnull().sum())/len(self[i])\n",
    "            \n",
    "            if ((len(self[i].dropna().unique())==2) and (nulos<=self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: DICOTOMICA\"\n",
    "                dico.append(i)\n",
    "\n",
    "            elif ((len(self[i].dropna().unique())>10) and  (nulos<=self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: CUANTITATIVA\"\n",
    "                cuantis.append(i)\n",
    "\n",
    "            elif ( (len(self[i].dropna().unique())<2) or (nulos>self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"SOLO {len(self[i].dropna().unique())} TIPOS, NO VALE LA COLUMNA\"\n",
    "                eliminar.append(i)\n",
    "            else:\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: CATEGORICA/CUANTI\"\n",
    "                categori.append(i)\n",
    "\n",
    "            print (f\"|  {i} \\n|   - Tipo de dato: {self[i].dtype} \\n|   - Valores repetidos: {tipo_de_var} \\n|   - Nulos: {nulos} \\n| \")\n",
    "\n",
    "        print (f\"|----------------------------------------------------------------------------------------------------\\n|  TODAS: {self.columns} \\n|  DICOTOMICAS: {dico} \\n|  CATEGORICAS: {categori} \\n|  CUANTITATIVAS: {cuantis} \\n|  ELIMINAR: {eliminar}\")\n",
    "        print(\"|----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        self.DF_cuantis(cuantis)\n",
    "        self.DF_cualis(categori+dico)\n",
    "        self.DF_dicotomica(dico)\n",
    "        self.DF_categorica(categori)\n",
    "        self.DF_elimiminado(eliminar)\n",
    "        self.df=self\n",
    "        \n",
    "    def todas_col(self):\n",
    "        return self.df\n",
    "    \n",
    "    def DF_cuantis(self,lista):\n",
    "        self.cuanti=self[lista]\n",
    "\n",
    "    def DF_elimiminado(self,lista):\n",
    "        self.eliminado=self[lista]\n",
    "        \n",
    "    def DF_cualis(self,lista):\n",
    "        self.cuali=self[lista]\n",
    "        \n",
    "    def DF_dicotomica(self, lista):\n",
    "        self.dico=self[lista]\n",
    "        \n",
    "    def DF_categorica(self, lista):\n",
    "        self.cate=self[lista]   \n",
    "\n",
    "\n",
    "    def quita_valor(self,col,valor):\n",
    "        for valores in valor:\n",
    "            if valores in self[col].values:\n",
    "                self[col].loc[self[col] == valores] = None\n",
    "            else:\n",
    "                print(f\"El valor {valores} no está en la columna\" )\n",
    "            \n",
    "    def normalizar_col(self, col):\n",
    "        for columna in col:\n",
    "            titulo=columna+\"_Normalizada\"\n",
    "            self[titulo] = normalize(self[[columna]], axis=0).ravel()\n",
    "            print(\"-------------------------------\")\n",
    "            print(titulo)\n",
    "            print(self[titulo])\n",
    "            \n",
    "\n",
    "    def limpiar_aux(self):\n",
    "        \n",
    "        try:\n",
    "            df_nuevo=pd.DataFrame\n",
    "            aux1=list(self.dico.columns)\n",
    "            aux=[]\n",
    "            df_nuevo=pd.get_dummies(self.df, columns=aux1)\n",
    "            \n",
    "            for columna in df_nuevo.columns:\n",
    "                for variables in list(self.dico.columns):\n",
    "                    if variables in columna:\n",
    "                        aux.append(columna)\n",
    "                    \n",
    "            self.dummy=df_nuevo[aux]\n",
    "            self[aux]=df_nuevo[aux]\n",
    "\n",
    "            # self.df=self.drop(columns=var, axis='columns')\n",
    "            # self.df= self[self.columns.difference(self.dico.columns)]\n",
    "            \n",
    "            print(\"********************** self.dummy ************\\n\")\n",
    "            print(self.dummy)\n",
    "            print(\"\\n********************** self.df o todas_las_col() ************\\n\")\n",
    "            print(self.df)\n",
    "\n",
    "        except:\n",
    "            print(\"---------------------- ERROR -----------------\")\n",
    "\n",
    "\n",
    "\n",
    "    def limpiar_dummys(self):\n",
    "\n",
    "        b=False\n",
    "        lista=list(self.dico.columns)\n",
    "        for ind, i in enumerate(lista):\n",
    "                if (ind+1<len(lista)):\n",
    "                    if( (i in lista [ind+1]) ):\n",
    "                        b=True\n",
    "                        break\n",
    "        if b:\n",
    "            nombres_nuevos=[]\n",
    "            if len(lista)>2:\n",
    "                for ind, i in enumerate(lista):\n",
    "                    if (ind+1<len(lista)):\n",
    "                        if( (i in lista [ind+1]) ):\n",
    "                            nombres_nuevos.append(i.upper())\n",
    "                        else:\n",
    "                            nombres_nuevos.append(i)\n",
    "                    else:\n",
    "                        nombres_nuevos.append(i)\n",
    "                        \n",
    "            aux_df=self.df\n",
    "\n",
    "            for i,j in zip(lista,nombres_nuevos):\n",
    "                aux_df.rename(columns={i:j},inplace=True)\n",
    "                \n",
    "            self.df=aux_df\n",
    "            self.dico.columns=nombres_nuevos\n",
    "            \n",
    "            self.limpiar_aux()\n",
    "        else: \n",
    "            self.limpiar_aux()\n",
    "\n",
    "\n",
    "\n",
    "    def estadistica_descriptiva_cuantis(self):\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\nDESCRIPCIÓN\")\n",
    "        print (self.cuanti.describe())\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\nCUARTILES\")\n",
    "        print (self.cuanti.quantile([0.05,0.25,0.5,0.75,0.95]))\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        # df_auxiliar = self.groupby('sexo').apply(lambda x: pd.Series(shapiro(x), index=['W','P'])).reset_index()\n",
    "        # print(df_auxiliar)\n",
    "                \n",
    "        for a in list(aux1.values):\n",
    "            \n",
    "            for b in list(aux.values):\n",
    "                \n",
    "                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                agrupado=self.groupby(a)[b]\n",
    "                titulo=f\"Agrupado por {a} y por {b}\"\n",
    "                print(titulo)\n",
    "                print(agrupado.describe().reset_index())\n",
    "                # df.groupby(['cat1', 'cat2'])['purchases','sales'].apply(stats.shapiro)\n",
    "                print(\"////////////////////////// TEST DE SHAPIRO ////////////////////////////\")\n",
    "                aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                print(aux_shapiro)\n",
    "        \n",
    "                \n",
    "                print(\"\\n\")\n",
    "                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "    def estadistica_descriptiva_cualis(self):\n",
    "\n",
    "        print(\"\\n--------------------- Variables dico ---------------------\")\n",
    "        print(\"\\n\")\n",
    "        for i in self.dico.columns:\n",
    "            print(f\"...........Frecuencia variable {i} ....................\")\n",
    "            print(self[i].value_counts()/(self[i].count()))\n",
    "            print(\"\\n\")\n",
    "\n",
    "        print(\"\\n-------------------- Variables categoricas --------------------\")\n",
    "        print(\"\\n\")\n",
    "        for i in self.cate.columns:\n",
    "            print(f\"...........Frecuencia variable {i} ....................\")\n",
    "            print(self[i].value_counts()/(self[i].count()))\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # crosstab variables cualis con cate\n",
    "        aux=list(self.cate.columns)\n",
    "\n",
    "        a=0\n",
    "        for i in aux:\n",
    "            a=a+1\n",
    "            if a<len(aux)/2:\n",
    "                b=0\n",
    "                for j in aux[:-1]:\n",
    "                    b=b+1\n",
    "                    if b > a:\n",
    "                        print(f\"*************** TABAL DE VARIABLES CATEGORICAS {i} y {j} *********************\\n \")\n",
    "                        tab = pd.crosstab (index=self[i], columns=self[j])\n",
    "                        x=(tab/tab.sum())\n",
    "                        print(tab)\n",
    "                        print(\"\\n\")\n",
    "                        print(f\"/////////////////// EN PROPORCION //////////////////\\n\")\n",
    "                        print(x)\n",
    "                        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    def anova(self):\n",
    "\n",
    "        aux_cate=list(self.cate.columns)\n",
    "        aux_cuati=list(self.cuanti.columns)\n",
    "\n",
    "        for i in aux_cate:\n",
    "            for j in aux_cuati:\n",
    "                try:\n",
    "                    print(f\"\\n----------- ANOVA Categoria {i} y variable continua {j} ----------\\n\")\n",
    "                    model = ols(f\"{j} ~ {i}\", data=self).fit()\n",
    "                    a=sm.stats.anova_lm(model, typ=2)\n",
    "                    print(a)\n",
    "                except:\n",
    "                    print(f\"\\n - - - - - Fallo en variable {i} y {j} - - - - - - \\n\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Chi(self):\n",
    "\n",
    "        aux_dico=list(self.dico.columns)\n",
    "\n",
    "        if len(aux_dico)>1:\n",
    "            for ind, i in enumerate(aux_dico):\n",
    "                for j in range(ind+1,len(aux_dico)):\n",
    "                    chi, p, dof, expected = stats.chi2_contingency(pd.crosstab(self[i],self[aux_dico[j]]), correction=False)\n",
    "                    print(f\"\\n-------------- Chi2 entre {i} y {aux_dico[j]} ----------------\")\n",
    "                    print(f\"p: {p} \\n\") \n",
    "        else:\n",
    "            print(\"******************** No suficientes argumentos ********************\")\n",
    "\n",
    "\n",
    "    def t_test_aux(self, columns):\n",
    "        results = []\n",
    "        for i, col1 in enumerate(columns[:-1]):\n",
    "            for col2 in columns[i+1:]:\n",
    "                t, p = stats.ttest_ind(self[col1].dropna(), self[col2].dropna(), equal_var=False)\n",
    "                # results.append((col1, col2, t, p))\n",
    "                if p < 0.05:\n",
    "                    print( f\"+++++ Variable{col1}, variable 2 {col2} con p de: \\033[1m{p}\\033[0m  Se RECHAZA H0 ++++\") \n",
    "                else:\n",
    "                    print( f\"+++++ Variable{col1}, variable 2 {col2}  con p de: {p} SE ACEPTA H0 ++++\") \n",
    "    \n",
    "    def wilcoxon_test_aux(self,col1, col2):\n",
    "        if (col1== col2).all():\n",
    "            print (\"\\nLas coluimnas son iguales\\n\")\n",
    "        res = stats.wilcoxon(col1, col2)\n",
    "        if res.pvalue < 0.05:\n",
    "            print(f\"Reject null hypothesis. Significant difference  (p-value={res.pvalue:.4f})\")\n",
    "        else:\n",
    "            print (f\"Fail to reject null hypothesis. No significant difference (p-value={res.pvalue:.4f})\")\n",
    "\n",
    "    def wilconxon(self, lista):\n",
    "        # lista=[grupo, var]\n",
    "        a,b=self.agrupar(lista)\n",
    "        print(f\"\\n- Variable: {lista[1]}, Grupo: {lista[0]}\")\n",
    "        self.wilcoxon_test_aux(a, b)\n",
    "\n",
    "    def agrupar (self, lista):\n",
    "        groupby_col=lista[0]\n",
    "        col=lista[1]\n",
    "        valor=self[groupby_col].unique()\n",
    "        group= self.where(self[groupby_col]== valor[0])[col]\n",
    "        group2= self.where(self[groupby_col]== valor[1])[col] \n",
    "        return group,group2\n",
    "\n",
    "    # def t_test_groupby_one_col(self, col, groupby_col):\n",
    "        \n",
    "    #     group= self.where(self[groupby_col]== self[groupby_col][0]).dropna()[col]\n",
    "    #     group2= self.where(self[groupby_col]== self[groupby_col][1]).dropna()[col]\n",
    "    #     t, p = stats.ttest_ind(group, group2, equal_var=False)\n",
    "    #     print( col, groupby_col,p) \n",
    "\n",
    "    def t_test_all(self):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        aux2=list(self.dico.columns)\n",
    "        self.t_test_aux(self.normal_cuatis) #aqui ya hace todas las cuantis entre ellas faltan los grupos\n",
    "        for i in self.normal_grupos_dico:\n",
    "            a,b=self.agrupar(i)\n",
    "            t, p = stats.ttest_ind(a.dropna(), b.dropna(), equal_var=False)\n",
    "            if p < 0.05:\n",
    "                print( f\"+++++ Variable{i[1]}, Agrupado por {i[0]} con p de: \\033[1m{p}\\033[0m  Se RECHAZA H0 ++++\") \n",
    "            else:\n",
    "                print( f\"+++++ Variable{i[1]}, Agrupado por {i[0]} con p de: {p} SE ACEPTA H0 ++++\") \n",
    "    # df_prueba.groupby('sexo').apply(lambda df: stats.ttest_ind(df['Datos_D'].dropna(), df['Datos_E'].dropna())[1])\n",
    "\n",
    "\n",
    "    def plot_confidence_interval(self, col, confidence_level= 0.95):\n",
    "        data = self[col].to_numpy()\n",
    "        n = len(data)\n",
    "        mean =self[col].mean(axis=0)\n",
    "        # std_error = stats.sem( self[col].dropna())\n",
    "        std_error = self[col].dropna().std()\n",
    "        lower_bound = stats.t.ppf(0.025, n - 1, loc = mean, scale = std_error)  # =>  99.23452406698323\n",
    "        upper_bound = stats.t.ppf(0.975, n - 1, loc = mean, scale = std_error)\n",
    "        # h = std_error * stats.t.ppf((1 + confidence_level) / 2, n - 1)\n",
    "        \n",
    "        # lower_bound = mean - h\n",
    "        # upper_bound = mean + h\n",
    "        # plt.hist(data, bins=30, edgecolor='black', alpha=0.5)\n",
    "        # plt.axvspan(lower_bound, upper_bound, color='gray', alpha=0.2, label=f'{confidence_level * 100}% Confidence Interval')\n",
    "        # plt.axvline(x=mean, color='red', label='Sample Mean')\n",
    "        # plt.legend()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(data, bins=30, edgecolor='black', alpha=0.5)\n",
    "        ax.axvline(x=mean, color='red', label='Sample Mean')\n",
    "        ax.axvspan(lower_bound, upper_bound, color='grey', alpha=0.5, label=f'{confidence_level * 100}% Confidence Interval')\n",
    "        ax.annotate(\n",
    "            f'lower_bound:\\n {lower_bound:.2f}',\n",
    "            xy=(lower_bound, 0), xytext=(lower_bound-0.5, 50)\n",
    "        )\n",
    "        ax.annotate(\n",
    "            f'upper_bound:\\n  {upper_bound:.2f}',\n",
    "            xy=(upper_bound, 0), xytext=(upper_bound-0.5, 50)\n",
    "        )\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_normailidad(self):\n",
    "        aux=self.cuanti.columns\n",
    "        for i in aux:\n",
    "            stats.probplot(self[i], dist=\"norm\", plot=plt)\n",
    "            plt.title(\"Probability Plot - \" )\n",
    "            plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    def plot_bigotes(self):\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "        print(\"-------------- Graficas de bigotes cualitativas-------------------\")\n",
    "        # fig = plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        (self.cuanti).plot(kind='box', title='Variables cuantitativas',figsize=(12, 8))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        print(\"-------------- Graficas de bigotes por dicotomicas-------------------\")   \n",
    "        \n",
    "        for a in aux1:\n",
    "\n",
    "            # fig = plt.figure(figsize=(12, 8))\n",
    "            self.boxplot(column=list(aux.values), by=a,figsize=(12, 8))\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        print(\"-------------- Graficas de bigotes por categoricas-------------------\") \n",
    "\n",
    "        for a in aux2:\n",
    "            # fig = plt.figure(figsize=(12, 8))\n",
    "            ax= self.boxplot(column=list(aux.values), by=a, figsize=(12, 8))\n",
    "            # ax = sns.swarmplot(column=list(aux.values), by=a,data=self, color='#7d0013')\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        \n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "    \n",
    "    \n",
    "    def plot_bigotes_selec_grupos(self,col, grupos):\n",
    "\n",
    "        for a in grupos:\n",
    "            self.boxplot(column=col, by=a,figsize=(12, 8))\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        \n",
    "    \n",
    "    \n",
    "    def plot_bigotes_selec(self,col):\n",
    "        titulo=\"Comparación entre: \"\n",
    "        titulo_aux=\"\"\n",
    "        for columnas in col: \n",
    "            titulo_aux=titulo_aux+ \"  \"+ columnas\n",
    "        titulo=titulo+titulo_aux\n",
    "        aux=self.cuanti\n",
    "        aux[col].plot(kind='box', title=titulo,figsize=(12, 8))\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    def plot_corr(self):\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        print(\"-------------- MATRIZ DE CORRELACIONES ENTRE CUANTITATIVAS -------------------\\n\") \n",
    "\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        matrix = self.cuanti.corr().round(2)\n",
    "        mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "        sns.heatmap(matrix, annot=True, vmax=1, vmin=-1, center=0, cmap='vlag', mask=mask)  \n",
    "        plt.show()\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "    def plot_barras(self):\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"-------------- GRAFICA DE BARRAS DE TODAS LAS CUANTITATIVAS -------------------\\n\") \n",
    "        # fig = plt.figure(figsize=(15, 20))\n",
    "        self.cuanti.plot.bar(figsize=(18, 8))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"-------------- GRAFICA DE BARRAS CON DISTRIBUCIÓN DE DENSIDAD DE CADA CUANTITATIVA  -------------------\\n\") \n",
    "        for i in list(aux.values):\n",
    "            fig = plt.figure(figsize=(12, 8))\n",
    "            print(f\"\\n.............. GRAFICA DE BARRAS  DE {i} ............\\n\") \n",
    "            ax=self[i].plot.hist(density=True)\n",
    "            self[i].plot.density(ax=ax)\n",
    "            plt.show()\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")    \n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "    def todos_plots(self):\n",
    "\n",
    "        self.plot_bigotes()\n",
    "        self.plot_corr()\n",
    "        self.plot_barras()\n",
    "        self.violines()\n",
    "        \n",
    "        \n",
    "\n",
    "    def violines(self):\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        print(\"--------------  GRAFICA DE VIOLINES  -------------------\\n\") \n",
    "        sns.set(style=\"whitegrid\")\n",
    "        for i in aux2:\n",
    "            for j in aux:\n",
    "                ax= sns.violinplot(x=self[i], y=self[j], palette=\"Set2\", split=True, inner=\"quartile\",scale=\"count\")\n",
    "                plt.show()\n",
    "\n",
    "        print(\"\\n\\n/////////-------------- GRAFICA DE VIOLINES POR DICOTOMICAS -------------------/////////////\\n\") \n",
    "        \n",
    "        for i in aux2:\n",
    "            for j in aux:\n",
    "                for k in aux1:\n",
    "                    ax= sns.violinplot(x=self[i], y=self[j], hue=self[k],palette=\"Set2\", split=True, inner=\"quartile\",scale=\"count\")\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "    def cross_var_cualis_con_ciantis(self):\n",
    "\n",
    "        aux=list(self.cate.columns)\n",
    "        aux_cuati=list(self.cuanti.columns)\n",
    "\n",
    "        for k in aux_cuati:\n",
    "            a=0\n",
    "            for i in aux:\n",
    "                a=a+1\n",
    "                if a<len(aux)/2:\n",
    "                    b=0\n",
    "                    for j in aux[:-1]:\n",
    "                        b=b+1\n",
    "                        if b > a:\n",
    "                            print(f\"\\n\\n*************** TABAL DE VARIABLES CATEGORICAS {i} y {j} con valores de {k} MEDIA *********************\\n \")\n",
    "                            tab = pd.crosstab (index=self[i], columns=self[j],values=self[k],aggfunc=np.mean)\n",
    "                            print(tab)\n",
    "                            print(\"\\n\\n\")\n",
    "\n",
    "    def nulos(self):\n",
    "        aux_df=list(self.cuanti.columns)\n",
    "        self.inputado=self.df\n",
    "        for i in aux_df:\n",
    "            nulos=self[i].isna().sum()\n",
    "            total=len(self[i])\n",
    "            porcentaje=nulos/total\n",
    "            if ((nulos>0)):\n",
    "                percen=self[i].quantile([0.2,0.8]).to_list()\n",
    "                self[i]=self[i].apply(lambda x: ( random.randint ( round(percen[0]) , round(percen[1]) )) if pd.isna(x) else x )\n",
    "                print(f\"\\n- Se han inputado {nulos} nulos a la variable {i} (tenía porcentaje de nulos de: {porcentaje}) \\n\")\n",
    "            elif (porcentaje>self.porcentaje_nulos_permitido):\n",
    "                print(f\"\\n - No se ha podido inputar a la variable {i} porque el porcentaje de nulos era de {porcentaje}\\n\")\n",
    "                \n",
    "\n",
    "    def normalidad(self):\n",
    "        \n",
    "        DataF=self.df\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "                \n",
    "        for b in list(aux.values):\n",
    "            aux_shapiro=(stats.shapiro(DataF[b]))\n",
    "            if(aux_shapiro.pvalue<0.05):\n",
    "                print(\"////////////////////////// TEST DE SHAPIRO CUANTITATIVAS ////////////////////////////\")\n",
    "                print(\"++++++++++++++++++++++++++++  \"+ b +\"  ++++++++++++++++++++++++++\\n\")\n",
    "                titulo=f\"Variable cuantitativa {b} y test Shapiro < 0.05\"\n",
    "                print(titulo)\n",
    "                print(aux_shapiro)\n",
    "                print(\"\\n\")\n",
    "                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                self.normal_cuatis.append(b)\n",
    "\n",
    "        for a in list(aux1.values):\n",
    "            for b in list(aux.values):\n",
    "                    agrupado=DataF.groupby(a)[b]\n",
    "                    try:\n",
    "                        aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                        for h in aux_shapiro:\n",
    "                            if(h.pvalue<0.05):\n",
    "                                print(\"////////////////////////// TEST DE SHAPIRO DICOTOMICAS ////////////////////////////\")\n",
    "                                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                                titulo=f\"Agrupado por {a} y por {b} y test Shapiro < 0.05\"\n",
    "                                print(titulo)\n",
    "                                print(aux_shapiro)\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                                self.normal_grupos_dico.append([a,b])\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "        for a in list(aux2.values):\n",
    "            for b in list(aux.values):\n",
    "                    agrupado=DataF.groupby([a])[b]\n",
    "                    try:\n",
    "                        aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                        for h in aux_shapiro:\n",
    "                            if(h.pvalue<0.05):\n",
    "                                print(\"////////////////////////// TEST DE SHAPIRO CATEGORICAS ////////////////////////////\")\n",
    "                                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                                titulo=f\"Agrupado por {a} y por {b} y test Shapiro < 0.05\"\n",
    "                                print(titulo)\n",
    "                                print(h)\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                                self.normal_grupos_cate.append([a,b])\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "        self.normal_grupos_dico=[i for n, i in enumerate(self.normal_grupos_dico) if i not in self.normal_grupos_dico[:n]]\n",
    "        self.normal_grupos_cate=[i for n, i in enumerate(self.normal_grupos_cate) if i not in self.normal_grupos_cate[:n]]\n",
    "        \n",
    "    def detec_outlaiers(self):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        aux_DF=self.cuanti\n",
    "        for i in aux:\n",
    "            z = np.abs(stats.zscore(aux_DF[i]))\n",
    "            print(z)\n",
    "    \n",
    "    def seleccionar_distribuciones(self,familia='realall', verbose=False):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        familia : {'realall', 'realline', 'realplus', 'real0to1', 'discreta'}\n",
    "            realall: distribuciones de la familia `realline` + `realplus`\n",
    "            realline: distribuciones continuas en el dominio (-inf, +inf)\n",
    "            realplus: distribuciones continuas en el dominio [0, +inf)\n",
    "            real0to1: distribuciones continuas en el dominio [0,1]\n",
    "            discreta: distribuciones discretas\n",
    "            \n",
    "        verbose : bool\n",
    "            Si se muestra información de las distribuciones seleccionadas\n",
    "            (the default `False`)\n",
    "        '''\n",
    "    \n",
    "        distribuciones = [getattr(stats,d) for d in dir(stats) \\\n",
    "                        if isinstance(getattr(stats,d), (stats.rv_continuous, stats.rv_discrete))]\n",
    "        \n",
    "        exclusiones = ['levy_stable', 'vonmises']\n",
    "        distribuciones = [dist for dist in distribuciones if dist.name not in exclusiones]\n",
    "                \n",
    "        dominios = {\n",
    "            'realall' : [-np.inf, np.inf],\n",
    "            'realline': [np.inf,np.inf],\n",
    "            'realplus': [0, np.inf],\n",
    "            'real0to1': [0, 1], \n",
    "            'discreta': [None, None],\n",
    "        }\n",
    "\n",
    "        distribucion = []\n",
    "        tipo = []\n",
    "        dominio_inf = []\n",
    "        dominio_sup = []\n",
    "\n",
    "        for dist in distribuciones:\n",
    "            distribucion.append(dist.name)\n",
    "            tipo.append(np.where(isinstance(dist, stats.rv_continuous), 'continua', 'discreta'))\n",
    "            dominio_inf.append(dist.a)\n",
    "            dominio_sup.append(dist.b)\n",
    "        \n",
    "        info_distribuciones = pd.DataFrame({\n",
    "                                'distribucion': distribucion,\n",
    "                                'tipo': tipo,\n",
    "                                'dominio_inf': dominio_inf,\n",
    "                                'dominio_sup': dominio_sup\n",
    "                            })\n",
    "\n",
    "        info_distribuciones = info_distribuciones \\\n",
    "                            .sort_values(by=['dominio_inf', 'dominio_sup'])\\\n",
    "                            .reset_index(drop=True)\n",
    "        \n",
    "        if familia in ['realall', 'realline', 'realplus', 'real0to1']:\n",
    "            info_distribuciones = info_distribuciones[info_distribuciones['tipo']=='continua']\n",
    "            condicion = (info_distribuciones['dominio_inf'] == dominios[familia][0]) & \\\n",
    "                        (info_distribuciones['dominio_sup'] == dominios[familia][1]) \n",
    "            info_distribuciones = info_distribuciones[condicion].reset_index(drop=True)\n",
    "            \n",
    "        if familia in ['discreta']:\n",
    "            info_distribuciones = info_distribuciones[info_distribuciones['tipo']=='discreta']\n",
    "            \n",
    "        seleccion = [dist for dist in distribuciones \\\n",
    "                    if dist.name in info_distribuciones['distribucion'].values]\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            print(\"---------------------------------------------------\")\n",
    "            print(\"       Distribuciones seleccionadas                \")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "                print(info_distribuciones)\n",
    "        \n",
    "        return seleccion\n",
    "\n",
    "\n",
    "    def plot_multiple_distribuciones(self, nombre_distribuciones):\n",
    "\n",
    "        aux=list(self.cuanti.columns)\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "        for i in aux:\n",
    "            x=self[i]\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots(figsize=(7,4))\n",
    "                \n",
    "            ax.hist(x=x, density=True, bins=30, color=\"#3182bd\", alpha=0.5)\n",
    "            ax.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "            ax.set_title('Ajuste distribuciones')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('Densidad de probabilidad')\n",
    "            \n",
    "            for nombre in nombre_distribuciones:\n",
    "                \n",
    "                distribucion = getattr(stats, nombre)\n",
    "\n",
    "                parametros = distribucion.fit(data=x)\n",
    "\n",
    "                nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                    if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "\n",
    "                log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "\n",
    "                aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "\n",
    "                x_hat = np.linspace(min(x), max(x), num=100)\n",
    "                y_hat = distribucion.pdf(x_hat, *parametros)\n",
    "                ax.plot(x_hat, y_hat, linewidth=2, label=distribucion.name)\n",
    "            \n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "    def fit_discrete(self,datos):\n",
    "\n",
    "        # self.discreta\n",
    "\n",
    "        mean = datos.mean()\n",
    "        var = datos.var()\n",
    "        likelihoods = {}  \n",
    "        log_likelihoods = {}\n",
    "\n",
    "        p = 1 - mean / var  \n",
    "        r = (1-p) * mean / p\n",
    "\n",
    "\n",
    "\n",
    "        log_likelihoods['nbinom'] = datos.map(lambda val: stats.nbinom.logpmf(val, r, p)).sum()\n",
    "\n",
    "        lambda_ = mean\n",
    "\n",
    "        log_likelihoods['poisson'] = datos.map(lambda val: stats.poisson.logpmf(val, lambda_)).sum()\n",
    "\n",
    "\n",
    "        best_fit = max(log_likelihoods, key=lambda x: log_likelihoods[x])\n",
    "        print(\"**** Best fit between poisson and nbinorm :\", best_fit)\n",
    "        \n",
    "\n",
    "    \n",
    "        plt.hist(datos, bins=int(np.max(datos)), density=True, alpha=0.5)\n",
    "\n",
    "        mean = datos.mean()\n",
    "        var = datos.var()\n",
    "\n",
    "\n",
    "        def loss_function_poisson(params, datos_in):\n",
    "\n",
    "            mu = params[0]\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            for i in range(len(datos_in)):\n",
    "\n",
    "                loglikelihood = stats.poisson.logpmf(datos_in[i], mu)\n",
    "\n",
    "                loss_to_add = -loglikelihood\n",
    "\n",
    "                loss += loss_to_add\n",
    "\n",
    "            return(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        params0 = np.array([20])\n",
    "        minimum = stats2.optimize.fmin(loss_function_poisson, params0, args=(datos,))\n",
    "\n",
    "        mu_fit = minimum[0]\n",
    "\n",
    "        print(\"***********  The best mu_fit is:  \",  mu_fit)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        x = list(range(int(np.min(datos)), int(np.max(datos))+1))\n",
    "        plt.scatter(x, stats.poisson.pmf(x, mu_fit),color=\"red\")\n",
    "        plt.show()   \n",
    "\n",
    "        print(\"\\n\\n Otras variables discretas:  \",  self.discreta)\n",
    "\n",
    "\n",
    "    def comparar_distribuciones_caunti_cont(self, ordenar='aic', verbose=False):\n",
    "\n",
    "            '''\n",
    "            resultados: data.frame\n",
    "                distribucion: nombre de la distribución.\n",
    "                log_likelihood: logaritmo del likelihood del ajuste.\n",
    "                aic: métrica AIC.\n",
    "                bic: métrica BIC.\n",
    "                n_parametros: número de parámetros de la distribución de la distribución.\n",
    "                parametros: parámetros del tras el ajuste\n",
    "                \n",
    "            Raises\n",
    "            ------\n",
    "            Exception\n",
    "                Si `familia` es distinto de 'realall', 'realline', 'realplus', 'real0to1',\n",
    "                o 'discreta'.\n",
    "                \n",
    "            Notes\n",
    "            -----\n",
    "            '''\n",
    "            aux=list(self.cuanti.columns)\n",
    "            \n",
    "            for i in aux:\n",
    "                print(f\"\\n ******************** Variable: {i} ******************** \\n\")\n",
    "                x=self[i]\n",
    "                distribuciones = self.seleccionar_distribuciones(familia='realall',verbose=verbose)\n",
    "                distribucion_ = []\n",
    "                log_likelihood_= []\n",
    "                aic_ = []\n",
    "                bic_ = []\n",
    "                n_parametros_ = []\n",
    "                parametros_ = []\n",
    "                \n",
    "                for j, distribucion in enumerate(distribuciones):\n",
    "                    \n",
    "                    # print(f\"{j+1}/{len(distribuciones)} Ajustando distribución: {distribucion.name}\")\n",
    "                    \n",
    "                    try:\n",
    "                        parametros = distribucion.fit(data=x)\n",
    "                        nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                            if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                        parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "                        log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "                        aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                        bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "                        \n",
    "                        distribucion_.append(distribucion.name)\n",
    "                        log_likelihood_.append(log_likelihood)\n",
    "                        aic_.append(aic)\n",
    "                        bic_.append(bic)\n",
    "                        n_parametros_.append(len(parametros))\n",
    "                        parametros_.append(parametros_dict)\n",
    "                        \n",
    "                        resultados = pd.DataFrame({\n",
    "                                        'distribucion': distribucion_,\n",
    "                                        'log_likelihood': log_likelihood_,\n",
    "                                        'aic': aic_,\n",
    "                                        'bic': bic_,\n",
    "                                        'n_parametros': n_parametros_,\n",
    "                                        'parametros': parametros_,\n",
    "                            \n",
    "                                    })\n",
    "                        \n",
    "                        resultados = resultados.sort_values(by=ordenar).reset_index(drop=True)\n",
    "\n",
    "                        \n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al tratar de ajustar la distribución {distribucion.name}\")\n",
    "                        print(e)\n",
    "                        print(\"\")\n",
    "\n",
    "                nombre_distribuciones=resultados['distribucion'][:5]\n",
    "                fig, ax = plt.subplots(figsize=(7,4))\n",
    "                \n",
    "                \n",
    "                ax.hist(x=x, density=True, bins=30, color=\"#3182bd\", alpha=0.5)\n",
    "                ax.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "                ax.set_title('Ajuste distribuciones')\n",
    "                ax.set_xlabel('x')\n",
    "                ax.set_ylabel('Densidad de probabilidad')\n",
    "                \n",
    "                for nombre in nombre_distribuciones:\n",
    "                    \n",
    "                    distribucion = getattr(stats, nombre)\n",
    "\n",
    "                    parametros = distribucion.fit(data=x)\n",
    "\n",
    "                    nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                        if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                    parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "\n",
    "                    log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "\n",
    "                    aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                    bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "\n",
    "                    x_hat = np.linspace(min(x), max(x), num=100)\n",
    "                    y_hat = distribucion.pdf(x_hat, *parametros)\n",
    "                    ax.plot(x_hat, y_hat, linewidth=2, label=distribucion.name)\n",
    "            \n",
    "                ax.legend()\n",
    "                plt.show()\n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(resultados.head(5))    \n",
    "                print(\"\\n------------------------------------------------------------------\\n\")\n",
    "\n",
    "    def remove_outliers(self, k=1.5):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        for column in aux:\n",
    "            print(f\"\\n\\n                    <<<<<<<<<<<<<<<<<<<<<<<< {column} >>>>>>>>>>>>>>>>>>>>>>>>\\n\\n\")\n",
    "            self.plot_outliers2(column, k=1.5)\n",
    "            q1, q3 = self[column].quantile([0.25, 0.75])\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - (k * iqr)\n",
    "            upper_bound = q3 + (k * iqr)\n",
    "            self.loc[(self[column] < lower_bound) | (self[column] > upper_bound), column] = None    \n",
    "        self.nulos()\n",
    "        self.outliers_hecho=False\n",
    "\n",
    "\n",
    "    def plot_outliers(self, column, k=1.5):\n",
    "        \n",
    "        q1, q3 = self[column].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (k * iqr)\n",
    "        upper_bound = q3 + (k * iqr)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(self.index, self[column], color='blue', label='inlier')\n",
    "        ax.scatter(self[(self[column] < lower_bound) | (self[column] > upper_bound)].index,\n",
    "                self[(self[column] < lower_bound) | (self[column] > upper_bound)][column],\n",
    "                color='red', label='outlier')\n",
    "        ax.axhline(lower_bound, color='gray', linestyle='--')\n",
    "        ax.axhline(upper_bound, color='gray', linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.show() \n",
    "\n",
    "    \n",
    "    def plot_outliers2(df, column, k=1.5):\n",
    "        q1, q3 = df[column].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (k * iqr)\n",
    "        upper_bound = q3 + (k * iqr)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(df.index, df[column], color='blue')\n",
    "        ax.scatter(df[df[column].isnull()].index,\n",
    "                df[df[column].isnull()][column],\n",
    "                color='red', marker='x')\n",
    "        ax.axhline(lower_bound, color='red', linestyle='--')\n",
    "        ax.axhline(upper_bound, color='red', linestyle='--')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_xy_data(df, x_column, y_column):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(df[x_column], df[y_column])\n",
    "        plt.xlabel(x_column)\n",
    "        plt.ylabel(y_column)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def reg_lineal(self, predictores, OUTCOME):\n",
    "        aux1=set(predictores)\n",
    "        aux2=set(list(self.cuali.columns))\n",
    "        \n",
    "\n",
    "        if (aux1.intersection(aux2)): \n",
    "            print(\"Tienes alguna variable cualitativa en los predictores\")\n",
    "        elif(OUTCOME in list(self.cuali.columns)):\n",
    "            print(\"OUTCOME es cualitativa\") \n",
    "        #No funciona con NA ni con distinta longitud dentro de los DF\n",
    "        if (self.outliers_hecho):\n",
    "            try:\n",
    "                self.remove_outliers()\n",
    "                self.predicotres=self[predictores]\n",
    "                self.outcome=self[OUTCOME]\n",
    "                ej_lm=LinearRegression()\n",
    "                ej_lm.fit(self.predicotres,self.outcome)\n",
    "\n",
    "                for name, coef in zip(predictores,ej_lm.coef_):\n",
    "                    print(f\"{name}: {coef}\")\n",
    "\n",
    "                fitted= ej_lm.predict(self.predicotres)\n",
    "                RMSE= np.sqrt(mean_squared_error(self.outcome,fitted))\n",
    "                r2= r2_score(self.outcome,fitted) \n",
    "\n",
    "                # RMSE es como el accuracy del modelo (es practicamente igual al RSE)\n",
    "                print(f\"- RMSE: {RMSE:.0f}\")\n",
    "\n",
    "                # coeficiente de determinación:  0-1 proporción de varianza en los datos\n",
    "                # que estan contabilizados en el modelo\n",
    "                print(f\"- R2: {r2:.4f}\")\n",
    "                model=sm.OLS(self.outcome,self.predicotres.assign(const=1) )\n",
    "                resul=model.fit()\n",
    "                print(\"\\n - RESUMEN \\n\")\n",
    "                print( resul.summary())\n",
    "                return ej_lm\n",
    "            except:\n",
    "                print(\"Puede que haya columans con distinta longitud\")\n",
    "\n",
    "        elif (self[predictores].isna().any().any()):\n",
    "            print(\"HAY VALORES NULOS EN LAS COLUMNAS Y YA HAS HECHO LA FUNCIÓN DE OUTLIERS\")\n",
    "\n",
    "        else :\n",
    "            try:\n",
    "                self.predicotres=self[predictores]\n",
    "                self.outcome=self[OUTCOME]\n",
    "                ej_lm=LinearRegression()\n",
    "                ej_lm.fit(self.predicotres,self.outcome)\n",
    "\n",
    "                for name, coef in zip(predictores,ej_lm.coef_):\n",
    "                    print(f\"{name}: {coef}\")\n",
    "\n",
    "                fitted= ej_lm.predict(self.predicotres)\n",
    "                RMSE= np.sqrt(mean_squared_error(self.outcome,fitted))\n",
    "                r2= r2_score(self.outcome,fitted) \n",
    "\n",
    "                # RMSE es como el accuracy del modelo (es practicamente igual al RSE)\n",
    "                print(f\"- RMSE: {RMSE:.0f}\")\n",
    "\n",
    "                # coeficiente de determinación:  0-1 proporción de varianza en los datos\n",
    "                # que estan contabilizados en el modelo\n",
    "                print(f\"- R2: {r2:.4f}\")\n",
    "                model=sm.OLS(self.outcome,self.predicotres.assign(const=1) )\n",
    "                resul=model.fit()\n",
    "                print(\"\\n ------------------------- RESUMEN --------------------------- \\n\")\n",
    "                print( resul.summary())\n",
    "                return ej_lm\n",
    "            except:\n",
    "                print(\"Puede que haya columans con distinta longitud\")\n",
    "\n",
    "\n",
    "    def forward_selected(self):\n",
    "        \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "        response: string, name of response column in data\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        model: an \"optimal\" fitted statsmodels linear model\n",
    "            with an intercept\n",
    "            selected by forward selection\n",
    "            evaluated by adjusted R-squared\n",
    "        \"\"\"\n",
    "        data=pd.merge(self.predicotres, self.outcome,left_index=True, right_index=True)\n",
    "        response=self.outcome.columns[0]\n",
    "\n",
    "        remaining = set(data.columns)\n",
    "        remaining.remove(response)\n",
    "        selected = []\n",
    "        current_score, best_new_score = 0.0, 0.0\n",
    "        while remaining and current_score == best_new_score:\n",
    "            scores_with_candidates = []\n",
    "            for candidate in remaining:\n",
    "                formula = \"{} ~ {} + 1\".format(response,\n",
    "                                            ' + '.join(selected + [candidate]))\n",
    "                score = ols(formula, data).fit().rsquared_adj\n",
    "                scores_with_candidates.append((score, candidate))\n",
    "            scores_with_candidates.sort()\n",
    "            best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "            if current_score < best_new_score:\n",
    "                remaining.remove(best_candidate)\n",
    "                selected.append(best_candidate)\n",
    "                current_score = best_new_score\n",
    "        formula = \"{} ~ {} + 1\".format(response,\n",
    "                                    ' + '.join(selected))\n",
    "        model = ols(formula, data).fit()\n",
    "\n",
    "        print (f\"Formula: {model.model.formula}\")\n",
    "        print (f\"Ajuste por R2: {model.rsquared_adj}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def weighted_regression(self, weights):\n",
    "        X = self.predicotres.values\n",
    "        y = self.outcome.values\n",
    "        w = weights.values\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y, sample_weight=w)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def codificar_catego(self,modelo,cate_var:str):\n",
    "        self['residuos']=(self.outcome-modelo.predict(self.predicotres))\n",
    "        self['residuos']\n",
    "        self[cate_var]= self[cate_var]\n",
    "        grupos1_aux= pd.merge(self[cate_var], self['residuos'],left_index=True, right_index=True)\n",
    "        grupos1_agrupado=grupos1_aux.groupby([cate_var])\n",
    "\n",
    "        summary_function = lambda x: {\n",
    "            cate_var: x.iloc[0,0],\n",
    "            'count': len(x),\n",
    "            'residuo_medio': x.residuos.median()\n",
    "        }\n",
    "        \n",
    "        group_summaries = grupos1_agrupado.apply(summary_function)\n",
    "        final_df = pd.DataFrame([    *group_summaries])\n",
    "        grupos1 = final_df.sort_values('residuo_medio')\n",
    "        grupos1['cum_count']=np.cumsum(grupos1['count'])\n",
    "        grupos1['Col_a_codificar_grupos']=pd.qcut(grupos1['cum_count'],5,labels=False,retbins=False)\n",
    "        to_join= grupos1[[cate_var,'Col_a_codificar_grupos']].set_index(cate_var)\n",
    "\n",
    "        self=self.join(to_join, on=cate_var)\n",
    "        return (self[[cate_var,'Col_a_codificar_grupos']])\n",
    "    \n",
    "    def regre_con_interaccion_de_var(self,outcome,predictores,lista_predictores_condicionados):\n",
    "        frase=outcome+\" ~\"\n",
    "        frase_aux1=\"\"\n",
    "        frase_aux2=\"\"\n",
    "        aux=0\n",
    "        for i, j in lista_predictores_condicionados:\n",
    "            if aux==0:\n",
    "                frase_aux1=i+\"*\"+j\n",
    "            else:\n",
    "                frase_aux1=frase_aux1+\"+\"+i+\"*\"+j\n",
    "            aux=aux+1\n",
    "        for i in predictores:\n",
    "            frase_aux2=frase_aux2+\"+\"+i\n",
    "        frase=frase+frase_aux1+frase_aux2\n",
    "        print(f\" Formula final: {frase} \\n\\n\")\n",
    "        model=smf.ols(formula= frase,data=self )\n",
    "        results=model.fit()\n",
    "        return results.summary()\n",
    "    \n",
    "\n",
    "    def regre_outliers(self, cate=None, grupo=None):\n",
    "\n",
    "        if cate==None:\n",
    "            ej_outliers=sm.OLS(self.outcome, self.predicotres.assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "\n",
    "            influence=OLSInfluence(resul_1)\n",
    "            sresiduals= influence.resid_studentized_internal\n",
    "\n",
    "            outliers=self.loc[sresiduals.idxmin(), :]\n",
    "            print(\"resultado\", outliers[list(self.outcome.columns)])\n",
    "            print(outliers[list(self.predicotres.columns)])\n",
    "\n",
    "\n",
    "            print(\"puntos con alta influencia y distancia de Cooks mayor de 0.08\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            ax.axhline(-2.5, linestyle='--', color='C1')\n",
    "            ax.axhline(2.5, linestyle='--', color='C1')\n",
    "            ax.scatter(influence.hat_matrix_diag, \n",
    "                    influence.resid_studentized_internal,\n",
    "                    s=1000*np.sqrt(influence.cooks_distance[0]), \n",
    "                    alpha=0.5)\n",
    "            ax.set_xlabel('hat values')\n",
    "            ax.set_ylabel('studentized residuals')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            print(\"predictores vs residuos para ver heteroskedascity\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            df = pd.DataFrame({'fitted': resul_1.fittedvalues, \n",
    "                            'residuals': np.abs(resul_1.resid)})\n",
    "            sns.regplot(x='fitted', y='residuals', data=df, scatter_kws={'alpha':0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax)\n",
    "            ax.set_xlabel('predictos')\n",
    "            ax.set_ylabel('abs(residuos)')\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "            ej_outliers=sm.OLS(datos_agru[list(self.outcome.columns)], datos_agru[list(self.predicotres.columns)].assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "\n",
    "            influence=OLSInfluence(resul_1)\n",
    "            sresiduals= influence.resid_studentized_internal\n",
    "\n",
    "            outliers=datos_agru.loc[sresiduals.idxmin(), :]\n",
    "            print(\"resultado\", outliers[list(self.outcome.columns)])\n",
    "            print(outliers[list(self.predicotres.columns)])\n",
    "\n",
    "            print(\"puntos con alta influencia y distancia de Cooks mayor de 0.08\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            ax.axhline(-2.5, linestyle='--', color='C1')\n",
    "            ax.axhline(2.5, linestyle='--', color='C1')\n",
    "            ax.scatter(influence.hat_matrix_diag, \n",
    "                    influence.resid_studentized_internal,\n",
    "                    s=1000*np.sqrt(influence.cooks_distance[0]), \n",
    "                    alpha=0.5)\n",
    "            ax.set_xlabel('hat values')\n",
    "            ax.set_ylabel('studentized residuals')\n",
    "            plt.show()\n",
    "\n",
    "            print(\"predictores vs residuos para ver heteroskedascity\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            df = pd.DataFrame({'fitted': resul_1.fittedvalues, \n",
    "                            'residuals': np.abs(resul_1.resid)})\n",
    "            sns.regplot(x='fitted', y='residuals', data=df, scatter_kws={'alpha':0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax)\n",
    "            ax.set_xlabel('predictos')\n",
    "            ax.set_ylabel('abs(residuos)')\n",
    "            plt.show()\n",
    "\n",
    "    def infl_residual_modelo(self, var_influ, cate=None, grupo=None):\n",
    "        if cate==None:\n",
    "            ej_outliers=sm.OLS(self.outcome, self.predicotres.assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "            sm.graphics.plot_ccpr(resul_1,var_influ)\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fig = sm.graphics.plot_ccpr_grid(resul_1, fig=fig)\n",
    "        \n",
    "        else:\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "            ej_outliers=sm.OLS(datos_agru[list(self.outcome.columns)], datos_agru[list(self.predicotres.columns)].assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "            sm.graphics.plot_ccpr(resul_1,var_influ)\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fig = sm.graphics.plot_ccpr_grid(resul_1, fig=fig)\n",
    "\n",
    "    def regre_poly(self,variables_exp,expo,cate=None, grupo=None,verbose=False):\n",
    "\n",
    "        if cate==None:\n",
    "\n",
    "            out=list(self.outcome.columns)\n",
    "            predic=list(self.predicotres.columns)\n",
    "\n",
    "            frase=out[0]+\" ~ \"\n",
    "            variables_no_exp = [element for element in predic if element not in variables_exp]\n",
    "            frase_expo=\"\"\n",
    "            frase_no_expo=\"\"\n",
    "\n",
    "            for i,j in zip(variables_exp,expo):\n",
    "                frase_expo=frase_expo + f\"np.power({i}, {j}) + \" \n",
    "\n",
    "            for indice,i in enumerate(variables_no_exp):\n",
    "                if indice == len(variables_no_exp)-1:\n",
    "                    frase_no_expo=frase_no_expo+i    \n",
    "                else: \n",
    "                    frase_no_expo=frase_no_expo+i+ \"+\"   \n",
    "\n",
    "            frase=frase+frase_expo+frase_no_expo\n",
    "            print(frase)\n",
    "            \n",
    "            model_poly = smf.ols(formula=frase, data=self)\n",
    "            result_poly = model_poly.fit()\n",
    "            if (verbose):\n",
    "             print(result_poly.summary())\n",
    "\n",
    "        else:\n",
    "\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "\n",
    "            out=list(self.outcome.columns)\n",
    "            predic=list(self.predicotres.columns)\n",
    "\n",
    "            frase=out[0]+\" ~ \"\n",
    "            variables_no_exp = [element for element in predic if element not in variables_exp]\n",
    "            frase_expo=\"\"\n",
    "            frase_no_expo=\"\"\n",
    "\n",
    "            for i,j in zip(variables_exp,expo):\n",
    "                frase_expo=frase_expo + f\"np.power({i}, {j}) + \" \n",
    "\n",
    "            for indice,i in enumerate(variables_no_exp):\n",
    "                if indice == len(variables_no_exp)-1:\n",
    "                    frase_no_expo=frase_no_expo+i    \n",
    "                else: \n",
    "                    frase_no_expo=frase_no_expo+i+ \"+\"   \n",
    "\n",
    "            frase=frase+frase_expo+frase_no_expo\n",
    "            print(frase)\n",
    "            \n",
    "            model_poly = smf.ols(formula=frase, data=datos_agru)\n",
    "            result_poly = model_poly.fit()\n",
    "            if (verbose):\n",
    "                print(result_poly.summary())\n",
    "\n",
    "        return result_poly\n",
    "        \n",
    "\n",
    "    def partialResidualPlot(self, model, feature):\n",
    "        df= pd.merge(self.predicotres, self.outcome, left_index=True, right_index=True)\n",
    "        outcome= list(self.outcome.columns)\n",
    "\n",
    "        y_pred = model.predict(df)\n",
    "        copy_df = df.copy()\n",
    "        for c in copy_df.columns:\n",
    "            if c == feature:\n",
    "                continue\n",
    "            copy_df[c] = 0.0\n",
    "        feature_prediction = model.predict(copy_df)\n",
    "        \n",
    "        \n",
    "        residual=df[outcome].values - y_pred.values\n",
    "        results = pd.DataFrame({\n",
    "            'feature': df[feature].values,\n",
    "            'residual': residual[0],\n",
    "            'ypartial': feature_prediction.values - model.params[0],\n",
    "        })\n",
    "\n",
    "        results = results.sort_values(by=['feature'])\n",
    "        smoothed = sm.nonparametric.lowess(results.ypartial, results.feature, frac=1/3)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "        ax.scatter(results.feature, results.ypartial + results.residual)\n",
    "        ax.plot(smoothed[:, 0], smoothed[:, 1], color='gray')\n",
    "        ax.plot(results.feature, results.ypartial, color='black')\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(f'Residual + {feature} contribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def plot_partial_residuals_poly(self,variables_exp,expo,variable ,cate=None, grupo=None):\n",
    "        model=self.regre_poly(variables_exp,expo,cate, grupo)\n",
    "        self.partialResidualPlot(model,variable)\n",
    "\n",
    "    \n",
    "    def clasificador_bayes(self,predictores,outcome,new):\n",
    "        X =self[predictores]\n",
    "        y = self[outcome]\n",
    "\n",
    "        naive_model = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "        naive_model = MultinomialNB(alpha=1e-10, fit_prior=False)\n",
    "        naive_model.fit(X, y)\n",
    "\n",
    "        print(\"Input en el modelo bayesiano: \")\n",
    "        print(new)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print('Clase más probable: ', naive_model.predict(new)[0])\n",
    "\n",
    "        probabilities = pd.DataFrame(naive_model.predict_proba(new),columns=naive_model.classes_)\n",
    "        print('Probabilidades de cada clase:',)\n",
    "        print(probabilities)\n",
    "\n",
    "    def accuracy_bayes(self,predictores,outcome):\n",
    "        X =self[predictores]\n",
    "        y = self[outcome]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        modelo_gausian = GaussianNB()\n",
    "        \n",
    "        modelo_gausian .fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo_gausian .predict(X_test)\n",
    "\n",
    "        precision_gausian  = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"La precisión del modelo gaussiano de bayes es: {precision_gausian }\")\n",
    "\n",
    "        modelo_multino=MultinomialNB()\n",
    "\n",
    "        modelo_multino.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo_multino.predict(X_test)\n",
    "\n",
    "        precision_multino = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"La precisión del modelo multinomial de bayes es: {precision_multino}\")\n",
    "\n",
    "    def predict_lda(self,predictors,outcome):\n",
    "        X=self[predictors]\n",
    "        y=self[outcome]\n",
    "\n",
    "        modelo_lda = LinearDiscriminantAnalysis()\n",
    "        modelo_lda.fit(X, y)\n",
    "        y_pred = modelo_lda.predict(X)\n",
    "\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        print(\"Accuracy modelo LDA:\", accuracy)\n",
    "\n",
    "    def GLM_datos(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "\n",
    "            logit_reg_sm = sm.GLM(y, X.assign(const=1), \n",
    "                                family=sm.families.Binomial())\n",
    "            logit_result = logit_reg_sm.fit()\n",
    "            print(logit_result.summary())\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "\n",
    "    def GLM_datos_formula(self,predictors,outcome,formula):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            data=pd.merge(y, X,left_index=True, right_index=True)\n",
    "            model = glm(formula=formula, data=data, family=sm.families.Binomial())\n",
    "            results = model.fit()\n",
    "            print(results.summary())\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "\n",
    "    def mat_conf(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            logit_reg = LogisticRegression(penalty='l2', C=1e42, solver='liblinear')\n",
    "            logit_reg.fit(X, y)\n",
    "\n",
    "            print(' - Intercept ', logit_reg.intercept_[0])\n",
    "            print(' - Classes', logit_reg.classes_)\n",
    "            pd.DataFrame({'coeff': logit_reg.coef_[0]}, \n",
    "                        index=X.columns)\n",
    "\n",
    "            # Confusion matrix\n",
    "            pred = logit_reg.predict(X)\n",
    "            pred_y = logit_reg.predict(X) == \"0\"\n",
    "            true_y = y == \"0\"\n",
    "            true_pos = true_y & pred_y\n",
    "            true_neg = ~true_y & ~pred_y\n",
    "            false_pos = ~true_y & pred_y\n",
    "            false_neg = true_y & ~pred_y\n",
    "\n",
    "            conf_mat = pd.DataFrame([[np.sum(true_pos), np.sum(false_neg)], [np.sum(false_pos), np.sum(true_neg)]],\n",
    "                                index=['Y = 0', 'Y = 1'],\n",
    "                                columns=['Yhat = 1', 'Yhat = 0'])\n",
    "            # print(conf_mat)\n",
    "\n",
    "            # print(confusion_matrix(y, logit_reg.predict(X)))\n",
    "            print(\"\\n*******************************\")\n",
    "            classificationSummary(y, logit_reg.predict(X), \n",
    "                                class_names=logit_reg.classes_)\n",
    "            print(\"\\n*******************************\")\n",
    "            \n",
    "            self.prec_sens_espe(predictors,outcome,logit_reg)\n",
    "            self.ROC_curva(predictors,outcome,logit_reg)\n",
    "                        \n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "    \n",
    "    def prec_sens_espe(self,predictors,outcome,logit_reg):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            conf_mat = confusion_matrix(y, logit_reg.predict(X))\n",
    "            print(' - Precision', conf_mat[0, 0] / sum(conf_mat[:, 0]))\n",
    "            print(' - Sensibilidad', conf_mat[0, 0] / sum(conf_mat[0, :]))\n",
    "            print(' - Especificidad', conf_mat[1, 1] / sum(conf_mat[1, :]))\n",
    "\n",
    "            precision_recall_fscore_support(y, logit_reg.predict(X), \n",
    "                                            labels=['0', '1'])\n",
    "            \n",
    "\n",
    "    def ROC_curva(self,predictors,outcome,logit_reg):\n",
    "\n",
    "        y= self[outcome]\n",
    "        X= self[predictors]\n",
    "        fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:, 0], pos_label=0)\n",
    "        roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "        ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(1, 0)\n",
    "        ax.plot((1, 0), (0, 1))\n",
    "        ax.set_xlabel('Especificidad')\n",
    "        ax.set_ylabel('Sensibilidad')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:,0], \n",
    "                                        pos_label=0)\n",
    "        roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "\n",
    "        ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(1, 0)\n",
    "        # ax.plot((1, 0), (0, 1))\n",
    "        ax.set_xlabel('Especificidad')\n",
    "        ax.set_ylabel('Sensibilidad')\n",
    "        ax.fill_between(roc_df.specificity, 0, roc_df.recall, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def oversampling(self,predictors,outcome):\n",
    "        X= self[predictors]\n",
    "        y=self[outcome]\n",
    "        positive_wt = 1 / np.mean(y==1)\n",
    "        # default_wt = 1 / (np.sum(dummys.ES_NO_ES_s)/len(dummys.ES_NO_ES_s))\n",
    "        # default_wt = 1 / np.mean(dummys.ES_NO_ES_s)\n",
    "        wt = [positive_wt if outcome == 1 else 1 for outcome in y]\n",
    "\n",
    "        full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "        full_model.fit(X, y,wt)\n",
    "        print('Porcentaje de valores predichos (weighting): ') \n",
    "        print( 100 * np.mean(full_model.predict(X) == 1) )  \n",
    "\n",
    "    def data_gen(self,predictors,outcome):\n",
    "        X= self[predictors]\n",
    "        y=self[outcome]\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "        print('Porcentaje de elemetos positivos predichos (SMOTE resampled): ', \n",
    "            100 * np.mean(y_resampled == 1))\n",
    "        \n",
    "        full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "        full_model.fit(X_resampled, y_resampled)\n",
    "        print('Porcentaje de elemetos positivos predichos  (SMOTE): ', \n",
    "            100 * np.mean(full_model.predict(X) ==1 ))\n",
    "\n",
    "    def explo_predict(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y=self[outcome]\n",
    "            X=self[predictors]\n",
    "            loan_tree = DecisionTreeClassifier(random_state=1, criterion='entropy', \n",
    "                                            min_impurity_decrease=0.003)\n",
    "            loan_tree.fit(X, y)\n",
    "\n",
    "            loan_lda = LinearDiscriminantAnalysis()\n",
    "            loan_lda.fit(X, y)\n",
    "\n",
    "            logit_reg = LogisticRegression(penalty=\"l2\", solver='liblinear')\n",
    "            logit_reg.fit(X, y)\n",
    "\n",
    "\n",
    "            ## model\n",
    "            gam = LinearGAM(s(0) + s(1))\n",
    "            print(gam.gridsearch(X.values, y.values))\n",
    "\n",
    "            models = {\n",
    "                'Decision Tree': loan_tree,\n",
    "                'Linear Discriminant Analysis': loan_lda,\n",
    "                'Logistic Regression': logit_reg,\n",
    "                'Generalized Additive Model': gam,\n",
    "            }\n",
    "\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(5, 5))\n",
    "\n",
    "            xvalues = np.arange(0.25, 0.73, 0.005)\n",
    "            yvalues = np.arange(-0.1, 20.1, 0.1)\n",
    "            xx, yy = np.meshgrid(xvalues, yvalues)\n",
    "            X = pd.DataFrame({\n",
    "                'Datos_F': xx.ravel(),\n",
    "                'Datos_E': yy.ravel(),\n",
    "            })\n",
    "\n",
    "            boundary = {}\n",
    "\n",
    "            for n, (title, model) in enumerate(models.items()):\n",
    "                ax = axes[n // 2, n % 2]\n",
    "                predict = model.predict(X)\n",
    "                if 'Generalized' in title:\n",
    "                    Z = np.array([1 if z > 0.5 else 0 for z in predict])\n",
    "                else:\n",
    "                    \n",
    "                    Z = np.array([1 if z == 1 else 0 for z in predict])\n",
    "                Z = Z.reshape(xx.shape)\n",
    "                boundary[title] = yvalues[np.argmax(Z > 0, axis=0)]\n",
    "                boundary[title][Z[-1,:] == 0] = yvalues[-1]\n",
    "\n",
    "                c = ax.pcolormesh(xx, yy, Z, cmap='Blues', vmin=0.1, vmax=1.3, shading='auto')\n",
    "                ax.set_title(title)\n",
    "                ax.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            boundary['Datos_F'] = xvalues\n",
    "            boundaries = pd.DataFrame(boundary)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(5, 4))\n",
    "            boundaries.plot(x='Datos_F', ax=ax)\n",
    "            ax.set_ylabel('Datos_E')\n",
    "            ax.set_ylim(0, 20)\n",
    "\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "\n",
    "    def KNN_predict(self,predictors,outcome,new):\n",
    "        y=self[outcome]\n",
    "        X=self[predictors]\n",
    "        knn = KNeighborsClassifier(n_neighbors=40)\n",
    "        knn.fit(X, y)\n",
    "        data=pd.DataFrame({'result':knn.predict_proba(new)[:,1]})\n",
    "        print( data['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACIÓN DE LA CLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo=DF_exploracion(df_prueba)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINICIÓN DE LAS VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  ES_NO_ES \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  sexo \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_C \n",
      "|   - Tipo de dato: int32 \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_D \n",
      "|   - Tipo de dato: float64 \n",
      "|   - Valores repetidos: 1000 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_E \n",
      "|   - Tipo de dato: float64 \n",
      "|   - Valores repetidos: 1000 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Poisson_1 \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 13 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Poisson_3 \n",
      "|   - Tipo de dato: int32 \n",
      "|   - Valores repetidos: 21 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Geom \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 5 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_F \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 630 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_G \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 636 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_A \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 6 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_B \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 4 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_C \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 60 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|----------------------------------------------------------------------------------------------------\n",
      "|  TODAS: Index(['ES_NO_ES', 'sexo', 'Datos_C', 'Datos_D', 'Datos_E', 'Datos_Poisson_1',\n",
      "       'Datos_Poisson_3', 'Datos_Geom', 'Datos_F', 'Datos_G', 'Datos_cate_A',\n",
      "       'Datos_cate_B', 'Datos_cate_C'],\n",
      "      dtype='object') \n",
      "|  DICOTOMICAS: ['ES_NO_ES', 'sexo', 'Datos_C'] \n",
      "|  CATEGORICAS: ['Datos_Geom', 'Datos_cate_A', 'Datos_cate_B'] \n",
      "|  CUANTITATIVAS: ['Datos_D', 'Datos_E', 'Datos_Poisson_1', 'Datos_Poisson_3', 'Datos_F', 'Datos_G', 'Datos_cate_C'] \n",
      "|  ELIMINAR: []\n",
      "|----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ejemplo.variables()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de variables dummys a traves de dicotómicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** self.dummy ************\n",
      "\n",
      "     ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  Datos_C_1\n",
      "0             0           1       1       0          0          1\n",
      "1             0           1       0       1          1          0\n",
      "2             0           1       1       0          1          0\n",
      "3             0           1       0       1          1          0\n",
      "4             1           0       0       1          0          1\n",
      "..          ...         ...     ...     ...        ...        ...\n",
      "995           1           0       1       0          1          0\n",
      "996           1           0       1       0          1          0\n",
      "997           1           0       0       1          0          1\n",
      "998           1           0       0       1          1          0\n",
      "999           0           1       1       0          0          1\n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "\n",
      "********************** self.df o todas_las_col() ************\n",
      "\n",
      "    ES_NO_ES sexo  Datos_C   Datos_D   Datos_E  Datos_Poisson_1  \\\n",
      "0          s    h        1 -0.865482  2.218243                3   \n",
      "1          s    m        0 -0.551563  1.277139                3   \n",
      "2          s    h        0 -1.939156  0.500810                3   \n",
      "3          s    m        0 -1.614695 -0.927663                8   \n",
      "4          n    m        1  2.296360  1.571919                3   \n",
      "..       ...  ...      ...       ...       ...              ...   \n",
      "995        n    h        0 -1.345801 -0.122408                3   \n",
      "996        n    h        0  0.686523  0.439259                2   \n",
      "997        n    m        1 -1.621615  0.365545                2   \n",
      "998        n    m        0 -0.436986 -0.867003                4   \n",
      "999        s    h        1  1.772074  0.614434                7   \n",
      "\n",
      "     Datos_Poisson_3  Datos_Geom  Datos_F  Datos_G Datos_cate_A Datos_cate_B  \\\n",
      "0                  6           1      609      913      Grupo 1      Grupo 2   \n",
      "1                  8           2      989      549      Grupo 5      Grupo 2   \n",
      "2                  6           1      780      599      Grupo 4      Grupo 2   \n",
      "3                 10           3      376        7      Grupo 1      Grupo 2   \n",
      "4                  8           1      756       24      Grupo 1      Grupo 0   \n",
      "..               ...         ...      ...      ...          ...          ...   \n",
      "995               10           1      370      535      Grupo 4      Grupo 3   \n",
      "996                8           1      423      602      Grupo 3      Grupo 0   \n",
      "997               11           2      456      337      Grupo 2      Grupo 3   \n",
      "998               12           1      779      694      Grupo 5      Grupo 0   \n",
      "999                2           1      818       78      Grupo 0      Grupo 2   \n",
      "\n",
      "     Datos_cate_C  ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  \\\n",
      "0              34           0           1       1       0          0   \n",
      "1              53           0           1       0       1          1   \n",
      "2              11           0           1       1       0          1   \n",
      "3              38           0           1       0       1          1   \n",
      "4              38           1           0       0       1          0   \n",
      "..            ...         ...         ...     ...     ...        ...   \n",
      "995            12           1           0       1       0          1   \n",
      "996            57           1           0       1       0          1   \n",
      "997            57           1           0       0       1          0   \n",
      "998             2           1           0       0       1          1   \n",
      "999             8           0           1       1       0          0   \n",
      "\n",
      "     Datos_C_1  \n",
      "0            1  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            1  \n",
      "..         ...  \n",
      "995          0  \n",
      "996          0  \n",
      "997          1  \n",
      "998          0  \n",
      "999          1  \n",
      "\n",
      "[1000 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "ejemplo.limpiar_dummys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES_NO_ES</th>\n",
       "      <th>sexo</th>\n",
       "      <th>Datos_C</th>\n",
       "      <th>Datos_D</th>\n",
       "      <th>Datos_E</th>\n",
       "      <th>Datos_Poisson_1</th>\n",
       "      <th>Datos_Poisson_3</th>\n",
       "      <th>Datos_Geom</th>\n",
       "      <th>Datos_F</th>\n",
       "      <th>Datos_G</th>\n",
       "      <th>Datos_cate_A</th>\n",
       "      <th>Datos_cate_B</th>\n",
       "      <th>Datos_cate_C</th>\n",
       "      <th>ES_NO_ES_n</th>\n",
       "      <th>ES_NO_ES_s</th>\n",
       "      <th>sexo_h</th>\n",
       "      <th>sexo_m</th>\n",
       "      <th>Datos_C_0</th>\n",
       "      <th>Datos_C_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.865482</td>\n",
       "      <td>2.218243</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>609</td>\n",
       "      <td>913</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.551563</td>\n",
       "      <td>1.277139</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>989</td>\n",
       "      <td>549</td>\n",
       "      <td>Grupo 5</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.939156</td>\n",
       "      <td>0.500810</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "      <td>599</td>\n",
       "      <td>Grupo 4</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.614695</td>\n",
       "      <td>-0.927663</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>376</td>\n",
       "      <td>7</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>2.296360</td>\n",
       "      <td>1.571919</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>756</td>\n",
       "      <td>24</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.345801</td>\n",
       "      <td>-0.122408</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>535</td>\n",
       "      <td>Grupo 4</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686523</td>\n",
       "      <td>0.439259</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>602</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.621615</td>\n",
       "      <td>0.365545</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>456</td>\n",
       "      <td>337</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.436986</td>\n",
       "      <td>-0.867003</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>779</td>\n",
       "      <td>694</td>\n",
       "      <td>Grupo 5</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>1.772074</td>\n",
       "      <td>0.614434</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>818</td>\n",
       "      <td>78</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ES_NO_ES sexo  Datos_C   Datos_D   Datos_E  Datos_Poisson_1  \\\n",
       "0          s    h        1 -0.865482  2.218243                3   \n",
       "1          s    m        0 -0.551563  1.277139                3   \n",
       "2          s    h        0 -1.939156  0.500810                3   \n",
       "3          s    m        0 -1.614695 -0.927663                8   \n",
       "4          n    m        1  2.296360  1.571919                3   \n",
       "..       ...  ...      ...       ...       ...              ...   \n",
       "995        n    h        0 -1.345801 -0.122408                3   \n",
       "996        n    h        0  0.686523  0.439259                2   \n",
       "997        n    m        1 -1.621615  0.365545                2   \n",
       "998        n    m        0 -0.436986 -0.867003                4   \n",
       "999        s    h        1  1.772074  0.614434                7   \n",
       "\n",
       "     Datos_Poisson_3  Datos_Geom  Datos_F  Datos_G Datos_cate_A Datos_cate_B  \\\n",
       "0                  6           1      609      913      Grupo 1      Grupo 2   \n",
       "1                  8           2      989      549      Grupo 5      Grupo 2   \n",
       "2                  6           1      780      599      Grupo 4      Grupo 2   \n",
       "3                 10           3      376        7      Grupo 1      Grupo 2   \n",
       "4                  8           1      756       24      Grupo 1      Grupo 0   \n",
       "..               ...         ...      ...      ...          ...          ...   \n",
       "995               10           1      370      535      Grupo 4      Grupo 3   \n",
       "996                8           1      423      602      Grupo 3      Grupo 0   \n",
       "997               11           2      456      337      Grupo 2      Grupo 3   \n",
       "998               12           1      779      694      Grupo 5      Grupo 0   \n",
       "999                2           1      818       78      Grupo 0      Grupo 2   \n",
       "\n",
       "     Datos_cate_C  ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  \\\n",
       "0              34           0           1       1       0          0   \n",
       "1              53           0           1       0       1          1   \n",
       "2              11           0           1       1       0          1   \n",
       "3              38           0           1       0       1          1   \n",
       "4              38           1           0       0       1          0   \n",
       "..            ...         ...         ...     ...     ...        ...   \n",
       "995            12           1           0       1       0          1   \n",
       "996            57           1           0       1       0          1   \n",
       "997            57           1           0       0       1          0   \n",
       "998             2           1           0       0       1          1   \n",
       "999             8           0           1       1       0          0   \n",
       "\n",
       "     Datos_C_1  \n",
       "0            1  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            1  \n",
       "..         ...  \n",
       "995          0  \n",
       "996          0  \n",
       "997          1  \n",
       "998          0  \n",
       "999          1  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo.df\n",
    "# ejemplo.cuanti\n",
    "# ejemplo.dummy\n",
    "# ejemplo.dico\n",
    "ejemplo.df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de variables agrupadas automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datos con distribución discreta: ['Datos_C', 'Datos_Poisson_1', 'Datos_Poisson_3', 'Datos_Geom', 'Datos_F', 'Datos_G', 'Datos_cate_C']\n",
      "Datos de tipos string seguramente: ['ES_NO_ES', 'sexo', 'Datos_cate_A', 'Datos_cate_B']\n"
     ]
    }
   ],
   "source": [
    "print(f\" Datos con distribución discreta: {ejemplo.discreta}\")\n",
    "print(f\"Datos de tipos string seguramente: {ejemplo.stingg}\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitar algún valor concreto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor 8 no está en la columna\n"
     ]
    }
   ],
   "source": [
    "ejemplo.quita_valor([\"Datos_D\",\"Datos_E\"],[8])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Datos_F_Normalizada\n",
      "0      0.033614\n",
      "1      0.054588\n",
      "2      0.043052\n",
      "3      0.020753\n",
      "4      0.041727\n",
      "         ...   \n",
      "995    0.020422\n",
      "996    0.023347\n",
      "997    0.025169\n",
      "998    0.042997\n",
      "999    0.045150\n",
      "Name: Datos_F_Normalizada, Length: 1000, dtype: float64\n",
      "-------------------------------\n",
      "Datos_G_Normalizada\n",
      "0      0.049713\n",
      "1      0.029893\n",
      "2      0.032616\n",
      "3      0.000381\n",
      "4      0.001307\n",
      "         ...   \n",
      "995    0.029131\n",
      "996    0.032779\n",
      "997    0.018350\n",
      "998    0.037789\n",
      "999    0.004247\n",
      "Name: Datos_G_Normalizada, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ejemplo.normalizar_col([\"Datos_F\",\"Datos_G\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTADISTICA DESCRIPTIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.estadistica_descriptiva_cuantis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.estadistica_descriptiva_cualis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.cross_var_cualis_con_ciantis()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables normales y no normales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.normalidad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación normal por categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.normal_grupos_cate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación normalidad por dicotomicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.normal_grupos_dico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitar outlayers e inputar datos en columnas variables cuantitativas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.remove_outliers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar a distribuciones variables cuantitativas (No puede haber nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.comparar_distribuciones_caunti_cont()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar a distribuciones variables discretas (No puede haber nulos) (Solo poisson y binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.fit_discrete(df_prueba[\"Datos_Poisson_1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejemplo.todos_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ejemplo.plot_bigotes_selec_grupos(['Datos_D','Datos_E'],[\"sexo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ejemplo.plot_bigotes_selec(['Datos_D','Datos_E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_barras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.violines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_normailidad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ESTADISTICOS NO MULTIVARIANTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables cualitativas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.Chi()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables cuantitativas no pareadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.t_test_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilconxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.wilconxon( [\"sexo\",\"Datos_D\" ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.anova()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_confidence_interval(\"Datos_D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictores=['Datos_D','Datos_E','Datos_F']\n",
    "# OUTCOME=['Datos_G']\n",
    "\n",
    "# modelo=ejemplo.reg_lineal(predictores,OUTCOME)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables predictoras en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.forward_selected()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal por pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights=ejemplo[\"Datos_Poisson_1\"]\n",
    "# ejemplo.weighted_regression( weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificar variables categoricas si son muy largas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # si tienes variables con muchas categorias pues \n",
    "    # tendrías un monton de dummys y no es la cosa tampoco \n",
    "    # que va a parecer esto un sudoku (es que además pueden incluso ser practicamente iguales)\n",
    "    # Entonces los puedes codificar usando los residuos de la regresión\n",
    "    # DESPUES NO SE GUARDA COL_A_CODIFICAR_GRUPOS!!!\n",
    "\n",
    "# ejemplo.codificar_catego(modelo,'Datos_cate_C')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadir en el modelo variables correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # interacciones entre variables que entre ellas hacen efecto en el outcome\n",
    "\n",
    "# predictores=[\"Datos_E\",\"Datos_F\"]\n",
    "# lista_predictores_condicionados=[[\"Datos_D\",\"Datos_E\"],[\"Datos_Poisson_1\",\"Datos_Poisson_3\"]]\n",
    "# outcome=\"Datos_G\"\n",
    "# ejemplo.regre_con_interaccion_de_var(outcome,predictores,lista_predictores_condicionados)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Outliers no es lo mismo que en la distribución porque aqui se usa el \n",
    "\n",
    "# ejemplo.regre_outliers(cate=\"Datos_cate_C\",grupo=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuos parciales "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuos parciales: \n",
    "\n",
    "- La función sm.graphics.plot_ccpr de la biblioteca statsmodels es una función para \n",
    "crear un gráfico de la influencia residual del modelo lineal. \n",
    "La función toma como argumentos un objeto de resultado de modelo lineal (resul_1) \n",
    "y un nombre de variable independiente ('Datos_F').\n",
    "\n",
    "- El gráfico de influencia residual se utiliza para evaluar la influencia de cada \n",
    "punto en el ajuste del modelo lineal. En la gráfica, los ejes representan las \n",
    "predicciones del modelo y los residuales absolutos respectivamente. \n",
    "Los puntos son una representación de cada observación en el conjunto de datos, \n",
    "con la posición de cada punto indicando la influencia de esa observación en el modelo.\n",
    "\n",
    "- El gráfico de influencia residual se utiliza para detectar outliers y puntos \n",
    "con influencia anormal en el modelo lineal. Si un punto tiene una influencia \n",
    "anormal en el modelo, puede ser necesario revisar ese punto en el conjunto de datos \n",
    "y considerar si debería ser incluido o excluido del modelo.\n",
    "\n",
    "- En general, un gráfico de influencia residual es una herramienta útil para \n",
    "comprender la calidad del ajuste del modelo lineal y para detectar posibles \n",
    "problemas en los datos o en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.infl_residual_modelo(var_influ='Datos_F', cate=\"Datos_cate_C\",grupo=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_exp=[\"Datos_E\",\"Datos_F\"]\n",
    "# expo=[2,3]\n",
    "\n",
    "# ejemplo.regre_poly(variables_exp,expo, cate=\"Datos_cate_C\",grupo=1,verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot de residuos parciales con regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_exp=[\"Datos_E\",\"Datos_F\"]\n",
    "# expo=[2,3]\n",
    "# grupo=1\n",
    "# variable=\"Datos_F\"\n",
    "# cate=\"Datos_cate_C\"\n",
    "\n",
    "# ejemplo.plot_partial_residuals_poly(variables_exp,expo,variable ,cate, grupo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input en el modelo bayesiano: \n",
      "   Datos_Poisson_3  Datos_Poisson_1  Datos_Geom\n",
      "3               10                8           3\n",
      "\n",
      "\n",
      "Clase más probable:  Grupo 0\n",
      "Probabilidades de cada clase:\n",
      "   Grupo 0   Grupo 1   Grupo 2   Grupo 3   Grupo 4   Grupo 5\n",
      "0  0.19198  0.144261  0.168348  0.149496  0.165218  0.180697\n"
     ]
    }
   ],
   "source": [
    "predictors=['Datos_Poisson_3','Datos_Poisson_1','Datos_Geom']\n",
    "outcome=['Datos_cate_A']\n",
    "\n",
    "#LOS PREDICTORES TODOS EN NÚMEROS, SI SON DICO SE PASAN A DUMMYS\n",
    "# Naive porque predictores independientes \n",
    "\n",
    "ejemplo.clasificador_bayes(predictors,outcome,df_prueba[predictors].loc[3:3, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo gaussiano de bayes es: 0.144\n",
      "La precisión del modelo multinomial de bayes es: 0.14\n"
     ]
    }
   ],
   "source": [
    "ejemplo.accuracy_bayes(predictors,outcome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy modelo LDA: 0.512\n"
     ]
    }
   ],
   "source": [
    "# limitado al número de filas, da igual cuantos predictores mientras \n",
    "# distribución normal pero vamos que puede valer para todo\n",
    "# Outcome categorico \n",
    "\n",
    "predictors=['Datos_Poisson_3','Datos_Geom']\n",
    "outcome=['sexo']\n",
    "\n",
    "ejemplo.predict_lda(predictors,outcome)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_NO_ES_n\n",
      "ES_NO_ES_s\n",
      "sexo_h\n",
      "sexo_m\n",
      "Datos_C_0\n",
      "Datos_C_1\n"
     ]
    }
   ],
   "source": [
    "for i in list(ejemplo.dummy.columns): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ES_NO_ES_s   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      995\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -692.79\n",
      "Date:                Sat, 06 May 2023   Deviance:                       1385.6\n",
      "Time:                        20:07:19   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     3   Pseudo R-squ. (CS):          0.0004570\n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Datos_Poisson_3    -0.0079      0.021     -0.382      0.703      -0.048       0.032\n",
      "Datos_Geom         -0.0273      0.093     -0.295      0.768      -0.209       0.154\n",
      "Datos_F          7.158e-05      0.000      0.325      0.746      -0.000       0.001\n",
      "Datos_E            -0.0223      0.062     -0.357      0.721      -0.145       0.100\n",
      "const               0.1107      0.268      0.413      0.680      -0.415       0.636\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# solo se puede variables dummys (0 y 1)\n",
    "predictors=['Datos_Poisson_3','Datos_Geom',\"Datos_F\",\"Datos_E\"]\n",
    "\n",
    "ejemplo.GLM_datos(predictors,'ES_NO_ES_s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ES_NO_ES_s   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      987\n",
      "Model Family:                Binomial   Df Model:                           12\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -689.40\n",
      "Date:                Sat, 06 May 2023   Deviance:                       1378.8\n",
      "Time:                        20:07:19   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.007208\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept                2.2030      1.270      1.735      0.083      -0.285       4.691\n",
      "bs(Datos_F, df=8)[0]    -0.5065      0.917     -0.553      0.581      -2.303       1.290\n",
      "bs(Datos_F, df=8)[1]     0.3261      0.562      0.581      0.561      -0.775       1.427\n",
      "bs(Datos_F, df=8)[2]    -0.5413      0.692     -0.782      0.434      -1.898       0.816\n",
      "bs(Datos_F, df=8)[3]     0.2453      0.587      0.418      0.676      -0.905       1.395\n",
      "bs(Datos_F, df=8)[4]    -0.0233      0.651     -0.036      0.971      -1.299       1.252\n",
      "bs(Datos_F, df=8)[5]    -0.0131      0.689     -0.019      0.985      -1.363       1.337\n",
      "bs(Datos_F, df=8)[6]    -0.1849      0.728     -0.254      0.800      -1.612       1.242\n",
      "bs(Datos_F, df=8)[7]    -0.3488      0.684     -0.510      0.610      -1.688       0.991\n",
      "Datos_Poisson_3         -0.0056      0.021     -0.270      0.787      -0.046       0.035\n",
      "bs(Datos_E, df=3)[0]    -4.0023      2.252     -1.778      0.075      -8.415       0.411\n",
      "bs(Datos_E, df=3)[1]    -0.7579      0.796     -0.952      0.341      -2.318       0.802\n",
      "bs(Datos_E, df=3)[2]    -2.5369      1.457     -1.741      0.082      -5.392       0.319\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "formula = ('ES_NO_ES_s ~ bs(Datos_F, df=8) + ' +\n",
    "            'Datos_Poisson_3 + bs(Datos_E, df=3)')\n",
    "ejemplo.GLM_datos_formula(predictors,'ES_NO_ES_s',formula)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión + curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Intercept  0.11068310895532368\n",
      " - Classes [0 1]\n",
      "\n",
      "*******************************\n",
      "Confusion Matrix (Accuracy 0.5080)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 108 384\n",
      "     1 108 400\n",
      "\n",
      "*******************************\n",
      " - Precision 0.5\n",
      " - Sensibilidad 0.21951219512195122\n",
      " - Especificidad 0.7874015748031497\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ejemplo.mat_conf(predictors,'ES_NO_ES_s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos no balanceados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Undersample: usar un numero menor de datos de las clases mas prevalentes\n",
    "- Oversample: Usar más datos de la clase rara, bootstrapping\n",
    "- up weight y downweight: Darle más peso a la clase rara o menos a la clase más prev.\n",
    "- Data generation: Parecifo al bootstrapping \n",
    "- z- core: el valor resultante despúes de la estandarización \n",
    "- k:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling y pesos up/downs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de valores predichos (weighting): \n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "ejemplo.oversampling(predictors,'ES_NO_ES_s')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de elemetos positivos predichos (SMOTE resampled):  50.0\n",
      "Porcentaje de elemetos positivos predichos  (SMOTE):  50.6\n"
     ]
    }
   ],
   "source": [
    "ejemplo.data_gen(predictors,'ES_NO_ES_s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploración de predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 27% (3 of 11) |######                   | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 63% (7 of 11) |###############          | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearGAM(callbacks=[Deviance(), Diffs()], fit_intercept=True, \n",
      "   max_iter=100, scale=None, terms=s(0) + s(1) + intercept, \n",
      "   tol=0.0001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors=[\"Datos_F\",\"Datos_E\"]\n",
    "ejemplo.explo_predict(predictors,'ES_NO_ES_n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encuentra los K registros que tengan valor predictivo similar\n",
    "- Se puede usar para clasificar\n",
    "- Se puede usar para predecir \n",
    "\n",
    "Neighbor --> registros con valores predictivos similares entre sí\n",
    "z-score --> Valores de los resultados tras la estandarización\n",
    "\n",
    "características:\n",
    "  -  no hay modelo para ajustar\n",
    "  -  Depende de que esten escalados, similaridad de medidas, y tamaño\n",
    "  -  Solo variables numéricas y ESTANDARIZADAS PORQUE EN VALOR ABS PUEDE DOMINAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n",
      "   Datos_F  Datos_G   Datos_E\n",
      "0      609      913  2.218243\n",
      "1      989      549  1.277139\n",
      "2      780      599  0.500810 \n",
      "\n",
      "OUTPUT PROBABILIDAD:\n",
      "0    0.525\n",
      "1    0.525\n",
      "2    0.475\n",
      "Name: result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictors=[\"Datos_F\",\"Datos_G\",\"Datos_E\"]\n",
    "outcome = 'ES_NO_ES'\n",
    "new=df_prueba.loc[0:2,predictors]\n",
    "print(\"INPUT:\")\n",
    "print(new,\"\\n\")\n",
    "print(\"OUTPUT PROBABILIDAD:\")\n",
    "ejemplo.KNN_predict(predictors,outcome,new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREE MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subdivide los datos para hacerlos lo más homogeneos posible\n",
    "- Split value: es una valor predictor que divide los grupos minimizando el predictor\n",
    "- Nodos: son las ramas, representaciñon de las reglas del split value\n",
    "- Leaf: final de la rama\n",
    "- Loss: el número de clasificaciones erroneas en el split process., mayor loss mayor impureza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node=0 test node: go to node 1 if 2 <= -1.7392802834510803 else to node 10\n",
      "  node=1 test node: go to node 2 if 0 <= 64.0 else to node 3\n",
      "    node=2 leaf node: [[1.0, 0.0]]\n",
      "    node=3 test node: go to node 4 if 2 <= -1.8029978275299072 else to node 9\n",
      "      node=4 test node: go to node 5 if 2 <= -1.8356052041053772 else to node 8\n",
      "        node=5 test node: go to node 6 if 0 <= 325.5 else to node 7\n",
      "          node=6 leaf node: [[0.455, 0.545]]\n",
      "          node=7 leaf node: [[0.111, 0.889]]\n",
      "        node=8 leaf node: [[1.0, 0.0]]\n",
      "      node=9 leaf node: [[0.0, 1.0]]\n",
      "  node=10 test node: go to node 11 if 2 <= -1.1787307858467102 else to node 18\n",
      "    node=11 test node: go to node 12 if 2 <= -1.19194096326828 else to node 17\n",
      "      node=12 test node: go to node 13 if 0 <= 766.0 else to node 16\n",
      "        node=13 test node: go to node 14 if 0 <= 9.0 else to node 15\n",
      "          node=14 leaf node: [[0.0, 1.0]]\n",
      "          node=15 leaf node: [[0.661, 0.339]]\n",
      "        node=16 leaf node: [[0.308, 0.692]]\n",
      "      node=17 leaf node: [[1.0, 0.0]]\n",
      "    node=18 leaf node: [[0.491, 0.509]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictors=[\"Datos_F\",\"Datos_G\",\"Datos_E\"]\n",
    "outcome = 'ES_NO_ES'\n",
    "\n",
    "X = df_prueba[predictors]\n",
    "y = df_prueba[outcome]\n",
    "\n",
    "loan_tree = DecisionTreeClassifier(random_state=1, criterion='entropy',\n",
    "                                   min_impurity_decrease=0.003)\n",
    "clf=loan_tree.fit(X, y)\n",
    "\n",
    "\n",
    "print(textDecisionTree(loan_tree))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "609973a2d1f31d45d1c4d9f5c0b4ecf9cb33fe1a555b03392724c0cdbb5c54ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
