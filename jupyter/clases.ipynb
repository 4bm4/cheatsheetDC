{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import inspect\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from pygam import LinearGAM, s, f, l\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as stats2\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from statsmodels.formula.api import ols,glm\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.metrics import mean_squared_error,r2_score, confusion_matrix, precision_recall_fscore_support,roc_curve, accuracy_score, roc_auc_score\n",
    "from dmba import stepwise_selection,AIC_score,classificationSummary,textDecisionTree\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prueba = pd.DataFrame({\n",
    "\"ES_NO_ES\":[np.random.choice(['s','n']) for _ in range(1000)],\n",
    "\"sexo\":[np.random.choice(['h','m']) for _ in range(1000)],\n",
    "\"Datos_C\":[np.random.choice([0,1]) for _ in range(1000)],\n",
    "\"Datos_D\": list(np.random.standard_normal(1000)),\n",
    "\"Datos_E\": list(np.random.standard_normal(1000)),\n",
    "\"Datos_Poisson_1\": list( stats.poisson.rvs(mu=4, size=1000)),\n",
    "\"Datos_Poisson_3\": list( np.random.poisson(lam=10, size=1000)),\n",
    "\"Datos_Geom\": list( stats.geom.rvs(0.75, size=1000)),\n",
    "\"Datos_F\": [np.random.randint(0,1000) for _ in range(1000)],\n",
    "\"Datos_G\": [np.random.randint(0,1000) for _ in range(1000)],\n",
    "\"Datos_cate_A\": ['Grupo '+str(np.random.randint(0,6)) for _ in range(1000)],\n",
    "\"Datos_cate_B\": ['Grupo '+str(np.random.randint(0,4)) for _ in range(1000)],\n",
    "\"Datos_cate_C\": [np.random.randint(0,60) for _ in range(1000)],\n",
    "\n",
    "})\n",
    "\n",
    "# for i in range(1,6):\n",
    "#     df_prueba['Datos_E'][random.randint(0,23)]=None\n",
    "\n",
    "\n",
    "# for i in range(1,10):\n",
    "#     df_prueba['Datos_F'][random.randint(0,23)]=None\n",
    "\n",
    "# for i in range(0,11):\n",
    "#     df_prueba['Datos_G'][i]=None\n",
    "\n",
    "    \n",
    "lista_de_items= ['Item '+str(np.random.randint(0,6)) for _ in range(30000)]\n",
    "num_fact= 30000\n",
    "\n",
    "def crear_lista (lista):\n",
    "    listafin=[]\n",
    "    for i in range (0,num_fact):\n",
    "        lista_aux=[]\n",
    "        for j in range(1, random.randint(1, 10)):\n",
    "            lista_aux.append(random.choice(lista))\n",
    "        \n",
    "        listafin.append(lista_aux)\n",
    "    \n",
    "    return listafin\n",
    "\n",
    "# facturas=crear_lista(lista_de_items)\n",
    "\n",
    "\n",
    "# df_prueb2 = pd.DataFrame({\n",
    "# \"Items\": lista_de_items,\n",
    "# \"facturas\": facturas,\n",
    "# })\n",
    "\n",
    "# pd.merge(df_prueba, df_prueb2,left_index=True, right_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DF_exploracion(pd.DataFrame):\n",
    "\n",
    "    def __init__(self, *args, **kw):\n",
    "        super(DF_exploracion, self).__init__(*args, **kw)\n",
    "        self.cuanti=pd.DataFrame\n",
    "        self.cuanti_antes_de_outliers_y_inputs=pd.DataFrame\n",
    "        self.cuali=pd.DataFrame\n",
    "        self.dico=pd.DataFrame\n",
    "        self.cate=pd.DataFrame\n",
    "        self.eliminado=pd.DataFrame\n",
    "        self.dummy=pd.DataFrame\n",
    "        self.df=pd.DataFrame\n",
    "        self.df_inputado=pd.DataFrame\n",
    "        self.df_limpio=pd.DataFrame\n",
    "        self.predicotres=pd.DataFrame\n",
    "        self.outcome=pd.DataFrame\n",
    "        # self.outcome_col=self.outcome.columns\n",
    "        self.normal_cuatis=[]\n",
    "        self.normal_grupos_dico=[]\n",
    "        self.normal_grupos_cate=[]\n",
    "        self.discreta=[]\n",
    "        self.stingg=[]\n",
    "        self.outliers_hecho=True\n",
    "        self.porcentaje_nulos_permitido=0.3\n",
    "\n",
    "    def variables(self):\n",
    "\n",
    "        dico=[]\n",
    "        cuantis=[]\n",
    "        categori=[]\n",
    "        eliminar=[]\n",
    "        \n",
    "\n",
    "        for i in self.columns: \n",
    "\n",
    "            try:\n",
    "                datos=self[i].dropna().to_numpy()\n",
    "                discreta=True\n",
    "                for j in datos:\n",
    "                    if (j%1 !=0):\n",
    "                        discreta=False\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                if (discreta):\n",
    "                    self.discreta.append(i)\n",
    "            except:\n",
    "                self.stingg.append(i)\n",
    "\n",
    "            nulos= (self[i].isnull().sum())/len(self[i])\n",
    "            \n",
    "            if ((len(self[i].dropna().unique())==2) and (nulos<=self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: DICOTOMICA\"\n",
    "                dico.append(i)\n",
    "\n",
    "            elif ((len(self[i].dropna().unique())>10) and  (nulos<=self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: CUANTITATIVA\"\n",
    "                cuantis.append(i)\n",
    "\n",
    "            elif ( (len(self[i].dropna().unique())<2) or (nulos>self.porcentaje_nulos_permitido)):\n",
    "                tipo_de_var=f\"SOLO {len(self[i].dropna().unique())} TIPOS, NO VALE LA COLUMNA\"\n",
    "                eliminar.append(i)\n",
    "            else:\n",
    "                tipo_de_var=f\"{len(self[i].dropna().unique())} tipos, posiblemente: CATEGORICA/CUANTI\"\n",
    "                categori.append(i)\n",
    "\n",
    "            print (f\"|  {i} \\n|   - Tipo de dato: {self[i].dtype} \\n|   - Valores repetidos: {tipo_de_var} \\n|   - Nulos: {nulos} \\n| \")\n",
    "\n",
    "        print (f\"|----------------------------------------------------------------------------------------------------\\n|  TODAS: {self.columns} \\n|  DICOTOMICAS: {dico} \\n|  CATEGORICAS: {categori} \\n|  CUANTITATIVAS: {cuantis} \\n|  ELIMINAR: {eliminar}\")\n",
    "        print(\"|----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        self.DF_cuantis(cuantis)\n",
    "        self.DF_cualis(categori+dico)\n",
    "        self.DF_dicotomica(dico)\n",
    "        self.DF_categorica(categori)\n",
    "        self.DF_elimiminado(eliminar)\n",
    "        self.df=self\n",
    "        \n",
    "    def todas_col(self):\n",
    "        return self.df\n",
    "    \n",
    "    def DF_cuantis(self,lista):\n",
    "        self.cuanti=self[lista]\n",
    "\n",
    "    def DF_elimiminado(self,lista):\n",
    "        self.eliminado=self[lista]\n",
    "        \n",
    "    def DF_cualis(self,lista):\n",
    "        self.cuali=self[lista]\n",
    "        \n",
    "    def DF_dicotomica(self, lista):\n",
    "        self.dico=self[lista]\n",
    "        \n",
    "    def DF_categorica(self, lista):\n",
    "        self.cate=self[lista]   \n",
    "\n",
    "\n",
    "\n",
    "    def limpiar_aux(self):\n",
    "        \n",
    "        try:\n",
    "            df_nuevo=pd.DataFrame\n",
    "            aux1=list(self.dico.columns)\n",
    "            aux=[]\n",
    "            df_nuevo=pd.get_dummies(self.df, columns=aux1)\n",
    "            \n",
    "            for columna in df_nuevo.columns:\n",
    "                for variables in list(self.dico.columns):\n",
    "                    if variables in columna:\n",
    "                        aux.append(columna)\n",
    "                    \n",
    "            self.dummy=df_nuevo[aux]\n",
    "            self[aux]=df_nuevo[aux]\n",
    "\n",
    "            # self.df=self.drop(columns=var, axis='columns')\n",
    "            # self.df= self[self.columns.difference(self.dico.columns)]\n",
    "            \n",
    "            print(\"********************** self.dummy ************\\n\")\n",
    "            print(self.dummy)\n",
    "            print(\"\\n********************** self.df o todas_las_col() ************\\n\")\n",
    "            print(self.df)\n",
    "\n",
    "        except:\n",
    "            print(\"---------------------- ERROR -----------------\")\n",
    "\n",
    "\n",
    "\n",
    "    def limpiar_dummys(self):\n",
    "\n",
    "        b=False\n",
    "        lista=list(self.dico.columns)\n",
    "        for ind, i in enumerate(lista):\n",
    "                if (ind+1<len(lista)):\n",
    "                    if( (i in lista [ind+1]) ):\n",
    "                        b=True\n",
    "                        break\n",
    "        if b:\n",
    "            nombres_nuevos=[]\n",
    "            if len(lista)>2:\n",
    "                for ind, i in enumerate(lista):\n",
    "                    if (ind+1<len(lista)):\n",
    "                        if( (i in lista [ind+1]) ):\n",
    "                            nombres_nuevos.append(i.upper())\n",
    "                        else:\n",
    "                            nombres_nuevos.append(i)\n",
    "                    else:\n",
    "                        nombres_nuevos.append(i)\n",
    "                        \n",
    "            aux_df=self.df\n",
    "\n",
    "            for i,j in zip(lista,nombres_nuevos):\n",
    "                aux_df.rename(columns={i:j},inplace=True)\n",
    "                \n",
    "            self.df=aux_df\n",
    "            self.dico.columns=nombres_nuevos\n",
    "            \n",
    "            self.limpiar_aux()\n",
    "        else: \n",
    "            self.limpiar_aux()\n",
    "\n",
    "\n",
    "\n",
    "    def estadistica_descriptiva_cuantis(self):\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\nDESCRIPCIÓN\")\n",
    "        print (self.cuanti.describe())\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\nCUARTILES\")\n",
    "        print (self.cuanti.quantile([0.05,0.25,0.5,0.75,0.95]))\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        # df_auxiliar = self.groupby('sexo').apply(lambda x: pd.Series(shapiro(x), index=['W','P'])).reset_index()\n",
    "        # print(df_auxiliar)\n",
    "                \n",
    "        for a in list(aux1.values):\n",
    "            \n",
    "            for b in list(aux.values):\n",
    "                \n",
    "                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                agrupado=self.groupby(a)[b]\n",
    "                titulo=f\"Agrupado por {a} y por {b}\"\n",
    "                print(titulo)\n",
    "                print(agrupado.describe().reset_index())\n",
    "                # df.groupby(['cat1', 'cat2'])['purchases','sales'].apply(stats.shapiro)\n",
    "                print(\"////////////////////////// TEST DE SHAPIRO ////////////////////////////\")\n",
    "                aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                print(aux_shapiro)\n",
    "        \n",
    "                \n",
    "                print(\"\\n\")\n",
    "                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "    def estadistica_descriptiva_cualis(self):\n",
    "\n",
    "        print(\"\\n--------------------- Variables dico ---------------------\")\n",
    "        print(\"\\n\")\n",
    "        for i in self.dico.columns:\n",
    "            print(f\"...........Frecuencia variable {i} ....................\")\n",
    "            print(self[i].value_counts()/(self[i].count()))\n",
    "            print(\"\\n\")\n",
    "\n",
    "        print(\"\\n-------------------- Variables categoricas --------------------\")\n",
    "        print(\"\\n\")\n",
    "        for i in self.cate.columns:\n",
    "            print(f\"...........Frecuencia variable {i} ....................\")\n",
    "            print(self[i].value_counts()/(self[i].count()))\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # crosstab variables cualis con cate\n",
    "        aux=list(self.cate.columns)\n",
    "\n",
    "        a=0\n",
    "        for i in aux:\n",
    "            a=a+1\n",
    "            if a<len(aux)/2:\n",
    "                b=0\n",
    "                for j in aux[:-1]:\n",
    "                    b=b+1\n",
    "                    if b > a:\n",
    "                        print(f\"*************** TABAL DE VARIABLES CATEGORICAS {i} y {j} *********************\\n \")\n",
    "                        tab = pd.crosstab (index=self[i], columns=self[j])\n",
    "                        x=(tab/tab.sum())\n",
    "                        print(tab)\n",
    "                        print(\"\\n\")\n",
    "                        print(f\"/////////////////// EN PROPORCION //////////////////\\n\")\n",
    "                        print(x)\n",
    "                        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    def anova(self):\n",
    "\n",
    "        aux_cate=list(self.cate.columns)\n",
    "        aux_cuati=list(self.cuanti.columns)\n",
    "\n",
    "        for i in aux_cate:\n",
    "            for j in aux_cuati:\n",
    "                try:\n",
    "                    print(f\"\\n----------- ANOVA Categoria {i} y variable continua {j} ----------\\n\")\n",
    "                    model = ols(f\"{j} ~ {i}\", data=self).fit()\n",
    "                    a=sm.stats.anova_lm(model, typ=2)\n",
    "                    print(a)\n",
    "                except:\n",
    "                    print(f\"\\n - - - - - Fallo en variable {i} y {j} - - - - - - \\n\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def Chi(self):\n",
    "\n",
    "        aux_dico=list(self.dico.columns)\n",
    "\n",
    "        if len(aux_dico)>1:\n",
    "            for ind, i in enumerate(aux_dico):\n",
    "                for j in range(ind+1,len(aux_dico)):\n",
    "                    chi, p, dof, expected = stats.chi2_contingency(pd.crosstab(self[i],self[aux_dico[j]]), correction=False)\n",
    "                    print(f\"\\n-------------- Chi2 entre {i} y {aux_dico[j]} ----------------\")\n",
    "                    print(f\"p: {p} \\n\") \n",
    "        else:\n",
    "            print(\"******************** No suficientes argumentos ********************\")\n",
    "\n",
    "\n",
    "    def t_test_aux(self, columns):\n",
    "        results = []\n",
    "        for i, col1 in enumerate(columns[:-1]):\n",
    "            for col2 in columns[i+1:]:\n",
    "                t, p = stats.ttest_ind(self[col1].dropna(), self[col2].dropna(), equal_var=False)\n",
    "                # results.append((col1, col2, t, p))\n",
    "                if p < 0.05:\n",
    "                    print( f\"+++++ Variable{col1}, variable 2 {col2} con p de: \\033[1m{p}\\033[0m  Se RECHAZA H0 ++++\") \n",
    "                else:\n",
    "                    print( f\"+++++ Variable{col1}, variable 2 {col2}  con p de: {p} SE ACEPTA H0 ++++\") \n",
    "    \n",
    "    def wilcoxon_test_aux(self,col1, col2):\n",
    "        if (col1== col2).all():\n",
    "            print (\"\\nLas coluimnas son iguales\\n\")\n",
    "        res = stats.wilcoxon(col1, col2)\n",
    "        if res.pvalue < 0.05:\n",
    "            print(f\"Reject null hypothesis. Significant difference  (p-value={res.pvalue:.4f})\")\n",
    "        else:\n",
    "            print (f\"Fail to reject null hypothesis. No significant difference (p-value={res.pvalue:.4f})\")\n",
    "\n",
    "    def wilconxon(self, lista):\n",
    "        # lista=[grupo, var]\n",
    "        a,b=self.agrupar(lista)\n",
    "        print(f\"\\n- Variable: {lista[1]}, Grupo: {lista[0]}\")\n",
    "        self.wilcoxon_test_aux(a, b)\n",
    "\n",
    "    def agrupar (self, lista):\n",
    "        groupby_col=lista[0]\n",
    "        col=lista[1]\n",
    "        valor=self[groupby_col].unique()\n",
    "        group= self.where(self[groupby_col]== valor[0])[col]\n",
    "        group2= self.where(self[groupby_col]== valor[1])[col] \n",
    "        return group,group2\n",
    "\n",
    "    # def t_test_groupby_one_col(self, col, groupby_col):\n",
    "        \n",
    "    #     group= self.where(self[groupby_col]== self[groupby_col][0]).dropna()[col]\n",
    "    #     group2= self.where(self[groupby_col]== self[groupby_col][1]).dropna()[col]\n",
    "    #     t, p = stats.ttest_ind(group, group2, equal_var=False)\n",
    "    #     print( col, groupby_col,p) \n",
    "\n",
    "    def t_test_all(self):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        aux2=list(self.dico.columns)\n",
    "        self.t_test_aux(self.normal_cuatis) #aqui ya hace todas las cuantis entre ellas faltan los grupos\n",
    "        for i in self.normal_grupos_dico:\n",
    "            a,b=self.agrupar(i)\n",
    "            t, p = stats.ttest_ind(a.dropna(), b.dropna(), equal_var=False)\n",
    "            if p < 0.05:\n",
    "                print( f\"+++++ Variable{i[1]}, Agrupado por {i[0]} con p de: \\033[1m{p}\\033[0m  Se RECHAZA H0 ++++\") \n",
    "            else:\n",
    "                print( f\"+++++ Variable{i[1]}, Agrupado por {i[0]} con p de: {p} SE ACEPTA H0 ++++\") \n",
    "    # df_prueba.groupby('sexo').apply(lambda df: stats.ttest_ind(df['Datos_D'].dropna(), df['Datos_E'].dropna())[1])\n",
    "\n",
    "\n",
    "    def plot_confidence_interval(self, col, confidence_level= 0.95):\n",
    "        data = self[col].to_numpy()\n",
    "        n = len(data)\n",
    "        mean =self[col].mean(axis=0)\n",
    "        # std_error = stats.sem( self[col].dropna())\n",
    "        std_error = self[col].dropna().std()\n",
    "        lower_bound = stats.t.ppf(0.025, n - 1, loc = mean, scale = std_error)  # =>  99.23452406698323\n",
    "        upper_bound = stats.t.ppf(0.975, n - 1, loc = mean, scale = std_error)\n",
    "        # h = std_error * stats.t.ppf((1 + confidence_level) / 2, n - 1)\n",
    "        \n",
    "        # lower_bound = mean - h\n",
    "        # upper_bound = mean + h\n",
    "        # plt.hist(data, bins=30, edgecolor='black', alpha=0.5)\n",
    "        # plt.axvspan(lower_bound, upper_bound, color='gray', alpha=0.2, label=f'{confidence_level * 100}% Confidence Interval')\n",
    "        # plt.axvline(x=mean, color='red', label='Sample Mean')\n",
    "        # plt.legend()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(data, bins=30, edgecolor='black', alpha=0.5)\n",
    "        ax.axvline(x=mean, color='red', label='Sample Mean')\n",
    "        ax.axvspan(lower_bound, upper_bound, color='grey', alpha=0.5, label=f'{confidence_level * 100}% Confidence Interval')\n",
    "        ax.annotate(\n",
    "            f'lower_bound:\\n {lower_bound:.2f}',\n",
    "            xy=(lower_bound, 0), xytext=(lower_bound-0.5, 50)\n",
    "        )\n",
    "        ax.annotate(\n",
    "            f'upper_bound:\\n  {upper_bound:.2f}',\n",
    "            xy=(upper_bound, 0), xytext=(upper_bound-0.5, 50)\n",
    "        )\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_normailidad(self):\n",
    "        aux=self.cuanti.columns\n",
    "        for i in aux:\n",
    "            stats.probplot(self[i], dist=\"norm\", plot=plt)\n",
    "            plt.title(\"Probability Plot - \" )\n",
    "            plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    def plot_bigotes(self):\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "        print(\"-------------- Graficas de bigotes cualitativas-------------------\")\n",
    "        # fig = plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        (self.cuanti).plot(kind='box', title='Variables cuantitativas',figsize=(12, 8))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        print(\"-------------- Graficas de bigotes por dicotomicas-------------------\")   \n",
    "        \n",
    "        for a in aux1:\n",
    "\n",
    "            # fig = plt.figure(figsize=(12, 8))\n",
    "            self.boxplot(column=list(aux.values), by=a,figsize=(12, 8))\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        print(\"-------------- Graficas de bigotes por categoricas-------------------\") \n",
    "\n",
    "        for a in aux2:\n",
    "            # fig = plt.figure(figsize=(12, 8))\n",
    "            ax= self.boxplot(column=list(aux.values), by=a, figsize=(12, 8))\n",
    "            # ax = sns.swarmplot(column=list(aux.values), by=a,data=self, color='#7d0013')\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "        print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        \n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    def plot_corr(self):\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        print(\"-------------- MATRIZ DE CORRELACIONES ENTRE CUANTITATIVAS -------------------\\n\") \n",
    "\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        matrix = self.cuanti.corr().round(2)\n",
    "        mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "        sns.heatmap(matrix, annot=True, vmax=1, vmin=-1, center=0, cmap='vlag', mask=mask)  \n",
    "        plt.show()\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "    def plot_barras(self):\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"-------------- GRAFICA DE BARRAS DE TODAS LAS CUANTITATIVAS -------------------\\n\") \n",
    "        # fig = plt.figure(figsize=(15, 20))\n",
    "        self.cuanti.plot.bar(figsize=(18, 8))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"-------------- GRAFICA DE BARRAS CON DISTRIBUCIÓN DE DENSIDAD DE CADA CUANTITATIVA  -------------------\\n\") \n",
    "        for i in list(aux.values):\n",
    "            fig = plt.figure(figsize=(12, 8))\n",
    "            print(f\"\\n.............. GRAFICA DE BARRAS  DE {i} ............\\n\") \n",
    "            ax=self[i].plot.hist(density=True)\n",
    "            self[i].plot.density(ax=ax)\n",
    "            plt.show()\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")    \n",
    "        print(\"\\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "\n",
    "    def todos_plots(self):\n",
    "\n",
    "        self.plot_bigotes()\n",
    "        self.plot_corr()\n",
    "        self.plot_barras()\n",
    "        self.violines()\n",
    "        \n",
    "        \n",
    "\n",
    "    def violines(self):\n",
    "\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "\n",
    "        print(\"--------------  GRAFICA DE VIOLINES  -------------------\\n\") \n",
    "        sns.set(style=\"whitegrid\")\n",
    "        for i in aux2:\n",
    "            for j in aux:\n",
    "                ax= sns.violinplot(x=self[i], y=self[j], palette=\"Set2\", split=True, inner=\"quartile\",scale=\"count\")\n",
    "                plt.show()\n",
    "\n",
    "        print(\"\\n\\n/////////-------------- GRAFICA DE VIOLINES POR DICOTOMICAS -------------------/////////////\\n\") \n",
    "        \n",
    "        for i in aux2:\n",
    "            for j in aux:\n",
    "                for k in aux1:\n",
    "                    ax= sns.violinplot(x=self[i], y=self[j], hue=self[k],palette=\"Set2\", split=True, inner=\"quartile\",scale=\"count\")\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "    def cross_var_cualis_con_ciantis(self):\n",
    "\n",
    "        aux=list(self.cate.columns)\n",
    "        aux_cuati=list(self.cuanti.columns)\n",
    "\n",
    "        for k in aux_cuati:\n",
    "            a=0\n",
    "            for i in aux:\n",
    "                a=a+1\n",
    "                if a<len(aux)/2:\n",
    "                    b=0\n",
    "                    for j in aux[:-1]:\n",
    "                        b=b+1\n",
    "                        if b > a:\n",
    "                            print(f\"\\n\\n*************** TABAL DE VARIABLES CATEGORICAS {i} y {j} con valores de {k} MEDIA *********************\\n \")\n",
    "                            tab = pd.crosstab (index=self[i], columns=self[j],values=self[k],aggfunc=np.mean)\n",
    "                            print(tab)\n",
    "                            print(\"\\n\\n\")\n",
    "\n",
    "    def nulos(self):\n",
    "        aux_df=list(self.cuanti.columns)\n",
    "        self.inputado=self.df\n",
    "        for i in aux_df:\n",
    "            nulos=self[i].isna().sum()\n",
    "            total=len(self[i])\n",
    "            porcentaje=nulos/total\n",
    "            if ((nulos>0)):\n",
    "                percen=self[i].quantile([0.2,0.8]).to_list()\n",
    "                self[i]=self[i].apply(lambda x: ( random.randint ( round(percen[0]) , round(percen[1]) )) if pd.isna(x) else x )\n",
    "                print(f\"\\n- Se han inputado {nulos} nulos a la variable {i} (tenía porcentaje de nulos de: {porcentaje}) \\n\")\n",
    "            elif (porcentaje>self.porcentaje_nulos_permitido):\n",
    "                print(f\"\\n - No se ha podido inputar a la variable {i} porque el porcentaje de nulos era de {porcentaje}\\n\")\n",
    "                \n",
    "\n",
    "    def normalidad(self):\n",
    "        \n",
    "        DataF=self.df\n",
    "        aux1=self.dico.columns\n",
    "        aux2=self.cate.columns\n",
    "        aux=self.cuanti.columns\n",
    "                \n",
    "        for b in list(aux.values):\n",
    "            aux_shapiro=(stats.shapiro(DataF[b]))\n",
    "            if(aux_shapiro.pvalue<0.05):\n",
    "                print(\"////////////////////////// TEST DE SHAPIRO CUANTITATIVAS ////////////////////////////\")\n",
    "                print(\"++++++++++++++++++++++++++++  \"+ b +\"  ++++++++++++++++++++++++++\\n\")\n",
    "                titulo=f\"Variable cuantitativa {b} y test Shapiro < 0.05\"\n",
    "                print(titulo)\n",
    "                print(aux_shapiro)\n",
    "                print(\"\\n\")\n",
    "                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                self.normal_cuatis.append(b)\n",
    "\n",
    "        for a in list(aux1.values):\n",
    "            for b in list(aux.values):\n",
    "                    agrupado=DataF.groupby(a)[b]\n",
    "                    try:\n",
    "                        aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                        for h in aux_shapiro:\n",
    "                            if(h.pvalue<0.05):\n",
    "                                print(\"////////////////////////// TEST DE SHAPIRO DICOTOMICAS ////////////////////////////\")\n",
    "                                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                                titulo=f\"Agrupado por {a} y por {b} y test Shapiro < 0.05\"\n",
    "                                print(titulo)\n",
    "                                print(aux_shapiro)\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                                self.normal_grupos_dico.append([a,b])\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "        for a in list(aux2.values):\n",
    "            for b in list(aux.values):\n",
    "                    agrupado=DataF.groupby([a])[b]\n",
    "                    try:\n",
    "                        aux_shapiro=(agrupado.apply(stats.shapiro))\n",
    "                        for h in aux_shapiro:\n",
    "                            if(h.pvalue<0.05):\n",
    "                                print(\"////////////////////////// TEST DE SHAPIRO CATEGORICAS ////////////////////////////\")\n",
    "                                print(\"++++++++++++++++++++++++++++  \"+a+\" y \"+b+\"  ++++++++++++++++++++++++++\\n\")\n",
    "                                titulo=f\"Agrupado por {a} y por {b} y test Shapiro < 0.05\"\n",
    "                                print(titulo)\n",
    "                                print(h)\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------------------------------------------------------------------------------------------\\n\")\n",
    "                                self.normal_grupos_cate.append([a,b])\n",
    "                    except:\n",
    "                        continue \n",
    "\n",
    "        self.normal_grupos_dico=[i for n, i in enumerate(self.normal_grupos_dico) if i not in self.normal_grupos_dico[:n]]\n",
    "        self.normal_grupos_cate=[i for n, i in enumerate(self.normal_grupos_cate) if i not in self.normal_grupos_cate[:n]]\n",
    "        \n",
    "    def detec_outlaiers(self):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        aux_DF=self.cuanti\n",
    "        for i in aux:\n",
    "            z = np.abs(stats.zscore(aux_DF[i]))\n",
    "            print(z)\n",
    "    \n",
    "    def seleccionar_distribuciones(self,familia='realall', verbose=False):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        familia : {'realall', 'realline', 'realplus', 'real0to1', 'discreta'}\n",
    "            realall: distribuciones de la familia `realline` + `realplus`\n",
    "            realline: distribuciones continuas en el dominio (-inf, +inf)\n",
    "            realplus: distribuciones continuas en el dominio [0, +inf)\n",
    "            real0to1: distribuciones continuas en el dominio [0,1]\n",
    "            discreta: distribuciones discretas\n",
    "            \n",
    "        verbose : bool\n",
    "            Si se muestra información de las distribuciones seleccionadas\n",
    "            (the default `False`)\n",
    "        '''\n",
    "    \n",
    "        distribuciones = [getattr(stats,d) for d in dir(stats) \\\n",
    "                        if isinstance(getattr(stats,d), (stats.rv_continuous, stats.rv_discrete))]\n",
    "        \n",
    "        exclusiones = ['levy_stable', 'vonmises']\n",
    "        distribuciones = [dist for dist in distribuciones if dist.name not in exclusiones]\n",
    "                \n",
    "        dominios = {\n",
    "            'realall' : [-np.inf, np.inf],\n",
    "            'realline': [np.inf,np.inf],\n",
    "            'realplus': [0, np.inf],\n",
    "            'real0to1': [0, 1], \n",
    "            'discreta': [None, None],\n",
    "        }\n",
    "\n",
    "        distribucion = []\n",
    "        tipo = []\n",
    "        dominio_inf = []\n",
    "        dominio_sup = []\n",
    "\n",
    "        for dist in distribuciones:\n",
    "            distribucion.append(dist.name)\n",
    "            tipo.append(np.where(isinstance(dist, stats.rv_continuous), 'continua', 'discreta'))\n",
    "            dominio_inf.append(dist.a)\n",
    "            dominio_sup.append(dist.b)\n",
    "        \n",
    "        info_distribuciones = pd.DataFrame({\n",
    "                                'distribucion': distribucion,\n",
    "                                'tipo': tipo,\n",
    "                                'dominio_inf': dominio_inf,\n",
    "                                'dominio_sup': dominio_sup\n",
    "                            })\n",
    "\n",
    "        info_distribuciones = info_distribuciones \\\n",
    "                            .sort_values(by=['dominio_inf', 'dominio_sup'])\\\n",
    "                            .reset_index(drop=True)\n",
    "        \n",
    "        if familia in ['realall', 'realline', 'realplus', 'real0to1']:\n",
    "            info_distribuciones = info_distribuciones[info_distribuciones['tipo']=='continua']\n",
    "            condicion = (info_distribuciones['dominio_inf'] == dominios[familia][0]) & \\\n",
    "                        (info_distribuciones['dominio_sup'] == dominios[familia][1]) \n",
    "            info_distribuciones = info_distribuciones[condicion].reset_index(drop=True)\n",
    "            \n",
    "        if familia in ['discreta']:\n",
    "            info_distribuciones = info_distribuciones[info_distribuciones['tipo']=='discreta']\n",
    "            \n",
    "        seleccion = [dist for dist in distribuciones \\\n",
    "                    if dist.name in info_distribuciones['distribucion'].values]\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            print(\"---------------------------------------------------\")\n",
    "            print(\"       Distribuciones seleccionadas                \")\n",
    "            print(\"---------------------------------------------------\")\n",
    "            with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "                print(info_distribuciones)\n",
    "        \n",
    "        return seleccion\n",
    "\n",
    "\n",
    "    def plot_multiple_distribuciones(self, nombre_distribuciones):\n",
    "\n",
    "        aux=list(self.cuanti.columns)\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "        for i in aux:\n",
    "            x=self[i]\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots(figsize=(7,4))\n",
    "                \n",
    "            ax.hist(x=x, density=True, bins=30, color=\"#3182bd\", alpha=0.5)\n",
    "            ax.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "            ax.set_title('Ajuste distribuciones')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('Densidad de probabilidad')\n",
    "            \n",
    "            for nombre in nombre_distribuciones:\n",
    "                \n",
    "                distribucion = getattr(stats, nombre)\n",
    "\n",
    "                parametros = distribucion.fit(data=x)\n",
    "\n",
    "                nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                    if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "\n",
    "                log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "\n",
    "                aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "\n",
    "                x_hat = np.linspace(min(x), max(x), num=100)\n",
    "                y_hat = distribucion.pdf(x_hat, *parametros)\n",
    "                ax.plot(x_hat, y_hat, linewidth=2, label=distribucion.name)\n",
    "            \n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "    def fit_discrete(self,datos):\n",
    "\n",
    "        # self.discreta\n",
    "\n",
    "        mean = datos.mean()\n",
    "        var = datos.var()\n",
    "        likelihoods = {}  \n",
    "        log_likelihoods = {}\n",
    "\n",
    "        p = 1 - mean / var  \n",
    "        r = (1-p) * mean / p\n",
    "\n",
    "\n",
    "\n",
    "        log_likelihoods['nbinom'] = datos.map(lambda val: stats.nbinom.logpmf(val, r, p)).sum()\n",
    "\n",
    "        lambda_ = mean\n",
    "\n",
    "        log_likelihoods['poisson'] = datos.map(lambda val: stats.poisson.logpmf(val, lambda_)).sum()\n",
    "\n",
    "\n",
    "        best_fit = max(log_likelihoods, key=lambda x: log_likelihoods[x])\n",
    "        print(\"**** Best fit between poisson and nbinorm :\", best_fit)\n",
    "        \n",
    "\n",
    "    \n",
    "        plt.hist(datos, bins=int(np.max(datos)), density=True, alpha=0.5)\n",
    "\n",
    "        mean = datos.mean()\n",
    "        var = datos.var()\n",
    "\n",
    "\n",
    "        def loss_function_poisson(params, datos_in):\n",
    "\n",
    "            mu = params[0]\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            for i in range(len(datos_in)):\n",
    "\n",
    "                loglikelihood = stats.poisson.logpmf(datos_in[i], mu)\n",
    "\n",
    "                loss_to_add = -loglikelihood\n",
    "\n",
    "                loss += loss_to_add\n",
    "\n",
    "            return(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        params0 = np.array([20])\n",
    "        minimum = stats2.optimize.fmin(loss_function_poisson, params0, args=(datos,))\n",
    "\n",
    "        mu_fit = minimum[0]\n",
    "\n",
    "        print(\"***********  The best mu_fit is:  \",  mu_fit)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        x = list(range(int(np.min(datos)), int(np.max(datos))+1))\n",
    "        plt.scatter(x, stats.poisson.pmf(x, mu_fit),color=\"red\")\n",
    "        plt.show()   \n",
    "\n",
    "        print(\"\\n\\n Otras variables discretas:  \",  self.discreta)\n",
    "\n",
    "\n",
    "    def comparar_distribuciones_caunti_cont(self, ordenar='aic', verbose=False):\n",
    "\n",
    "            '''\n",
    "            resultados: data.frame\n",
    "                distribucion: nombre de la distribución.\n",
    "                log_likelihood: logaritmo del likelihood del ajuste.\n",
    "                aic: métrica AIC.\n",
    "                bic: métrica BIC.\n",
    "                n_parametros: número de parámetros de la distribución de la distribución.\n",
    "                parametros: parámetros del tras el ajuste\n",
    "                \n",
    "            Raises\n",
    "            ------\n",
    "            Exception\n",
    "                Si `familia` es distinto de 'realall', 'realline', 'realplus', 'real0to1',\n",
    "                o 'discreta'.\n",
    "                \n",
    "            Notes\n",
    "            -----\n",
    "            '''\n",
    "            aux=list(self.cuanti.columns)\n",
    "            \n",
    "            for i in aux:\n",
    "                print(f\"\\n ******************** Variable: {i} ******************** \\n\")\n",
    "                x=self[i]\n",
    "                distribuciones = self.seleccionar_distribuciones(familia='realall',verbose=verbose)\n",
    "                distribucion_ = []\n",
    "                log_likelihood_= []\n",
    "                aic_ = []\n",
    "                bic_ = []\n",
    "                n_parametros_ = []\n",
    "                parametros_ = []\n",
    "                \n",
    "                for j, distribucion in enumerate(distribuciones):\n",
    "                    \n",
    "                    # print(f\"{j+1}/{len(distribuciones)} Ajustando distribución: {distribucion.name}\")\n",
    "                    \n",
    "                    try:\n",
    "                        parametros = distribucion.fit(data=x)\n",
    "                        nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                            if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                        parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "                        log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "                        aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                        bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "                        \n",
    "                        distribucion_.append(distribucion.name)\n",
    "                        log_likelihood_.append(log_likelihood)\n",
    "                        aic_.append(aic)\n",
    "                        bic_.append(bic)\n",
    "                        n_parametros_.append(len(parametros))\n",
    "                        parametros_.append(parametros_dict)\n",
    "                        \n",
    "                        resultados = pd.DataFrame({\n",
    "                                        'distribucion': distribucion_,\n",
    "                                        'log_likelihood': log_likelihood_,\n",
    "                                        'aic': aic_,\n",
    "                                        'bic': bic_,\n",
    "                                        'n_parametros': n_parametros_,\n",
    "                                        'parametros': parametros_,\n",
    "                            \n",
    "                                    })\n",
    "                        \n",
    "                        resultados = resultados.sort_values(by=ordenar).reset_index(drop=True)\n",
    "\n",
    "                        \n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al tratar de ajustar la distribución {distribucion.name}\")\n",
    "                        print(e)\n",
    "                        print(\"\")\n",
    "\n",
    "                nombre_distribuciones=resultados['distribucion'][:5]\n",
    "                fig, ax = plt.subplots(figsize=(7,4))\n",
    "                \n",
    "                \n",
    "                ax.hist(x=x, density=True, bins=30, color=\"#3182bd\", alpha=0.5)\n",
    "                ax.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "                ax.set_title('Ajuste distribuciones')\n",
    "                ax.set_xlabel('x')\n",
    "                ax.set_ylabel('Densidad de probabilidad')\n",
    "                \n",
    "                for nombre in nombre_distribuciones:\n",
    "                    \n",
    "                    distribucion = getattr(stats, nombre)\n",
    "\n",
    "                    parametros = distribucion.fit(data=x)\n",
    "\n",
    "                    nombre_parametros = [p for p in inspect.signature(distribucion._pdf).parameters \\\n",
    "                                        if not p=='x'] + [\"loc\",\"scale\"]\n",
    "                    parametros_dict = dict(zip(nombre_parametros, parametros))\n",
    "\n",
    "                    log_likelihood = distribucion.logpdf(x, *parametros).sum()\n",
    "\n",
    "                    aic = -2 * log_likelihood + 2 * len(parametros)\n",
    "                    bic = -2 * log_likelihood + np.log(x.shape[0]) * len(parametros)\n",
    "\n",
    "                    x_hat = np.linspace(min(x), max(x), num=100)\n",
    "                    y_hat = distribucion.pdf(x_hat, *parametros)\n",
    "                    ax.plot(x_hat, y_hat, linewidth=2, label=distribucion.name)\n",
    "            \n",
    "                ax.legend()\n",
    "                plt.show()\n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(resultados.head(5))    \n",
    "                print(\"\\n------------------------------------------------------------------\\n\")\n",
    "\n",
    "    def remove_outliers(self, k=1.5):\n",
    "        aux=list(self.cuanti.columns)\n",
    "        for column in aux:\n",
    "            print(f\"\\n\\n                    <<<<<<<<<<<<<<<<<<<<<<<< {column} >>>>>>>>>>>>>>>>>>>>>>>>\\n\\n\")\n",
    "            self.plot_outliers2(column, k=1.5)\n",
    "            q1, q3 = self[column].quantile([0.25, 0.75])\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - (k * iqr)\n",
    "            upper_bound = q3 + (k * iqr)\n",
    "            self.loc[(self[column] < lower_bound) | (self[column] > upper_bound), column] = None    \n",
    "        self.nulos()\n",
    "        self.outliers_hecho=False\n",
    "\n",
    "\n",
    "    def plot_outliers(self, column, k=1.5):\n",
    "        \n",
    "        q1, q3 = self[column].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (k * iqr)\n",
    "        upper_bound = q3 + (k * iqr)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(self.index, self[column], color='blue', label='inlier')\n",
    "        ax.scatter(self[(self[column] < lower_bound) | (self[column] > upper_bound)].index,\n",
    "                self[(self[column] < lower_bound) | (self[column] > upper_bound)][column],\n",
    "                color='red', label='outlier')\n",
    "        ax.axhline(lower_bound, color='gray', linestyle='--')\n",
    "        ax.axhline(upper_bound, color='gray', linestyle='--')\n",
    "        plt.legend()\n",
    "        plt.show() \n",
    "\n",
    "    \n",
    "    def plot_outliers2(df, column, k=1.5):\n",
    "        q1, q3 = df[column].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (k * iqr)\n",
    "        upper_bound = q3 + (k * iqr)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(df.index, df[column], color='blue')\n",
    "        ax.scatter(df[df[column].isnull()].index,\n",
    "                df[df[column].isnull()][column],\n",
    "                color='red', marker='x')\n",
    "        ax.axhline(lower_bound, color='red', linestyle='--')\n",
    "        ax.axhline(upper_bound, color='red', linestyle='--')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_xy_data(df, x_column, y_column):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(df[x_column], df[y_column])\n",
    "        plt.xlabel(x_column)\n",
    "        plt.ylabel(y_column)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def reg_lineal(self, predictores, OUTCOME):\n",
    "        aux1=set(predictores)\n",
    "        aux2=set(list(self.cuali.columns))\n",
    "        \n",
    "\n",
    "        if (aux1.intersection(aux2)): \n",
    "            print(\"Tienes alguna variable cualitativa en los predictores\")\n",
    "        elif(OUTCOME in list(self.cuali.columns)):\n",
    "            print(\"OUTCOME es cualitativa\") \n",
    "        #No funciona con NA ni con distinta longitud dentro de los DF\n",
    "        if (self.outliers_hecho):\n",
    "            try:\n",
    "                self.remove_outliers()\n",
    "                self.predicotres=self[predictores]\n",
    "                self.outcome=self[OUTCOME]\n",
    "                ej_lm=LinearRegression()\n",
    "                ej_lm.fit(self.predicotres,self.outcome)\n",
    "\n",
    "                for name, coef in zip(predictores,ej_lm.coef_):\n",
    "                    print(f\"{name}: {coef}\")\n",
    "\n",
    "                fitted= ej_lm.predict(self.predicotres)\n",
    "                RMSE= np.sqrt(mean_squared_error(self.outcome,fitted))\n",
    "                r2= r2_score(self.outcome,fitted) \n",
    "\n",
    "                # RMSE es como el accuracy del modelo (es practicamente igual al RSE)\n",
    "                print(f\"- RMSE: {RMSE:.0f}\")\n",
    "\n",
    "                # coeficiente de determinación:  0-1 proporción de varianza en los datos\n",
    "                # que estan contabilizados en el modelo\n",
    "                print(f\"- R2: {r2:.4f}\")\n",
    "                model=sm.OLS(self.outcome,self.predicotres.assign(const=1) )\n",
    "                resul=model.fit()\n",
    "                print(\"\\n - RESUMEN \\n\")\n",
    "                print( resul.summary())\n",
    "                return ej_lm\n",
    "            except:\n",
    "                print(\"Puede que haya columans con distinta longitud\")\n",
    "\n",
    "        elif (self[predictores].isna().any().any()):\n",
    "            print(\"HAY VALORES NULOS EN LAS COLUMNAS Y YA HAS HECHO LA FUNCIÓN DE OUTLIERS\")\n",
    "\n",
    "        else :\n",
    "            try:\n",
    "                self.predicotres=self[predictores]\n",
    "                self.outcome=self[OUTCOME]\n",
    "                ej_lm=LinearRegression()\n",
    "                ej_lm.fit(self.predicotres,self.outcome)\n",
    "\n",
    "                for name, coef in zip(predictores,ej_lm.coef_):\n",
    "                    print(f\"{name}: {coef}\")\n",
    "\n",
    "                fitted= ej_lm.predict(self.predicotres)\n",
    "                RMSE= np.sqrt(mean_squared_error(self.outcome,fitted))\n",
    "                r2= r2_score(self.outcome,fitted) \n",
    "\n",
    "                # RMSE es como el accuracy del modelo (es practicamente igual al RSE)\n",
    "                print(f\"- RMSE: {RMSE:.0f}\")\n",
    "\n",
    "                # coeficiente de determinación:  0-1 proporción de varianza en los datos\n",
    "                # que estan contabilizados en el modelo\n",
    "                print(f\"- R2: {r2:.4f}\")\n",
    "                model=sm.OLS(self.outcome,self.predicotres.assign(const=1) )\n",
    "                resul=model.fit()\n",
    "                print(\"\\n ------------------------- RESUMEN --------------------------- \\n\")\n",
    "                print( resul.summary())\n",
    "                return ej_lm\n",
    "            except:\n",
    "                print(\"Puede que haya columans con distinta longitud\")\n",
    "\n",
    "\n",
    "    def forward_selected(self):\n",
    "        \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "        response: string, name of response column in data\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        model: an \"optimal\" fitted statsmodels linear model\n",
    "            with an intercept\n",
    "            selected by forward selection\n",
    "            evaluated by adjusted R-squared\n",
    "        \"\"\"\n",
    "        data=pd.merge(self.predicotres, self.outcome,left_index=True, right_index=True)\n",
    "        response=self.outcome.columns[0]\n",
    "\n",
    "        remaining = set(data.columns)\n",
    "        remaining.remove(response)\n",
    "        selected = []\n",
    "        current_score, best_new_score = 0.0, 0.0\n",
    "        while remaining and current_score == best_new_score:\n",
    "            scores_with_candidates = []\n",
    "            for candidate in remaining:\n",
    "                formula = \"{} ~ {} + 1\".format(response,\n",
    "                                            ' + '.join(selected + [candidate]))\n",
    "                score = ols(formula, data).fit().rsquared_adj\n",
    "                scores_with_candidates.append((score, candidate))\n",
    "            scores_with_candidates.sort()\n",
    "            best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "            if current_score < best_new_score:\n",
    "                remaining.remove(best_candidate)\n",
    "                selected.append(best_candidate)\n",
    "                current_score = best_new_score\n",
    "        formula = \"{} ~ {} + 1\".format(response,\n",
    "                                    ' + '.join(selected))\n",
    "        model = ols(formula, data).fit()\n",
    "\n",
    "        print (f\"Formula: {model.model.formula}\")\n",
    "        print (f\"Ajuste por R2: {model.rsquared_adj}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def weighted_regression(self, weights):\n",
    "        X = self.predicotres.values\n",
    "        y = self.outcome.values\n",
    "        w = weights.values\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y, sample_weight=w)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def codificar_catego(self,modelo,cate_var:str):\n",
    "        self['residuos']=(self.outcome-modelo.predict(self.predicotres))\n",
    "        self['residuos']\n",
    "        self[cate_var]= self[cate_var]\n",
    "        grupos1_aux= pd.merge(self[cate_var], self['residuos'],left_index=True, right_index=True)\n",
    "        grupos1_agrupado=grupos1_aux.groupby([cate_var])\n",
    "\n",
    "        summary_function = lambda x: {\n",
    "            cate_var: x.iloc[0,0],\n",
    "            'count': len(x),\n",
    "            'residuo_medio': x.residuos.median()\n",
    "        }\n",
    "        \n",
    "        group_summaries = grupos1_agrupado.apply(summary_function)\n",
    "        final_df = pd.DataFrame([    *group_summaries])\n",
    "        grupos1 = final_df.sort_values('residuo_medio')\n",
    "        grupos1['cum_count']=np.cumsum(grupos1['count'])\n",
    "        grupos1['Col_a_codificar_grupos']=pd.qcut(grupos1['cum_count'],5,labels=False,retbins=False)\n",
    "        to_join= grupos1[[cate_var,'Col_a_codificar_grupos']].set_index(cate_var)\n",
    "\n",
    "        self=self.join(to_join, on=cate_var)\n",
    "        return (self[[cate_var,'Col_a_codificar_grupos']])\n",
    "    \n",
    "    def regre_con_interaccion_de_var(self,outcome,predictores,lista_predictores_condicionados):\n",
    "        frase=outcome+\" ~\"\n",
    "        frase_aux1=\"\"\n",
    "        frase_aux2=\"\"\n",
    "        aux=0\n",
    "        for i, j in lista_predictores_condicionados:\n",
    "            if aux==0:\n",
    "                frase_aux1=i+\"*\"+j\n",
    "            else:\n",
    "                frase_aux1=frase_aux1+\"+\"+i+\"*\"+j\n",
    "            aux=aux+1\n",
    "        for i in predictores:\n",
    "            frase_aux2=frase_aux2+\"+\"+i\n",
    "        frase=frase+frase_aux1+frase_aux2\n",
    "        print(f\" Formula final: {frase} \\n\\n\")\n",
    "        model=smf.ols(formula= frase,data=self )\n",
    "        results=model.fit()\n",
    "        return results.summary()\n",
    "    \n",
    "\n",
    "    def regre_outliers(self, cate=None, grupo=None):\n",
    "\n",
    "        if cate==None:\n",
    "            ej_outliers=sm.OLS(self.outcome, self.predicotres.assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "\n",
    "            influence=OLSInfluence(resul_1)\n",
    "            sresiduals= influence.resid_studentized_internal\n",
    "\n",
    "            outliers=self.loc[sresiduals.idxmin(), :]\n",
    "            print(\"resultado\", outliers[list(self.outcome.columns)])\n",
    "            print(outliers[list(self.predicotres.columns)])\n",
    "\n",
    "\n",
    "            print(\"puntos con alta influencia y distancia de Cooks mayor de 0.08\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            ax.axhline(-2.5, linestyle='--', color='C1')\n",
    "            ax.axhline(2.5, linestyle='--', color='C1')\n",
    "            ax.scatter(influence.hat_matrix_diag, \n",
    "                    influence.resid_studentized_internal,\n",
    "                    s=1000*np.sqrt(influence.cooks_distance[0]), \n",
    "                    alpha=0.5)\n",
    "            ax.set_xlabel('hat values')\n",
    "            ax.set_ylabel('studentized residuals')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            print(\"predictores vs residuos para ver heteroskedascity\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            df = pd.DataFrame({'fitted': resul_1.fittedvalues, \n",
    "                            'residuals': np.abs(resul_1.resid)})\n",
    "            sns.regplot(x='fitted', y='residuals', data=df, scatter_kws={'alpha':0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax)\n",
    "            ax.set_xlabel('predictos')\n",
    "            ax.set_ylabel('abs(residuos)')\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "            ej_outliers=sm.OLS(datos_agru[list(self.outcome.columns)], datos_agru[list(self.predicotres.columns)].assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "\n",
    "            influence=OLSInfluence(resul_1)\n",
    "            sresiduals= influence.resid_studentized_internal\n",
    "\n",
    "            outliers=datos_agru.loc[sresiduals.idxmin(), :]\n",
    "            print(\"resultado\", outliers[list(self.outcome.columns)])\n",
    "            print(outliers[list(self.predicotres.columns)])\n",
    "\n",
    "            print(\"puntos con alta influencia y distancia de Cooks mayor de 0.08\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            ax.axhline(-2.5, linestyle='--', color='C1')\n",
    "            ax.axhline(2.5, linestyle='--', color='C1')\n",
    "            ax.scatter(influence.hat_matrix_diag, \n",
    "                    influence.resid_studentized_internal,\n",
    "                    s=1000*np.sqrt(influence.cooks_distance[0]), \n",
    "                    alpha=0.5)\n",
    "            ax.set_xlabel('hat values')\n",
    "            ax.set_ylabel('studentized residuals')\n",
    "            plt.show()\n",
    "\n",
    "            print(\"predictores vs residuos para ver heteroskedascity\")\n",
    "            fig, ax=plt.subplots(figsize=(5,5))\n",
    "            df = pd.DataFrame({'fitted': resul_1.fittedvalues, \n",
    "                            'residuals': np.abs(resul_1.resid)})\n",
    "            sns.regplot(x='fitted', y='residuals', data=df, scatter_kws={'alpha':0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax)\n",
    "            ax.set_xlabel('predictos')\n",
    "            ax.set_ylabel('abs(residuos)')\n",
    "            plt.show()\n",
    "\n",
    "    def infl_residual_modelo(self, var_influ, cate=None, grupo=None):\n",
    "        if cate==None:\n",
    "            ej_outliers=sm.OLS(self.outcome, self.predicotres.assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "            sm.graphics.plot_ccpr(resul_1,var_influ)\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fig = sm.graphics.plot_ccpr_grid(resul_1, fig=fig)\n",
    "        \n",
    "        else:\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "            ej_outliers=sm.OLS(datos_agru[list(self.outcome.columns)], datos_agru[list(self.predicotres.columns)].assign(conts=1))\n",
    "            resul_1=ej_outliers.fit()\n",
    "            sm.graphics.plot_ccpr(resul_1,var_influ)\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fig = sm.graphics.plot_ccpr_grid(resul_1, fig=fig)\n",
    "\n",
    "    def regre_poly(self,variables_exp,expo,cate=None, grupo=None,verbose=False):\n",
    "\n",
    "        if cate==None:\n",
    "\n",
    "            out=list(self.outcome.columns)\n",
    "            predic=list(self.predicotres.columns)\n",
    "\n",
    "            frase=out[0]+\" ~ \"\n",
    "            variables_no_exp = [element for element in predic if element not in variables_exp]\n",
    "            frase_expo=\"\"\n",
    "            frase_no_expo=\"\"\n",
    "\n",
    "            for i,j in zip(variables_exp,expo):\n",
    "                frase_expo=frase_expo + f\"np.power({i}, {j}) + \" \n",
    "\n",
    "            for indice,i in enumerate(variables_no_exp):\n",
    "                if indice == len(variables_no_exp)-1:\n",
    "                    frase_no_expo=frase_no_expo+i    \n",
    "                else: \n",
    "                    frase_no_expo=frase_no_expo+i+ \"+\"   \n",
    "\n",
    "            frase=frase+frase_expo+frase_no_expo\n",
    "            print(frase)\n",
    "            \n",
    "            model_poly = smf.ols(formula=frase, data=self)\n",
    "            result_poly = model_poly.fit()\n",
    "            if (verbose):\n",
    "             print(result_poly.summary())\n",
    "\n",
    "        else:\n",
    "\n",
    "            datos_agru=self.loc[df_prueba[cate]==grupo,]\n",
    "\n",
    "            out=list(self.outcome.columns)\n",
    "            predic=list(self.predicotres.columns)\n",
    "\n",
    "            frase=out[0]+\" ~ \"\n",
    "            variables_no_exp = [element for element in predic if element not in variables_exp]\n",
    "            frase_expo=\"\"\n",
    "            frase_no_expo=\"\"\n",
    "\n",
    "            for i,j in zip(variables_exp,expo):\n",
    "                frase_expo=frase_expo + f\"np.power({i}, {j}) + \" \n",
    "\n",
    "            for indice,i in enumerate(variables_no_exp):\n",
    "                if indice == len(variables_no_exp)-1:\n",
    "                    frase_no_expo=frase_no_expo+i    \n",
    "                else: \n",
    "                    frase_no_expo=frase_no_expo+i+ \"+\"   \n",
    "\n",
    "            frase=frase+frase_expo+frase_no_expo\n",
    "            print(frase)\n",
    "            \n",
    "            model_poly = smf.ols(formula=frase, data=datos_agru)\n",
    "            result_poly = model_poly.fit()\n",
    "            if (verbose):\n",
    "                print(result_poly.summary())\n",
    "\n",
    "        return result_poly\n",
    "        \n",
    "\n",
    "    def partialResidualPlot(self, model, feature):\n",
    "        df= pd.merge(self.predicotres, self.outcome, left_index=True, right_index=True)\n",
    "        outcome= list(self.outcome.columns)\n",
    "\n",
    "        y_pred = model.predict(df)\n",
    "        copy_df = df.copy()\n",
    "        for c in copy_df.columns:\n",
    "            if c == feature:\n",
    "                continue\n",
    "            copy_df[c] = 0.0\n",
    "        feature_prediction = model.predict(copy_df)\n",
    "        \n",
    "        \n",
    "        residual=df[outcome].values - y_pred.values\n",
    "        results = pd.DataFrame({\n",
    "            'feature': df[feature].values,\n",
    "            'residual': residual[0],\n",
    "            'ypartial': feature_prediction.values - model.params[0],\n",
    "        })\n",
    "\n",
    "        results = results.sort_values(by=['feature'])\n",
    "        smoothed = sm.nonparametric.lowess(results.ypartial, results.feature, frac=1/3)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "        ax.scatter(results.feature, results.ypartial + results.residual)\n",
    "        ax.plot(smoothed[:, 0], smoothed[:, 1], color='gray')\n",
    "        ax.plot(results.feature, results.ypartial, color='black')\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(f'Residual + {feature} contribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def plot_partial_residuals_poly(self,variables_exp,expo,variable ,cate=None, grupo=None):\n",
    "        model=self.regre_poly(variables_exp,expo,cate, grupo)\n",
    "        self.partialResidualPlot(model,variable)\n",
    "\n",
    "    \n",
    "    def clasificador_bayes(self,predictores,outcome,new):\n",
    "        X =self[predictores]\n",
    "        y = self[outcome]\n",
    "\n",
    "        naive_model = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "        naive_model = MultinomialNB(alpha=1e-10, fit_prior=False)\n",
    "        naive_model.fit(X, y)\n",
    "\n",
    "        print(\"Input en el modelo bayesiano: \")\n",
    "        print(new)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print('Clase más probable: ', naive_model.predict(new)[0])\n",
    "\n",
    "        probabilities = pd.DataFrame(naive_model.predict_proba(new),columns=naive_model.classes_)\n",
    "        print('Probabilidades de cada clase:',)\n",
    "        print(probabilities)\n",
    "\n",
    "    def accuracy_bayes(self,predictores,outcome):\n",
    "        X =self[predictores]\n",
    "        y = self[outcome]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        modelo_gausian = GaussianNB()\n",
    "        \n",
    "        modelo_gausian .fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo_gausian .predict(X_test)\n",
    "\n",
    "        precision_gausian  = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"La precisión del modelo gaussiano de bayes es: {precision_gausian }\")\n",
    "\n",
    "        modelo_multino=MultinomialNB()\n",
    "\n",
    "        modelo_multino.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = modelo_multino.predict(X_test)\n",
    "\n",
    "        precision_multino = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"La precisión del modelo multinomial de bayes es: {precision_multino}\")\n",
    "\n",
    "    def predict_lda(self,predictors,outcome):\n",
    "        X=self[predictors]\n",
    "        y=self[outcome]\n",
    "\n",
    "        modelo_lda = LinearDiscriminantAnalysis()\n",
    "        modelo_lda.fit(X, y)\n",
    "        y_pred = modelo_lda.predict(X)\n",
    "\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        print(\"Accuracy modelo LDA:\", accuracy)\n",
    "\n",
    "    def GLM_datos(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "\n",
    "            logit_reg_sm = sm.GLM(y, X.assign(const=1), \n",
    "                                family=sm.families.Binomial())\n",
    "            logit_result = logit_reg_sm.fit()\n",
    "            print(logit_result.summary())\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "\n",
    "    def GLM_datos_formula(self,predictors,outcome,formula):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            data=pd.merge(y, X,left_index=True, right_index=True)\n",
    "            model = glm(formula=formula, data=data, family=sm.families.Binomial())\n",
    "            results = model.fit()\n",
    "            print(results.summary())\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "\n",
    "    def mat_conf(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            logit_reg = LogisticRegression(penalty='l2', C=1e42, solver='liblinear')\n",
    "            logit_reg.fit(X, y)\n",
    "\n",
    "            print(' - Intercept ', logit_reg.intercept_[0])\n",
    "            print(' - Classes', logit_reg.classes_)\n",
    "            pd.DataFrame({'coeff': logit_reg.coef_[0]}, \n",
    "                        index=X.columns)\n",
    "\n",
    "            # Confusion matrix\n",
    "            pred = logit_reg.predict(X)\n",
    "            pred_y = logit_reg.predict(X) == \"0\"\n",
    "            true_y = y == \"0\"\n",
    "            true_pos = true_y & pred_y\n",
    "            true_neg = ~true_y & ~pred_y\n",
    "            false_pos = ~true_y & pred_y\n",
    "            false_neg = true_y & ~pred_y\n",
    "\n",
    "            conf_mat = pd.DataFrame([[np.sum(true_pos), np.sum(false_neg)], [np.sum(false_pos), np.sum(true_neg)]],\n",
    "                                index=['Y = 0', 'Y = 1'],\n",
    "                                columns=['Yhat = 1', 'Yhat = 0'])\n",
    "            # print(conf_mat)\n",
    "\n",
    "            # print(confusion_matrix(y, logit_reg.predict(X)))\n",
    "            print(\"\\n*******************************\")\n",
    "            classificationSummary(y, logit_reg.predict(X), \n",
    "                                class_names=logit_reg.classes_)\n",
    "            print(\"\\n*******************************\")\n",
    "            \n",
    "            self.prec_sens_espe(predictors,outcome,logit_reg)\n",
    "            self.ROC_curva(predictors,outcome,logit_reg)\n",
    "                        \n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "    \n",
    "    def prec_sens_espe(self,predictors,outcome,logit_reg):\n",
    "            y= self[outcome]\n",
    "            X= self[predictors]\n",
    "            conf_mat = confusion_matrix(y, logit_reg.predict(X))\n",
    "            print(' - Precision', conf_mat[0, 0] / sum(conf_mat[:, 0]))\n",
    "            print(' - Sensibilidad', conf_mat[0, 0] / sum(conf_mat[0, :]))\n",
    "            print(' - Especificidad', conf_mat[1, 1] / sum(conf_mat[1, :]))\n",
    "\n",
    "            precision_recall_fscore_support(y, logit_reg.predict(X), \n",
    "                                            labels=['0', '1'])\n",
    "            \n",
    "\n",
    "    def ROC_curva(self,predictors,outcome,logit_reg):\n",
    "\n",
    "        y= self[outcome]\n",
    "        X= self[predictors]\n",
    "        fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:, 0], pos_label=0)\n",
    "        roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "        ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(1, 0)\n",
    "        ax.plot((1, 0), (0, 1))\n",
    "        ax.set_xlabel('Especificidad')\n",
    "        ax.set_ylabel('Sensibilidad')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:,0], \n",
    "                                        pos_label=0)\n",
    "        roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
    "\n",
    "        ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlim(1, 0)\n",
    "        # ax.plot((1, 0), (0, 1))\n",
    "        ax.set_xlabel('Especificidad')\n",
    "        ax.set_ylabel('Sensibilidad')\n",
    "        ax.fill_between(roc_df.specificity, 0, roc_df.recall, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def oversampling(self,predictors,outcome):\n",
    "        X= self[predictors]\n",
    "        y=self[outcome]\n",
    "        positive_wt = 1 / np.mean(y==1)\n",
    "        # default_wt = 1 / (np.sum(dummys.ES_NO_ES_s)/len(dummys.ES_NO_ES_s))\n",
    "        # default_wt = 1 / np.mean(dummys.ES_NO_ES_s)\n",
    "        wt = [positive_wt if outcome == 1 else 1 for outcome in y]\n",
    "\n",
    "        full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "        full_model.fit(X, y,wt)\n",
    "        print('Porcentaje de valores predichos (weighting): ') \n",
    "        print( 100 * np.mean(full_model.predict(X) == 1) )  \n",
    "\n",
    "    def data_gen(self,predictors,outcome):\n",
    "        X= self[predictors]\n",
    "        y=self[outcome]\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "        print('Porcentaje de elemetos positivos predichos (SMOTE resampled): ', \n",
    "            100 * np.mean(y_resampled == 1))\n",
    "        \n",
    "        full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "        full_model.fit(X_resampled, y_resampled)\n",
    "        print('Porcentaje de elemetos positivos predichos  (SMOTE): ', \n",
    "            100 * np.mean(full_model.predict(X) ==1 ))\n",
    "\n",
    "    def explo_predict(self,predictors,outcome):\n",
    "        if (outcome in list(self.dummy.columns)):\n",
    "            y=self[outcome]\n",
    "            X=self[predictors]\n",
    "            loan_tree = DecisionTreeClassifier(random_state=1, criterion='entropy', \n",
    "                                            min_impurity_decrease=0.003)\n",
    "            loan_tree.fit(X, y)\n",
    "\n",
    "            loan_lda = LinearDiscriminantAnalysis()\n",
    "            loan_lda.fit(X, y)\n",
    "\n",
    "            logit_reg = LogisticRegression(penalty=\"l2\", solver='liblinear')\n",
    "            logit_reg.fit(X, y)\n",
    "\n",
    "\n",
    "            ## model\n",
    "            gam = LinearGAM(s(0) + s(1))\n",
    "            print(gam.gridsearch(X.values, y.values))\n",
    "\n",
    "            models = {\n",
    "                'Decision Tree': loan_tree,\n",
    "                'Linear Discriminant Analysis': loan_lda,\n",
    "                'Logistic Regression': logit_reg,\n",
    "                'Generalized Additive Model': gam,\n",
    "            }\n",
    "\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(5, 5))\n",
    "\n",
    "            xvalues = np.arange(0.25, 0.73, 0.005)\n",
    "            yvalues = np.arange(-0.1, 20.1, 0.1)\n",
    "            xx, yy = np.meshgrid(xvalues, yvalues)\n",
    "            X = pd.DataFrame({\n",
    "                'Datos_F': xx.ravel(),\n",
    "                'Datos_E': yy.ravel(),\n",
    "            })\n",
    "\n",
    "            boundary = {}\n",
    "\n",
    "            for n, (title, model) in enumerate(models.items()):\n",
    "                ax = axes[n // 2, n % 2]\n",
    "                predict = model.predict(X)\n",
    "                if 'Generalized' in title:\n",
    "                    Z = np.array([1 if z > 0.5 else 0 for z in predict])\n",
    "                else:\n",
    "                    \n",
    "                    Z = np.array([1 if z == 1 else 0 for z in predict])\n",
    "                Z = Z.reshape(xx.shape)\n",
    "                boundary[title] = yvalues[np.argmax(Z > 0, axis=0)]\n",
    "                boundary[title][Z[-1,:] == 0] = yvalues[-1]\n",
    "\n",
    "                c = ax.pcolormesh(xx, yy, Z, cmap='Blues', vmin=0.1, vmax=1.3, shading='auto')\n",
    "                ax.set_title(title)\n",
    "                ax.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            boundary['Datos_F'] = xvalues\n",
    "            boundaries = pd.DataFrame(boundary)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(5, 4))\n",
    "            boundaries.plot(x='Datos_F', ax=ax)\n",
    "            ax.set_ylabel('Datos_E')\n",
    "            ax.set_ylim(0, 20)\n",
    "\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\" El outcome no está bien escrito prueba con alguno de estos:\\n\")\n",
    "            print(list(self.dummy.columns))\n",
    "\n",
    "    def KNN_predict(self,predictors,outcome,new):\n",
    "        y=self[outcome]\n",
    "        X=self[predictors]\n",
    "        knn = KNeighborsClassifier(n_neighbors=40)\n",
    "        knn.fit(X, y)\n",
    "        data=pd.DataFrame({'result':knn.predict_proba(new)[:,1]})\n",
    "        print( data['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACIÓN DE LA CLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo=DF_exploracion(df_prueba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas._libs.properties.AxisProperty at 0x14eba162b00>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.cuanti.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINICIÓN DE LAS VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  ES_NO_ES \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  sexo \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_C \n",
      "|   - Tipo de dato: int32 \n",
      "|   - Valores repetidos: 2 tipos, posiblemente: DICOTOMICA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_D \n",
      "|   - Tipo de dato: float64 \n",
      "|   - Valores repetidos: 1000 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_E \n",
      "|   - Tipo de dato: float64 \n",
      "|   - Valores repetidos: 1000 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Poisson_1 \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 13 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Poisson_3 \n",
      "|   - Tipo de dato: int32 \n",
      "|   - Valores repetidos: 21 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_Geom \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 6 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_F \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 631 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_G \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 632 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_A \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 6 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_B \n",
      "|   - Tipo de dato: object \n",
      "|   - Valores repetidos: 4 tipos, posiblemente: CATEGORICA/CUANTI \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|  Datos_cate_C \n",
      "|   - Tipo de dato: int64 \n",
      "|   - Valores repetidos: 60 tipos, posiblemente: CUANTITATIVA \n",
      "|   - Nulos: 0.0 \n",
      "| \n",
      "|----------------------------------------------------------------------------------------------------\n",
      "|  TODAS: Index(['ES_NO_ES', 'sexo', 'Datos_C', 'Datos_D', 'Datos_E', 'Datos_Poisson_1',\n",
      "       'Datos_Poisson_3', 'Datos_Geom', 'Datos_F', 'Datos_G', 'Datos_cate_A',\n",
      "       'Datos_cate_B', 'Datos_cate_C'],\n",
      "      dtype='object') \n",
      "|  DICOTOMICAS: ['ES_NO_ES', 'sexo', 'Datos_C'] \n",
      "|  CATEGORICAS: ['Datos_Geom', 'Datos_cate_A', 'Datos_cate_B'] \n",
      "|  CUANTITATIVAS: ['Datos_D', 'Datos_E', 'Datos_Poisson_1', 'Datos_Poisson_3', 'Datos_F', 'Datos_G', 'Datos_cate_C'] \n",
      "|  ELIMINAR: []\n",
      "|----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ejemplo.variables()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de variables dummys a traves de dicotómicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** self.dummy ************\n",
      "\n",
      "     ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  Datos_C_1\n",
      "0             1           0       0       1          0          1\n",
      "1             0           1       1       0          1          0\n",
      "2             0           1       1       0          1          0\n",
      "3             0           1       0       1          0          1\n",
      "4             0           1       0       1          0          1\n",
      "..          ...         ...     ...     ...        ...        ...\n",
      "995           1           0       1       0          0          1\n",
      "996           0           1       0       1          1          0\n",
      "997           0           1       1       0          0          1\n",
      "998           0           1       0       1          0          1\n",
      "999           0           1       1       0          1          0\n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "\n",
      "********************** self.df o todas_las_col() ************\n",
      "\n",
      "    ES_NO_ES sexo  Datos_C   Datos_D   Datos_E  Datos_Poisson_1  \\\n",
      "0          n    m        1 -0.921078  0.358668                2   \n",
      "1          s    h        0  0.479400  1.023644                4   \n",
      "2          s    h        0 -2.005625 -0.140854                3   \n",
      "3          s    m        1  1.275350  0.675714                4   \n",
      "4          s    m        1 -1.601822 -1.104652                6   \n",
      "..       ...  ...      ...       ...       ...              ...   \n",
      "995        n    h        1  0.367191 -1.673144                5   \n",
      "996        s    m        0 -0.587544 -1.497237                1   \n",
      "997        s    h        1  0.601153 -0.758735                1   \n",
      "998        s    m        1 -0.125307  0.706663                0   \n",
      "999        s    h        0 -1.459210  1.517723                2   \n",
      "\n",
      "     Datos_Poisson_3  Datos_Geom  Datos_F  Datos_G Datos_cate_A Datos_cate_B  \\\n",
      "0                 11           1      664        0      Grupo 3      Grupo 2   \n",
      "1                  5           1      240      114      Grupo 2      Grupo 0   \n",
      "2                 18           1      563      466      Grupo 2      Grupo 2   \n",
      "3                 11           1      322      418      Grupo 0      Grupo 0   \n",
      "4                  8           1       47      769      Grupo 0      Grupo 2   \n",
      "..               ...         ...      ...      ...          ...          ...   \n",
      "995               11           1      143      491      Grupo 5      Grupo 1   \n",
      "996                9           1      206      474      Grupo 4      Grupo 3   \n",
      "997                7           1      674      188      Grupo 0      Grupo 0   \n",
      "998               11           1      507       53      Grupo 0      Grupo 1   \n",
      "999               10           1      387      999      Grupo 4      Grupo 1   \n",
      "\n",
      "     Datos_cate_C  ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  \\\n",
      "0              54           1           0       0       1          0   \n",
      "1              49           0           1       1       0          1   \n",
      "2              35           0           1       1       0          1   \n",
      "3              56           0           1       0       1          0   \n",
      "4              22           0           1       0       1          0   \n",
      "..            ...         ...         ...     ...     ...        ...   \n",
      "995            57           1           0       1       0          0   \n",
      "996            56           0           1       0       1          1   \n",
      "997            22           0           1       1       0          0   \n",
      "998            32           0           1       0       1          0   \n",
      "999             8           0           1       1       0          1   \n",
      "\n",
      "     Datos_C_1  \n",
      "0            1  \n",
      "1            0  \n",
      "2            0  \n",
      "3            1  \n",
      "4            1  \n",
      "..         ...  \n",
      "995          1  \n",
      "996          0  \n",
      "997          1  \n",
      "998          1  \n",
      "999          0  \n",
      "\n",
      "[1000 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "ejemplo.limpiar_dummys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ES_NO_ES</th>\n",
       "      <th>sexo</th>\n",
       "      <th>Datos_C</th>\n",
       "      <th>Datos_D</th>\n",
       "      <th>Datos_E</th>\n",
       "      <th>Datos_Poisson_1</th>\n",
       "      <th>Datos_Poisson_3</th>\n",
       "      <th>Datos_Geom</th>\n",
       "      <th>Datos_F</th>\n",
       "      <th>Datos_G</th>\n",
       "      <th>Datos_cate_A</th>\n",
       "      <th>Datos_cate_B</th>\n",
       "      <th>Datos_cate_C</th>\n",
       "      <th>ES_NO_ES_n</th>\n",
       "      <th>ES_NO_ES_s</th>\n",
       "      <th>sexo_h</th>\n",
       "      <th>sexo_m</th>\n",
       "      <th>Datos_C_0</th>\n",
       "      <th>Datos_C_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.921078</td>\n",
       "      <td>0.358668</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>664</td>\n",
       "      <td>0</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479400</td>\n",
       "      <td>1.023644</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>114</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.005625</td>\n",
       "      <td>-0.140854</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>563</td>\n",
       "      <td>466</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>1.275350</td>\n",
       "      <td>0.675714</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>322</td>\n",
       "      <td>418</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.601822</td>\n",
       "      <td>-1.104652</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>769</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>n</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367191</td>\n",
       "      <td>-1.673144</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>491</td>\n",
       "      <td>Grupo 5</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.587544</td>\n",
       "      <td>-1.497237</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>206</td>\n",
       "      <td>474</td>\n",
       "      <td>Grupo 4</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601153</td>\n",
       "      <td>-0.758735</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>674</td>\n",
       "      <td>188</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.125307</td>\n",
       "      <td>0.706663</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>507</td>\n",
       "      <td>53</td>\n",
       "      <td>Grupo 0</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>s</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.459210</td>\n",
       "      <td>1.517723</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>387</td>\n",
       "      <td>999</td>\n",
       "      <td>Grupo 4</td>\n",
       "      <td>Grupo 1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ES_NO_ES sexo  Datos_C   Datos_D   Datos_E  Datos_Poisson_1  \\\n",
       "0          n    m        1 -0.921078  0.358668                2   \n",
       "1          s    h        0  0.479400  1.023644                4   \n",
       "2          s    h        0 -2.005625 -0.140854                3   \n",
       "3          s    m        1  1.275350  0.675714                4   \n",
       "4          s    m        1 -1.601822 -1.104652                6   \n",
       "..       ...  ...      ...       ...       ...              ...   \n",
       "995        n    h        1  0.367191 -1.673144                5   \n",
       "996        s    m        0 -0.587544 -1.497237                1   \n",
       "997        s    h        1  0.601153 -0.758735                1   \n",
       "998        s    m        1 -0.125307  0.706663                0   \n",
       "999        s    h        0 -1.459210  1.517723                2   \n",
       "\n",
       "     Datos_Poisson_3  Datos_Geom  Datos_F  Datos_G Datos_cate_A Datos_cate_B  \\\n",
       "0                 11           1      664        0      Grupo 3      Grupo 2   \n",
       "1                  5           1      240      114      Grupo 2      Grupo 0   \n",
       "2                 18           1      563      466      Grupo 2      Grupo 2   \n",
       "3                 11           1      322      418      Grupo 0      Grupo 0   \n",
       "4                  8           1       47      769      Grupo 0      Grupo 2   \n",
       "..               ...         ...      ...      ...          ...          ...   \n",
       "995               11           1      143      491      Grupo 5      Grupo 1   \n",
       "996                9           1      206      474      Grupo 4      Grupo 3   \n",
       "997                7           1      674      188      Grupo 0      Grupo 0   \n",
       "998               11           1      507       53      Grupo 0      Grupo 1   \n",
       "999               10           1      387      999      Grupo 4      Grupo 1   \n",
       "\n",
       "     Datos_cate_C  ES_NO_ES_n  ES_NO_ES_s  sexo_h  sexo_m  Datos_C_0  \\\n",
       "0              54           1           0       0       1          0   \n",
       "1              49           0           1       1       0          1   \n",
       "2              35           0           1       1       0          1   \n",
       "3              56           0           1       0       1          0   \n",
       "4              22           0           1       0       1          0   \n",
       "..            ...         ...         ...     ...     ...        ...   \n",
       "995            57           1           0       1       0          0   \n",
       "996            56           0           1       0       1          1   \n",
       "997            22           0           1       1       0          0   \n",
       "998            32           0           1       0       1          0   \n",
       "999             8           0           1       1       0          1   \n",
       "\n",
       "     Datos_C_1  \n",
       "0            1  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  \n",
       "..         ...  \n",
       "995          1  \n",
       "996          0  \n",
       "997          1  \n",
       "998          1  \n",
       "999          0  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo.df\n",
    "# ejemplo.cuanti\n",
    "# ejemplo.dummy\n",
    "# ejemplo.dico\n",
    "ejemplo.df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de variables agrupadas automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datos con distribución discreta: ['Datos_C', 'Datos_Poisson_1', 'Datos_Poisson_3', 'Datos_Geom', 'Datos_F', 'Datos_G', 'Datos_cate_C']\n",
      "Datos de tipos string seguramente: ['ES_NO_ES', 'sexo', 'Datos_cate_A', 'Datos_cate_B']\n"
     ]
    }
   ],
   "source": [
    "print(f\" Datos con distribución discreta: {ejemplo.discreta}\")\n",
    "print(f\"Datos de tipos string seguramente: {ejemplo.stingg}\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTADISTICA DESCRIPTIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.estadistica_descriptiva_cuantis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.estadistica_descriptiva_cualis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.cross_var_cualis_con_ciantis()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables normales y no normales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.normalidad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación normal por categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.normal_grupos_cate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación normalidad por dicotomicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo.normal_grupos_dico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitar outlayers e inputar datos en columnas variables cuantitativas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.remove_outliers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar a distribuciones variables cuantitativas (No puede haber nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.comparar_distribuciones_caunti_cont()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar a distribuciones variables discretas (No puede haber nulos) (Solo poisson y binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.fit_discrete(df_prueba[\"Datos_Poisson_1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejemplo.todos_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_bigotes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_barras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.violines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_normailidad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ESTADISTICOS NO MULTIVARIANTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables cualitativas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.Chi()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables cuantitativas no pareadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.t_test_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilconxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.wilconxon( [\"sexo\",\"Datos_D\" ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.anova()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.plot_confidence_interval(\"Datos_D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictores=['Datos_D','Datos_E','Datos_F']\n",
    "# OUTCOME=['Datos_G']\n",
    "\n",
    "# modelo=ejemplo.reg_lineal(predictores,OUTCOME)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables predictoras en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.forward_selected()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal por pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights=ejemplo[\"Datos_Poisson_1\"]\n",
    "# ejemplo.weighted_regression( weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificar variables categoricas si son muy largas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # si tienes variables con muchas categorias pues \n",
    "    # tendrías un monton de dummys y no es la cosa tampoco \n",
    "    # que va a parecer esto un sudoku (es que además pueden incluso ser practicamente iguales)\n",
    "    # Entonces los puedes codificar usando los residuos de la regresión\n",
    "    # DESPUES NO SE GUARDA COL_A_CODIFICAR_GRUPOS!!!\n",
    "\n",
    "# ejemplo.codificar_catego(modelo,'Datos_cate_C')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadir en el modelo variables correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # interacciones entre variables que entre ellas hacen efecto en el outcome\n",
    "\n",
    "# predictores=[\"Datos_E\",\"Datos_F\"]\n",
    "# lista_predictores_condicionados=[[\"Datos_D\",\"Datos_E\"],[\"Datos_Poisson_1\",\"Datos_Poisson_3\"]]\n",
    "# outcome=\"Datos_G\"\n",
    "# ejemplo.regre_con_interaccion_de_var(outcome,predictores,lista_predictores_condicionados)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Outliers no es lo mismo que en la distribución porque aqui se usa el \n",
    "\n",
    "# ejemplo.regre_outliers(cate=\"Datos_cate_C\",grupo=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuos parciales "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuos parciales: \n",
    "\n",
    "- La función sm.graphics.plot_ccpr de la biblioteca statsmodels es una función para \n",
    "crear un gráfico de la influencia residual del modelo lineal. \n",
    "La función toma como argumentos un objeto de resultado de modelo lineal (resul_1) \n",
    "y un nombre de variable independiente ('Datos_F').\n",
    "\n",
    "- El gráfico de influencia residual se utiliza para evaluar la influencia de cada \n",
    "punto en el ajuste del modelo lineal. En la gráfica, los ejes representan las \n",
    "predicciones del modelo y los residuales absolutos respectivamente. \n",
    "Los puntos son una representación de cada observación en el conjunto de datos, \n",
    "con la posición de cada punto indicando la influencia de esa observación en el modelo.\n",
    "\n",
    "- El gráfico de influencia residual se utiliza para detectar outliers y puntos \n",
    "con influencia anormal en el modelo lineal. Si un punto tiene una influencia \n",
    "anormal en el modelo, puede ser necesario revisar ese punto en el conjunto de datos \n",
    "y considerar si debería ser incluido o excluido del modelo.\n",
    "\n",
    "- En general, un gráfico de influencia residual es una herramienta útil para \n",
    "comprender la calidad del ajuste del modelo lineal y para detectar posibles \n",
    "problemas en los datos o en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo.infl_residual_modelo(var_influ='Datos_F', cate=\"Datos_cate_C\",grupo=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_exp=[\"Datos_E\",\"Datos_F\"]\n",
    "# expo=[2,3]\n",
    "\n",
    "# ejemplo.regre_poly(variables_exp,expo, cate=\"Datos_cate_C\",grupo=1,verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot de residuos parciales con regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_exp=[\"Datos_E\",\"Datos_F\"]\n",
    "# expo=[2,3]\n",
    "# grupo=1\n",
    "# variable=\"Datos_F\"\n",
    "# cate=\"Datos_cate_C\"\n",
    "\n",
    "# ejemplo.plot_partial_residuals_poly(variables_exp,expo,variable ,cate, grupo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input en el modelo bayesiano: \n",
      "   Datos_Poisson_3  Datos_Poisson_1  Datos_Geom\n",
      "3               11                4           1\n",
      "\n",
      "\n",
      "Clase más probable:  Grupo 0\n",
      "Probabilidades de cada clase:\n",
      "    Grupo 0   Grupo 1   Grupo 2   Grupo 3   Grupo 4   Grupo 5\n",
      "0  0.171245  0.167579  0.170113  0.161853  0.162303  0.166906\n"
     ]
    }
   ],
   "source": [
    "predictors=['Datos_Poisson_3','Datos_Poisson_1','Datos_Geom']\n",
    "outcome=['Datos_cate_A']\n",
    "\n",
    "#LOS PREDICTORES TODOS EN NÚMEROS, SI SON DICO SE PASAN A DUMMYS\n",
    "# Naive porque predictores independientes \n",
    "\n",
    "ejemplo.clasificador_bayes(predictors,outcome,df_prueba[predictors].loc[3:3, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo gaussiano de bayes es: 0.176\n",
      "La precisión del modelo multinomial de bayes es: 0.144\n"
     ]
    }
   ],
   "source": [
    "ejemplo.accuracy_bayes(predictors,outcome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy modelo LDA: 0.527\n"
     ]
    }
   ],
   "source": [
    "# limitado al número de filas, da igual cuantos predictores mientras \n",
    "# distribución normal pero vamos que puede valer para todo\n",
    "# Outcome categorico \n",
    "\n",
    "predictors=['Datos_Poisson_3','Datos_Geom']\n",
    "outcome=['sexo']\n",
    "\n",
    "ejemplo.predict_lda(predictors,outcome)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES_NO_ES_n\n",
      "ES_NO_ES_s\n",
      "sexo_h\n",
      "sexo_m\n",
      "Datos_C_0\n",
      "Datos_C_1\n"
     ]
    }
   ],
   "source": [
    "for i in list(ejemplo.dummy.columns): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ES_NO_ES_s   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      995\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -690.37\n",
      "Date:                Tue, 04 Apr 2023   Deviance:                       1380.7\n",
      "Time:                        18:41:18   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.003775\n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Datos_Poisson_3     0.0099      0.019      0.515      0.607      -0.028       0.047\n",
      "Datos_Geom         -0.1060      0.091     -1.170      0.242      -0.284       0.072\n",
      "Datos_F            -0.0001      0.000     -0.675      0.500      -0.001       0.000\n",
      "Datos_E            -0.0774      0.062     -1.247      0.212      -0.199       0.044\n",
      "const               0.2053      0.263      0.780      0.435      -0.310       0.721\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# solo se puede variables dummys (0 y 1)\n",
    "predictors=['Datos_Poisson_3','Datos_Geom',\"Datos_F\",\"Datos_E\"]\n",
    "\n",
    "ejemplo.GLM_datos(predictors,'ES_NO_ES_s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ES_NO_ES_s   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      987\n",
      "Model Family:                Binomial   Df Model:                           12\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -688.64\n",
      "Date:                Tue, 04 Apr 2023   Deviance:                       1377.3\n",
      "Time:                        18:41:18   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.007230\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -0.0731      0.768     -0.095      0.924      -1.578       1.432\n",
      "bs(Datos_F, df=8)[0]    -0.5039      0.953     -0.529      0.597      -2.371       1.363\n",
      "bs(Datos_F, df=8)[1]     0.1020      0.584      0.175      0.861      -1.042       1.246\n",
      "bs(Datos_F, df=8)[2]    -0.1866      0.681     -0.274      0.784      -1.521       1.148\n",
      "bs(Datos_F, df=8)[3]     0.0577      0.595      0.097      0.923      -1.109       1.225\n",
      "bs(Datos_F, df=8)[4]    -0.8121      0.660     -1.230      0.219      -2.106       0.482\n",
      "bs(Datos_F, df=8)[5]     0.4080      0.694      0.588      0.556      -0.952       1.768\n",
      "bs(Datos_F, df=8)[6]    -0.8750      0.730     -1.199      0.230      -2.305       0.555\n",
      "bs(Datos_F, df=8)[7]     0.2150      0.673      0.320      0.749      -1.104       1.534\n",
      "Datos_Poisson_3          0.0086      0.019      0.448      0.654      -0.029       0.046\n",
      "bs(Datos_E, df=3)[0]     0.9573      1.311      0.731      0.465      -1.611       3.526\n",
      "bs(Datos_E, df=3)[1]    -0.2270      0.678     -0.335      0.738      -1.555       1.101\n",
      "bs(Datos_E, df=3)[2]     0.1295      1.013      0.128      0.898      -1.856       2.115\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "formula = ('ES_NO_ES_s ~ bs(Datos_F, df=8) + ' +\n",
    "            'Datos_Poisson_3 + bs(Datos_E, df=3)')\n",
    "ejemplo.GLM_datos_formula(predictors,'ES_NO_ES_s',formula)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión + curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Intercept  0.20520352743080916\n",
      " - Classes [0 1]\n",
      "\n",
      "*******************************\n",
      "Confusion Matrix (Accuracy 0.5290)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 119 360\n",
      "     1 111 410\n",
      "\n",
      "*******************************\n",
      " - Precision 0.5173913043478261\n",
      " - Sensibilidad 0.24843423799582465\n",
      " - Especificidad 0.7869481765834933\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ejemplo.mat_conf(predictors,'ES_NO_ES_s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos no balanceados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Undersample: usar un numero menor de datos de las clases mas prevalentes\n",
    "- Oversample: Usar más datos de la clase rara, bootstrapping\n",
    "- up weight y downweight: Darle más peso a la clase rara o menos a la clase más prev.\n",
    "- Data generation: Parecifo al bootstrapping \n",
    "- z- core: el valor resultante despúes de la estandarización \n",
    "- k:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling y pesos up/downs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de valores predichos (weighting): \n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "ejemplo.oversampling(predictors,'ES_NO_ES_s')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de elemetos positivos predichos (SMOTE resampled):  50.0\n",
      "Porcentaje de elemetos positivos predichos  (SMOTE):  51.1\n"
     ]
    }
   ],
   "source": [
    "ejemplo.data_gen(predictors,'ES_NO_ES_s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploración de predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 27% (3 of 11) |######                   | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 63% (7 of 11) |###############          | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearGAM(callbacks=[Deviance(), Diffs()], fit_intercept=True, \n",
      "   max_iter=100, scale=None, terms=s(0) + s(1) + intercept, \n",
      "   tol=0.0001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors=[\"Datos_F\",\"Datos_E\"]\n",
    "ejemplo.explo_predict(predictors,'ES_NO_ES_n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encuentra los K registros que tengan valor predictivo similar\n",
    "- Se puede usar para clasificar\n",
    "- Se puede usar para predecir \n",
    "\n",
    "Neighbor --> registros con valores predictivos similares entre sí\n",
    "z-score --> Valores de los resultados tras la estandarización\n",
    "\n",
    "características:\n",
    "  -  no hay modelo para ajustar\n",
    "  -  Depende de que esten escalados, similaridad de medidas, y tamaño\n",
    "  -  Solo variables numéricas y ESTANDARIZADAS PORQUE EN VALOR ABS PUEDE DOMINAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n",
      "   Datos_F  Datos_G   Datos_E\n",
      "0      664        0  0.358668\n",
      "1      240      114  1.023644\n",
      "2      563      466 -0.140854 \n",
      "\n",
      "OUTPUT PROBABILIDAD:\n",
      "0    0.525\n",
      "1    0.600\n",
      "2    0.400\n",
      "Name: result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictors=[\"Datos_F\",\"Datos_G\",\"Datos_E\"]\n",
    "outcome = 'ES_NO_ES'\n",
    "new=df_prueba.loc[0:2,predictors]\n",
    "print(\"INPUT:\")\n",
    "print(new,\"\\n\")\n",
    "print(\"OUTPUT PROBABILIDAD:\")\n",
    "ejemplo.KNN_predict(predictors,outcome,new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREE MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subdivide los datos para hacerlos lo más homogeneos posible\n",
    "- Split value: es una valor predictor que divide los grupos minimizando el predictor\n",
    "- Nodos: son las ramas, representaciñon de las reglas del split value\n",
    "- Leaf: final de la rama\n",
    "- Loss: el número de clasificaciones erroneas en el split process., mayor loss mayor impureza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node=0 test node: go to node 1 if 2 <= -0.3629712015390396 else to node 16\n",
      "  node=1 test node: go to node 2 if 1 <= 652.0 else to node 13\n",
      "    node=2 test node: go to node 3 if 1 <= 108.5 else to node 8\n",
      "      node=3 test node: go to node 4 if 2 <= -1.3491140007972717 else to node 5\n",
      "        node=4 leaf node: [[0.0, 1.0]]\n",
      "        node=5 test node: go to node 6 if 2 <= -1.1407527923583984 else to node 7\n",
      "          node=6 leaf node: [[1.0, 0.0]]\n",
      "          node=7 leaf node: [[0.276, 0.724]]\n",
      "      node=8 test node: go to node 9 if 2 <= -1.9709627628326416 else to node 12\n",
      "        node=9 test node: go to node 10 if 2 <= -2.5345969200134277 else to node 11\n",
      "          node=10 leaf node: [[0.0, 1.0]]\n",
      "          node=11 leaf node: [[1.0, 0.0]]\n",
      "        node=12 leaf node: [[0.503, 0.497]]\n",
      "    node=13 test node: go to node 14 if 2 <= -2.6731470823287964 else to node 15\n",
      "      node=14 leaf node: [[1.0, 0.0]]\n",
      "      node=15 leaf node: [[0.311, 0.689]]\n",
      "  node=16 test node: go to node 17 if 2 <= -0.3336757719516754 else to node 18\n",
      "    node=17 leaf node: [[1.0, 0.0]]\n",
      "    node=18 test node: go to node 19 if 2 <= 2.6100449562072754 else to node 26\n",
      "      node=19 test node: go to node 20 if 0 <= 997.5 else to node 25\n",
      "        node=20 test node: go to node 21 if 0 <= 990.5 else to node 24\n",
      "          node=21 test node: go to node 22 if 0 <= 979.5 else to node 23\n",
      "            node=22 leaf node: [[0.495, 0.505]]\n",
      "            node=23 leaf node: [[1.0, 0.0]]\n",
      "          node=24 leaf node: [[0.0, 1.0]]\n",
      "        node=25 leaf node: [[1.0, 0.0]]\n",
      "      node=26 leaf node: [[1.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictors=[\"Datos_F\",\"Datos_G\",\"Datos_E\"]\n",
    "outcome = 'ES_NO_ES'\n",
    "\n",
    "X = df_prueba[predictors]\n",
    "y = df_prueba[outcome]\n",
    "\n",
    "loan_tree = DecisionTreeClassifier(random_state=1, criterion='entropy',\n",
    "                                   min_impurity_decrease=0.003)\n",
    "clf=loan_tree.fit(X, y)\n",
    "\n",
    "\n",
    "print(textDecisionTree(loan_tree))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "609973a2d1f31d45d1c4d9f5c0b4ecf9cb33fe1a555b03392724c0cdbb5c54ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
